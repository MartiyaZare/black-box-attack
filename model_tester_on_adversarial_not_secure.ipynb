{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Flatten, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load config\n",
    "config = loadData(\"config\")\n",
    "dataSetSize = config[\"dataSetSize\"]\n",
    "testSetBenignSize = config[\"testSetBenignSize\"]\n",
    "validationSetSize = config[\"validationSetSize\"]\n",
    "trainingSetSize = config[\"trainingSetSize\"]\n",
    "sequenceLen = config[\"sequenceLen\"]\n",
    "dimensionsCount = config[\"dimensionsCount\"]\n",
    "numberOfAttackSamplesToChoose = 100\n",
    "testSetSize = testSetBenignSize + numberOfAttackSamplesToChoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = loadData(\"thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minPositiveMSE 0.0012496358692751217\n",
      "maxNegativeMSE nan\n",
      "Precision is:  1.0\n",
      "Recall is:  1.0\n",
      "0.0012496358692751217\n",
      "0.0012682043275681816\n",
      "Threshold is  0.0012682255911249565\n",
      "0 <TP   FP> 0\n",
      "Precision by threshold is:  nan\n",
      "Recall by threshold is:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\archive\\uni\\PhD\\Trustworthy Machine Learning\\project\\Angle_Difference\\utilities.py:88: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP/(TP+FP)\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_pca\")\n",
    "test_labels = np.ones(len(adversarialSet)) \n",
    "testSet = getReshapedTestSet(adversarialSet, \"PCA\")\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/pca.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"PCA\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <TP   FP> 0\n",
      "Precision without threshold is:  nan\n",
      "Recall without threshold is:  nan\n",
      "minPositiveMSE 0.001349663181208897\n",
      "maxNegativeMSE nan\n",
      "Threshold is  0.0013730668853040838\n",
      "Precision by threshold is:  nan\n",
      "Recall by threshold is:  0.0\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_fullyConnected\")\n",
    "test_labels = np.ones(len(adversarialSet)) \n",
    "testSet = getReshapedTestSet(adversarialSet, \"fullyConnected\")\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/autoencoder.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"fullyConnected\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <TP   FP> 0\n",
      "Precision without threshold is:  nan\n",
      "Recall without threshold is:  nan\n",
      "minPositiveMSE 3.60813332074621e-05\n",
      "maxNegativeMSE nan\n",
      "Threshold is  3.693430875407472e-05\n",
      "Precision by threshold is:  nan\n",
      "Recall by threshold is:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\archive\\uni\\PhD\\Trustworthy Machine Learning\\project\\Angle_Difference\\utilities.py:88: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP/(TP+FP)\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_conv\")\n",
    "test_labels = np.ones(len(adversarialSet)) \n",
    "testSet = getReshapedTestSet(adversarialSet, \"1DConv\")\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/conv.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse = mse.reshape(len(adversarialSet)) # for conv only\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"1DConv\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <TP   FP> 0\n",
      "Precision without threshold is:  nan\n",
      "Recall without threshold is:  nan\n",
      "minPositiveMSE 1.0538012298846228e-05\n",
      "maxNegativeMSE nan\n",
      "Threshold is  1.0687692541864324e-05\n",
      "Precision by threshold is:  nan\n",
      "Recall by threshold is:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\archive\\uni\\PhD\\Trustworthy Machine Learning\\project\\Angle_Difference\\utilities.py:88: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP/(TP+FP)\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_lstm\")\n",
    "test_labels = np.ones(len(adversarialSet)) \n",
    "testSet = getReshapedTestSet(adversarialSet, \"LSTM\")\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/lstm.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=2).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"LSTM\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.82487482e-05]\n"
     ]
    }
   ],
   "source": [
    "# Testing adversarial samples\n",
    "with open('Data_Set/adversarial_data_set.pickle', 'rb') as data:\n",
    "    advDataSet = pickle.load(data)\n",
    "sample = np.reshape(advDataSet[0,:,:],(1,200,9))\n",
    "predicted = model.predict(sample)\n",
    "mse = (np.square(sample - predicted)).mean(axis=2).mean(axis=1)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
