{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9583903607575301506\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9105744200\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3013583170029521808\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape, ZeroPadding1D, Cropping1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = None\n",
    "\n",
    "with open('dataset/tuning_set.pickle', 'rb') as data:\n",
    "    training_set = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = list()\n",
    "for entry in training_set:\n",
    "    for i in range(48):\n",
    "        trainingSet.append(list(entry[i:i+48,:]))\n",
    "trainingSet = np.array(trainingSet)\n",
    "sequenceLen = trainingSet.shape[1] # in training\n",
    "trainDataSize = trainingSet.shape[0]\n",
    "dimensionsCount = 6\n",
    "\n",
    "LSTMTraining_data = np.reshape(trainingSet, (trainDataSize,sequenceLen,dimensionsCount), order='C')\n",
    "FlattenedTrainingData = np.reshape(trainingSet, (trainDataSize,sequenceLen*dimensionsCount,1), order='C')\n",
    "fullyConnectedTrainingData = np.reshape(trainingSet, (trainDataSize,sequenceLen*dimensionsCount), order='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1DConv(numOfHiddenLayersInEncoder, FiltersCountInFirstLayer = 32, printSummary = 1, vrbs = 1, return_best = 0, filterSize = 3, learningRate = 0.001):    \n",
    "    numOfHiddenLayersInEncoder = numOfHiddenLayersInEncoder + 1\n",
    "    model = Sequential()    \n",
    "    poolingSize = 2\n",
    "    numOfFiltersInEncoder = [FiltersCountInFirstLayer]\n",
    "    paddingSize = (filterSize // 2)\n",
    "    inputLen = (sequenceLen * dimensionsCount)\n",
    "    paddedInputLength = inputLen + (paddingSize*2)\n",
    "    encoderLayersFilterSizes = [paddedInputLength]\n",
    "    model.add(ZeroPadding1D(paddingSize,input_shape=(sequenceLen * dimensionsCount,1)))\n",
    "    model.add(Conv1D(int(FiltersCountInFirstLayer), filterSize, activation='relu', padding = 'same'))\n",
    "    for i in range(1,numOfHiddenLayersInEncoder):\n",
    "        model.add(MaxPooling1D(poolingSize, padding='same'))\n",
    "        model.add(Conv1D(int(FiltersCountInFirstLayer*np.power(2,i)), filterSize, activation='relu', padding = 'same'))\n",
    "        \n",
    "        encoderLayersFilterSizes.append(int(np.ceil(paddedInputLength/np.power(2,i))))\n",
    "        numOfFiltersInEncoder.append(int(FiltersCountInFirstLayer*np.power(2,i)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((encoderLayersFilterSizes[-1], numOfFiltersInEncoder[-1])))\n",
    "    for j in range(1,numOfHiddenLayersInEncoder):    \n",
    "        model.add(Conv1D(numOfFiltersInEncoder[-j], filterSize, activation='relu', padding = 'same'))\n",
    "        model.add(UpSampling1D(poolingSize))\n",
    "\n",
    "    model.add(Conv1D(numOfFiltersInEncoder[0], filterSize, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(1, filterSize, activation='linear', padding='same'))\n",
    "    \n",
    "    toCrop = (model.layers[-1].output_shape[1] - inputLen) // 2\n",
    "    \n",
    "    model.add(Cropping1D(toCrop))\n",
    "    model.summary()\n",
    "\n",
    "    adamOptimizer = Adam(learning_rate=learningRate) # , beta_1=0.9, beta_2=0.999, amsgrad=False            \n",
    "    model.compile(optimizer=adamOptimizer,\n",
    "        loss='mean_squared_error',\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_1DConv.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "\n",
    "    history=model.fit(FlattenedTrainingData, FlattenedTrainingData,\n",
    "                        batch_size=1000, # normally 500 but for filter count tuning \n",
    "                        epochs=1000, \n",
    "                        shuffle=True,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=callbacksArray,\n",
    "                        )\n",
    "    if(return_best):\n",
    "        best_model = load_model('best_1DConv.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolutional Learning Rate Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_1 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 73, 128)           49280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 146, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 292, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 292, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 111,233\n",
      "Trainable params: 111,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 8s 188us/step - loss: 0.4665 - val_loss: 0.0322\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0314 - val_loss: 0.0314\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0309 - val_loss: 0.0306\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0307 - val_loss: 0.0306\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0303 - val_loss: 0.0304\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0299 - val_loss: 0.0303\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0299 - val_loss: 0.0300\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0285 - val_loss: 0.0255\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0233 - val_loss: 0.0209\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0199 - val_loss: 0.0172\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.9841e-04 - val_loss: 9.3636e-04\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.4700e-04 - val_loss: 9.2809e-04\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.7123e-04 - val_loss: 7.9870e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 8.6845e-04 - val_loss: 7.4501e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 7.6064e-04 - val_loss: 7.9486e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.8544e-04 - val_loss: 6.9853e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.4468e-04 - val_loss: 6.0248e-04\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.3689e-04 - val_loss: 5.4761e-04\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.1002e-04 - val_loss: 5.9918e-04\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.8173e-04 - val_loss: 5.6697e-04\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.7987e-04 - val_loss: 6.2951e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.1807e-04 - val_loss: 4.9995e-04\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.1554e-04 - val_loss: 5.0453e-04\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.4028e-04 - val_loss: 5.2503e-04\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.4555e-04 - val_loss: 5.4082e-04\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.6094e-04 - val_loss: 5.0749e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.6821e-04 - val_loss: 4.8626e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 4.5168e-04 - val_loss: 3.9133e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.2347e-04 - val_loss: 4.4630e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.5506e-04 - val_loss: 3.6876e-04\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.2151e-04 - val_loss: 6.0357e-04\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.9213e-04 - val_loss: 4.0738e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.2685e-04 - val_loss: 3.6482e-04\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.8870e-04 - val_loss: 4.2183e-04\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 3.9810e-04 - val_loss: 3.4994e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.5603e-04 - val_loss: 3.4980e-04\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.8122e-04 - val_loss: 3.4116e-04\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.8760e-04 - val_loss: 3.3527e-04\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.6793e-04 - val_loss: 3.6606e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.6702e-04 - val_loss: 3.6038e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.3926e-04 - val_loss: 3.4797e-04\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.5645e-04 - val_loss: 3.4787e-04\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.8167e-04 - val_loss: 4.1908e-04\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.3044e-04 - val_loss: 2.9331e-04\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.4698e-04 - val_loss: 2.6768e-04\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.1828e-04 - val_loss: 2.6660e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.1622e-04 - val_loss: 4.2027e-04\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.3029e-04 - val_loss: 2.8683e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.4893e-04 - val_loss: 3.3239e-04\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.7389e-04 - val_loss: 2.6310e-04\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.1213e-04 - val_loss: 4.0813e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.0705e-04 - val_loss: 3.7422e-04\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8920e-04 - val_loss: 3.4140e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.4617e-04 - val_loss: 3.6789e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.0183e-04 - val_loss: 2.4354e-04\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.7077e-04 - val_loss: 3.0195e-04\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.6293e-04 - val_loss: 2.8945e-04\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.9305e-04 - val_loss: 3.0653e-04\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.3619e-04 - val_loss: 2.7737e-04\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.7264e-04 - val_loss: 4.3729e-04\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.1326e-04 - val_loss: 2.5821e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.9601e-04 - val_loss: 2.6537e-04\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.7755e-04 - val_loss: 2.5414e-04\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.9582e-04 - val_loss: 3.3763e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.8760e-04 - val_loss: 3.0105e-04\n",
      "Epoch 00097: early stopping\n",
      "1\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_2 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 73, 128)           49280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 146, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 292, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 292, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 111,233\n",
      "Trainable params: 111,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 3s 79us/step - loss: 0.0516 - val_loss: 0.0305\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0290 - val_loss: 0.0266\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 0.0135 - val_loss: 0.0042\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0012 - val_loss: 6.4076e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.5102e-04 - val_loss: 2.8888e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.2902e-04 - val_loss: 1.7771e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.5391e-04 - val_loss: 1.1524e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.2962e-04 - val_loss: 9.8578e-05\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.3338e-05 - val_loss: 7.2554e-05\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.5275e-04 - val_loss: 7.0671e-05\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 6.4995e-05 - val_loss: 5.7735e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.4205e-05 - val_loss: 5.1626e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 5.3579e-05 - val_loss: 5.3383e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.5437e-05 - val_loss: 4.8730e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.8748e-05 - val_loss: 4.3772e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.3365e-05 - val_loss: 3.8249e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.4301e-05 - val_loss: 2.5510e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.1348e-05 - val_loss: 3.3922e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.3614e-05 - val_loss: 3.2939e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.9535e-05 - val_loss: 3.1909e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.4064e-05 - val_loss: 6.4801e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.9417e-05 - val_loss: 2.7891e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.9557e-05 - val_loss: 4.2502e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.9072e-05 - val_loss: 3.1756e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.2927e-05 - val_loss: 3.2367e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.7625e-05 - val_loss: 5.9023e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.2524e-05 - val_loss: 2.4845e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.7645e-05 - val_loss: 3.3471e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.4390e-05 - val_loss: 2.5201e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 6.0764e-05 - val_loss: 3.1545e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.2724e-05 - val_loss: 2.4436e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 5.6329e-05 - val_loss: 2.1556e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 2.2369e-05 - val_loss: 4.1417e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.6157e-05 - val_loss: 2.1550e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1029e-05 - val_loss: 7.2879e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.3917e-05 - val_loss: 1.8478e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.9203e-05 - val_loss: 1.7652e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0705e-05 - val_loss: 1.0546e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.6188e-05 - val_loss: 1.7127e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 1.7592e-05 - val_loss: 1.6257e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.8075e-05 - val_loss: 6.1694e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2958e-05 - val_loss: 1.6321e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8742e-05 - val_loss: 7.7713e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.3211e-05 - val_loss: 1.7033e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.5959e-05 - val_loss: 2.9696e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.3989e-05 - val_loss: 2.1743e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.5605e-05 - val_loss: 1.4315e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.6683e-05 - val_loss: 1.7176e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.2779e-05 - val_loss: 1.3882e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.7596e-05 - val_loss: 2.7360e-04\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.4573e-05 - val_loss: 1.7041e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.4120e-05 - val_loss: 1.3114e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 6.5010e-05 - val_loss: 3.0662e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.6444e-05 - val_loss: 1.3493e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 4.9324e-05 - val_loss: 1.0567e-04\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.6221e-05 - val_loss: 1.2728e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3299e-05 - val_loss: 1.5097e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.7707e-05 - val_loss: 2.3954e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 4.6290e-05 - val_loss: 8.9774e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.6757e-05 - val_loss: 1.2217e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.1637e-05 - val_loss: 1.3740e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.1311e-04 - val_loss: 2.2143e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.3866e-05 - val_loss: 1.1227e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.1184e-05 - val_loss: 1.0840e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.8508e-05 - val_loss: 6.0746e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.0562e-05 - val_loss: 1.0522e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.1638e-05 - val_loss: 2.4063e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7714e-05 - val_loss: 1.1274e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.5215e-05 - val_loss: 1.1922e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8156e-05 - val_loss: 1.0237e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.0440e-05 - val_loss: 9.8438e-06\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.9415e-05 - val_loss: 4.4350e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.6063e-05 - val_loss: 1.0257e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.0133e-05 - val_loss: 9.4538e-06\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.3449e-05 - val_loss: 1.1389e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.4092e-05 - val_loss: 1.0082e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.5777e-05 - val_loss: 1.8405e-04\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.2722e-05 - val_loss: 1.1152e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 4.3035e-05 - val_loss: 3.9074e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.9831e-05 - val_loss: 8.8543e-06\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.0597e-05 - val_loss: 1.2160e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.0022e-05 - val_loss: 4.5846e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.9876e-05 - val_loss: 1.3423e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2138e-05 - val_loss: 1.1353e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.9650e-05 - val_loss: 1.4405e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.3886e-06 - val_loss: 8.3100e-06\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.6831e-06 - val_loss: 2.7473e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.7350e-05 - val_loss: 8.4759e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.5066e-05 - val_loss: 4.6945e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9754e-05 - val_loss: 8.1663e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.5570e-05 - val_loss: 1.7380e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 7.1305e-05 - val_loss: 1.4090e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 8.9273e-06 - val_loss: 7.6507e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 7.8282e-06 - val_loss: 9.4453e-06\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.1717e-05 - val_loss: 9.0538e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.1503e-06 - val_loss: 7.4899e-06\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.4588e-06 - val_loss: 4.0477e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.9574e-05 - val_loss: 1.0844e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.4938e-05 - val_loss: 2.1898e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 5.7635e-05 - val_loss: 9.1213e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.7809e-06 - val_loss: 6.9496e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.4765e-05 - val_loss: 1.6890e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.2722e-05 - val_loss: 7.1583e-06\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.9789e-06 - val_loss: 2.9719e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.1205e-05 - val_loss: 8.4968e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.4942e-06 - val_loss: 6.7449e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.3592e-05 - val_loss: 7.1951e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.4677e-05 - val_loss: 9.6558e-06\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.3932e-06 - val_loss: 6.9327e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.6248e-05 - val_loss: 7.1161e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0848e-05 - val_loss: 1.5627e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.1311e-05 - val_loss: 1.3957e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.8859e-06 - val_loss: 2.9437e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.9004e-05 - val_loss: 1.0723e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.6416e-05 - val_loss: 2.0714e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.4295e-05 - val_loss: 4.2136e-05\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in [0.01, 0.001]:\n",
    "    lr = i\n",
    "    numOfLayers = 2\n",
    "    filtersCountInFirstLayer = 32\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer,learningRate = lr)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00024354380063111117, 6.744936683844571e-06]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(modelsLoss)\n",
    "\n",
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. learning rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('learning rate')\n",
    "plt.xticks(np.arange(2), [0.01, 0.001])\n",
    "plt.show()\n",
    "plt.savefig('figures_differential/1D_conv_learning_rate_tuning.eps', format='eps', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network Depth tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_1 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9280)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 145, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 145, 64)           12352     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 290, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 290, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 290, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 24,961\n",
      "Trainable params: 24,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 123us/step - loss: 0.0489 - val_loss: 0.0200\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 0.0077 - val_loss: 0.0020\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 9.4333e-04 - val_loss: 7.4694e-04\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.4389e-04 - val_loss: 3.6850e-04\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.9474e-04 - val_loss: 2.6290e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.0247e-04 - val_loss: 1.6759e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4676e-04 - val_loss: 1.2483e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.0495e-04 - val_loss: 9.1996e-05\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.0241e-05 - val_loss: 7.0703e-05\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.6262e-05 - val_loss: 5.7033e-05\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.4084e-05 - val_loss: 5.3379e-05\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7302e-05 - val_loss: 4.2387e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.0253e-05 - val_loss: 7.3646e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.3865e-05 - val_loss: 3.3298e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1472e-05 - val_loss: 2.9981e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.9328e-05 - val_loss: 3.7803e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.2178e-05 - val_loss: 2.6099e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.5055e-05 - val_loss: 2.4305e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 3.7014e-05 - val_loss: 2.2742e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.2390e-05 - val_loss: 2.1316e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.0722e-05 - val_loss: 2.0119e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.3168e-05 - val_loss: 2.0124e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.2074e-05 - val_loss: 3.4035e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.1051e-05 - val_loss: 1.8304e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1397e-05 - val_loss: 1.7091e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.6521e-05 - val_loss: 2.8134e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.6961e-05 - val_loss: 1.5500e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4995e-05 - val_loss: 1.5792e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.0132e-05 - val_loss: 1.4435e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.5705e-05 - val_loss: 1.3814e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3547e-05 - val_loss: 1.3990e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.3260e-05 - val_loss: 1.3161e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.0428e-05 - val_loss: 1.3177e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.2980e-05 - val_loss: 1.2130e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.0764e-05 - val_loss: 3.7184e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.5663e-05 - val_loss: 1.1414e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.1092e-05 - val_loss: 1.1645e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.8105e-05 - val_loss: 1.3131e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.1069e-05 - val_loss: 1.0874e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1289e-05 - val_loss: 1.0058e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.0997e-05 - val_loss: 9.6678e-06\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.3064e-05 - val_loss: 6.8699e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.6999e-05 - val_loss: 9.4120e-06\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.2402e-06 - val_loss: 9.5094e-06\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3194e-05 - val_loss: 1.0956e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.1237e-06 - val_loss: 8.5342e-06\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.3178e-05 - val_loss: 9.4697e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.0539e-05 - val_loss: 8.1839e-06\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.0890e-06 - val_loss: 7.9105e-06\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.0809e-06 - val_loss: 1.8130e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1286e-05 - val_loss: 8.7887e-06\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.0607e-06 - val_loss: 7.9371e-06\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.1646e-05 - val_loss: 2.0512e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 9.4271e-06 - val_loss: 7.4208e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.1360e-06 - val_loss: 7.0047e-06\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.6347e-05 - val_loss: 7.7596e-06\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.8596e-06 - val_loss: 6.8229e-06\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.7825e-06 - val_loss: 6.6624e-06\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.6110e-05 - val_loss: 6.8838e-06\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.9928e-06 - val_loss: 9.2124e-06\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.5299e-05 - val_loss: 8.2032e-06\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.3885e-05 - val_loss: 1.6432e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.0311e-06 - val_loss: 6.6626e-06\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.0575e-05 - val_loss: 7.0041e-06\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.8219e-06 - val_loss: 6.3039e-06\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.1214e-06 - val_loss: 8.0794e-06\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.3829e-05 - val_loss: 6.2841e-06\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.5121e-06 - val_loss: 5.8609e-06\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.8409e-06 - val_loss: 5.7202e-06\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.5776e-06 - val_loss: 2.0125e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.4219e-05 - val_loss: 7.4985e-06\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.9996e-06 - val_loss: 5.5088e-06\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.4265e-06 - val_loss: 5.5241e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.9567e-05 - val_loss: 6.0116e-06\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.5518e-06 - val_loss: 5.5459e-06\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.8161e-05 - val_loss: 3.6530e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.8929e-06 - val_loss: 5.7641e-06\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.3790e-06 - val_loss: 5.3049e-06\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.8297e-05 - val_loss: 6.5173e-06\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 5.7085e-06 - val_loss: 5.0477e-06\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.9046e-05 - val_loss: 4.1215e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.0516e-05 - val_loss: 5.1588e-06\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.0523e-06 - val_loss: 4.9000e-06\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 4.9471e-06 - val_loss: 4.8587e-06\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.3675e-05 - val_loss: 1.5787e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.7699e-06 - val_loss: 4.8133e-06\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.8060e-06 - val_loss: 5.3769e-06\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3509e-05 - val_loss: 5.2116e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 5.4805e-06 - val_loss: 4.8422e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 4.7795e-06 - val_loss: 7.1274e-06\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 3.2033e-05 - val_loss: 5.0662e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.0446e-06 - val_loss: 4.5123e-06\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 4.6630e-06 - val_loss: 4.4429e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 2.5321e-05 - val_loss: 5.3471e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.9159e-06 - val_loss: 4.9006e-06\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 4.5047e-06 - val_loss: 4.3125e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.2226e-05 - val_loss: 1.6828e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.2112e-06 - val_loss: 4.3648e-06\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.7915e-05 - val_loss: 4.3382e-06\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.0466e-06 - val_loss: 6.2441e-06\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.7144e-06 - val_loss: 9.5285e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 36us/step - loss: 1.3093e-05 - val_loss: 5.5624e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.8830e-05 - val_loss: 2.7815e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.8710e-06 - val_loss: 4.5202e-06\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.5381e-06 - val_loss: 2.0866e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.7866e-05 - val_loss: 6.1618e-06\n",
      "Epoch 00107: early stopping\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_2 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 73, 128)           49280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 146, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 292, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 292, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 111,233\n",
      "Trainable params: 111,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 86us/step - loss: 0.0531 - val_loss: 0.0286\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 0.0194 - val_loss: 0.0036\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0010 - val_loss: 9.5237e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.0485e-04 - val_loss: 8.5663e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.9820e-04 - val_loss: 6.9456e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 6.5043e-04 - val_loss: 5.4148e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.8944e-04 - val_loss: 3.6529e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8160e-04 - val_loss: 2.0047e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7315e-04 - val_loss: 1.3526e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.1906e-04 - val_loss: 9.5299e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.4782e-05 - val_loss: 8.0566e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 6.6855e-05 - val_loss: 1.0081e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 8.4338e-05 - val_loss: 5.1787e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.8009e-05 - val_loss: 4.6214e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.7093e-05 - val_loss: 5.3963e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.2000e-05 - val_loss: 3.9828e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.8543e-05 - val_loss: 7.1301e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 7.2964e-05 - val_loss: 3.5954e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 3.4531e-05 - val_loss: 3.4027e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.1742e-05 - val_loss: 3.6248e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.8108e-05 - val_loss: 3.1265e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.4951e-05 - val_loss: 5.3279e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.0992e-05 - val_loss: 3.0137e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8251e-05 - val_loss: 2.8579e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.1290e-05 - val_loss: 3.1066e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8112e-05 - val_loss: 2.7363e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.5041e-05 - val_loss: 2.2470e-04\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.2458e-05 - val_loss: 2.7409e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.4630e-05 - val_loss: 2.4500e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3685e-05 - val_loss: 2.3741e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.4452e-05 - val_loss: 3.5887e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.5958e-05 - val_loss: 2.5435e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.0423e-05 - val_loss: 3.0728e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2889e-05 - val_loss: 2.1826e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.0277e-05 - val_loss: 2.2592e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3054e-05 - val_loss: 2.0711e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2271e-05 - val_loss: 8.0661e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.6415e-05 - val_loss: 2.2884e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0190e-05 - val_loss: 2.3425e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.8720e-05 - val_loss: 2.2872e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.5541e-05 - val_loss: 2.9415e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.2574e-05 - val_loss: 3.7662e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.5911e-05 - val_loss: 1.8657e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8288e-05 - val_loss: 1.8608e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.5704e-05 - val_loss: 2.4652e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8658e-05 - val_loss: 1.7124e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.6585e-05 - val_loss: 1.7302e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.5191e-05 - val_loss: 2.7546e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7840e-05 - val_loss: 1.6388e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.3044e-05 - val_loss: 1.4015e-04\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.4054e-05 - val_loss: 1.7537e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.6345e-05 - val_loss: 1.8620e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.5413e-05 - val_loss: 2.1983e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.6151e-05 - val_loss: 1.5580e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.2331e-05 - val_loss: 2.6486e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.6454e-05 - val_loss: 1.4427e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.4179e-05 - val_loss: 4.3808e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.9147e-05 - val_loss: 1.4035e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.4567e-05 - val_loss: 7.1550e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.5202e-05 - val_loss: 1.3859e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.3898e-05 - val_loss: 2.3738e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 7.9554e-05 - val_loss: 1.4873e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.4196e-05 - val_loss: 1.3162e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.2599e-05 - val_loss: 1.2794e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.0687e-05 - val_loss: 2.3214e-04\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.1998e-05 - val_loss: 1.3078e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.2339e-05 - val_loss: 1.2375e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.1862e-05 - val_loss: 1.2167e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 8.1543e-05 - val_loss: 1.7547e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.7852e-05 - val_loss: 1.3832e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1741e-05 - val_loss: 1.1711e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.1222e-05 - val_loss: 1.1579e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.1137e-05 - val_loss: 1.2373e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.1720e-05 - val_loss: 1.2242e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.2482e-05 - val_loss: 1.4212e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.4670e-05 - val_loss: 1.6096e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.2049e-05 - val_loss: 2.7895e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.9828e-05 - val_loss: 1.3808e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.0830e-05 - val_loss: 1.0373e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.5143e-05 - val_loss: 3.0875e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.7530e-05 - val_loss: 1.2942e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0669e-05 - val_loss: 1.0156e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.7056e-06 - val_loss: 9.9750e-06\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.1256e-05 - val_loss: 1.2748e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.1154e-05 - val_loss: 1.1024e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.5579e-06 - val_loss: 9.9460e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.7070e-05 - val_loss: 1.3378e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 2.9132e-05 - val_loss: 1.1096e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.2611e-06 - val_loss: 9.2647e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.0672e-06 - val_loss: 1.1657e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.0508e-05 - val_loss: 1.7126e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.0107e-05 - val_loss: 1.0285e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.6331e-05 - val_loss: 1.1814e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.1103e-05 - val_loss: 3.5511e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.3192e-05 - val_loss: 1.1362e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 9.2987e-06 - val_loss: 8.6546e-06\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 8.2189e-06 - val_loss: 1.0905e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.1012e-05 - val_loss: 1.4865e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 9.0505e-06 - val_loss: 8.1935e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.8613e-06 - val_loss: 8.2929e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.8597e-05 - val_loss: 1.0233e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0389e-05 - val_loss: 8.0346e-06\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 7.6061e-06 - val_loss: 7.9415e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.3643e-05 - val_loss: 4.1550e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7705e-05 - val_loss: 8.1678e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 7.7070e-06 - val_loss: 7.5305e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.2082e-05 - val_loss: 6.4939e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9574e-05 - val_loss: 8.3511e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.5232e-06 - val_loss: 7.7428e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.1765e-05 - val_loss: 1.4036e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.4723e-06 - val_loss: 7.4072e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.5394e-05 - val_loss: 2.4215e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.5935e-05 - val_loss: 8.1956e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.0587e-06 - val_loss: 7.0848e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.5633e-05 - val_loss: 1.0492e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 9.5211e-06 - val_loss: 6.9700e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 6.6102e-06 - val_loss: 7.5338e-06\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.0841e-05 - val_loss: 9.2488e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.8479e-06 - val_loss: 6.6948e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.3645e-06 - val_loss: 7.1770e-06\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 3.7461e-05 - val_loss: 1.6710e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.5703e-06 - val_loss: 6.5864e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.5572e-06 - val_loss: 8.4500e-06\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.8713e-05 - val_loss: 9.7229e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.3499e-06 - val_loss: 6.3936e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.9785e-06 - val_loss: 6.2247e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.6975e-06 - val_loss: 2.9189e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5755e-05 - val_loss: 8.5955e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.3513e-06 - val_loss: 5.9923e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5945e-05 - val_loss: 4.9148e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.2560e-05 - val_loss: 6.1135e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.7914e-06 - val_loss: 5.7721e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2983e-05 - val_loss: 1.4878e-04\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.3725e-05 - val_loss: 7.1363e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.7515e-06 - val_loss: 5.7201e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.6567e-06 - val_loss: 6.1742e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.3147e-05 - val_loss: 1.0158e-05\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 66us/step - loss: 6.8236e-06 - val_loss: 5.5738e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.2909e-06 - val_loss: 5.9294e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.2092e-05 - val_loss: 8.9102e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 6.5894e-06 - val_loss: 5.4095e-06\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.5412e-05 - val_loss: 3.5281e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.0111e-05 - val_loss: 5.9002e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8481e-05 - val_loss: 1.2653e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.2495e-06 - val_loss: 5.1410e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6859e-05 - val_loss: 2.8340e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0442e-05 - val_loss: 5.2963e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.9816e-05 - val_loss: 6.7541e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.8052e-06 - val_loss: 5.1258e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.2082e-06 - val_loss: 8.4387e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.4124e-05 - val_loss: 7.9805e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.2249e-06 - val_loss: 4.9384e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.2792e-05 - val_loss: 2.1358e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 7.2727e-06 - val_loss: 4.9362e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.5767e-06 - val_loss: 4.7242e-06\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.6046e-05 - val_loss: 1.9218e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 8.2869e-06 - val_loss: 5.3830e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0706e-05 - val_loss: 9.4938e-06\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.6135e-06 - val_loss: 5.7624e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.4606e-05 - val_loss: 6.4320e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.5145e-06 - val_loss: 4.5352e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6221e-05 - val_loss: 3.2124e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.3713e-05 - val_loss: 4.8206e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.4303e-06 - val_loss: 4.9121e-06\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.8159e-05 - val_loss: 9.8999e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.6551e-06 - val_loss: 4.4031e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.2286e-06 - val_loss: 5.3954e-06\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.6709e-05 - val_loss: 7.8190e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.9349e-06 - val_loss: 5.0341e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.8755e-05 - val_loss: 9.6338e-06\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.6219e-06 - val_loss: 4.0718e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.1069e-05 - val_loss: 5.6327e-05\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.8662e-05 - val_loss: 4.9739e-06\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.0726e-06 - val_loss: 3.9882e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.7915e-06 - val_loss: 3.9476e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.9397e-06 - val_loss: 3.7275e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.9438e-05 - val_loss: 5.5523e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.9370e-06 - val_loss: 3.8142e-06\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.6487e-06 - val_loss: 6.2495e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6360e-05 - val_loss: 7.6400e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.4006e-06 - val_loss: 3.9700e-06\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6352e-05 - val_loss: 3.2500e-05\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0044e-05 - val_loss: 4.0131e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.8112e-06 - val_loss: 8.7723e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.7326e-05 - val_loss: 5.9430e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.1390e-06 - val_loss: 3.6956e-06\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 8.4636e-06 - val_loss: 6.0123e-05\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.3731e-05 - val_loss: 4.0347e-06\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.1633e-06 - val_loss: 2.1052e-05\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.9793e-05 - val_loss: 4.8582e-06\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.7537e-06 - val_loss: 3.5002e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.3372e-06 - val_loss: 4.1225e-06\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.7528e-05 - val_loss: 9.7078e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.2330e-06 - val_loss: 3.9252e-06\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.3901e-06 - val_loss: 3.5096e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.7098e-05 - val_loss: 7.5025e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.2079e-06 - val_loss: 3.4568e-06\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.1707e-06 - val_loss: 3.2790e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.7538e-06 - val_loss: 5.2140e-06\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2651e-05 - val_loss: 7.6991e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 5.2535e-06 - val_loss: 5.9326e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.5907e-05 - val_loss: 8.3303e-06\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.1567e-06 - val_loss: 1.3140e-05\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.6055e-06 - val_loss: 5.4491e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6720e-05 - val_loss: 4.0772e-06\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5239e-06 - val_loss: 4.2128e-06\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.9701e-05 - val_loss: 4.8501e-06\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5741e-06 - val_loss: 3.3293e-06\n",
      "Epoch 00211: early stopping\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_3 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 37, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 37, 256)           98560     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 37, 256)           196864    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 74, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 74, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1 (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 148, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1 (None, 296, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 296, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 296, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_3 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 455,809\n",
      "Trainable params: 455,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 115us/step - loss: 0.0507 - val_loss: 0.0294\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0271 - val_loss: 0.0156\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.0871e-04 - val_loss: 9.3121e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.6816e-04 - val_loss: 5.3326e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.6329e-04 - val_loss: 3.5306e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.8756e-04 - val_loss: 2.3107e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.8732e-04 - val_loss: 1.4314e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3850e-04 - val_loss: 1.1010e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.7951e-04 - val_loss: 1.0093e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.6448e-05 - val_loss: 8.7331e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 8.3018e-05 - val_loss: 8.9855e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.0507e-04 - val_loss: 7.6833e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.4503e-05 - val_loss: 8.2731e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.0591e-04 - val_loss: 9.8009e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 9.5117e-05 - val_loss: 1.4368e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.7076e-05 - val_loss: 7.1369e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.7560e-05 - val_loss: 1.1798e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.3532e-05 - val_loss: 6.5162e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 9.9028e-05 - val_loss: 6.1562e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 4s 98us/step - loss: 7.7841e-05 - val_loss: 4.0749e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.8865e-05 - val_loss: 5.5844e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 4s 86us/step - loss: 8.3918e-05 - val_loss: 1.1395e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 4s 83us/step - loss: 6.3994e-05 - val_loss: 5.0177e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.0707e-04 - val_loss: 9.5847e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 5.5858e-05 - val_loss: 4.7398e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 4s 88us/step - loss: 1.0916e-04 - val_loss: 1.7444e-04\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 4s 89us/step - loss: 6.6719e-05 - val_loss: 4.5251e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 4.3290e-05 - val_loss: 4.6645e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.0482e-04 - val_loss: 4.2586e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.3519e-05 - val_loss: 4.7657e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.0217e-04 - val_loss: 4.4313e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 9.3473e-05 - val_loss: 4.8732e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 4s 91us/step - loss: 6.0914e-05 - val_loss: 3.8163e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 4s 87us/step - loss: 4.4435e-05 - val_loss: 1.6713e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.8797e-05 - val_loss: 3.7393e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 5.8055e-05 - val_loss: 3.8942e-04\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 8.5177e-05 - val_loss: 3.5848e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.3146e-05 - val_loss: 2.2146e-04\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 8.8303e-05 - val_loss: 3.6982e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.8939e-05 - val_loss: 2.0029e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 5.3266e-05 - val_loss: 3.5287e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.4362e-05 - val_loss: 7.1250e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.0699e-05 - val_loss: 1.0543e-04\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 7.7746e-05 - val_loss: 3.2588e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 7.5598e-05 - val_loss: 7.5713e-04\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.0616e-04 - val_loss: 3.1075e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.8319e-05 - val_loss: 2.8401e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.0188e-05 - val_loss: 2.1951e-04\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.2559e-05 - val_loss: 3.7061e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 4s 94us/step - loss: 9.0144e-05 - val_loss: 5.5150e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.7477e-05 - val_loss: 3.1032e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 4s 85us/step - loss: 3.2896e-05 - val_loss: 1.7097e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 9.1782e-05 - val_loss: 3.1989e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.5651e-05 - val_loss: 3.1549e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.8041e-05 - val_loss: 2.6794e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.5272e-05 - val_loss: 2.7978e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 4s 84us/step - loss: 9.6035e-05 - val_loss: 4.0884e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.6055e-05 - val_loss: 2.5099e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.5764e-05 - val_loss: 8.1399e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 3.1913e-05 - val_loss: 2.3141e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 3.7299e-05 - val_loss: 2.4397e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.7022e-05 - val_loss: 2.9479e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.1750e-05 - val_loss: 2.1964e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.2169e-04 - val_loss: 3.7226e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.2643e-05 - val_loss: 2.0566e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.9592e-05 - val_loss: 2.0399e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.1486e-04 - val_loss: 3.9764e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.1872e-05 - val_loss: 1.9257e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.8513e-05 - val_loss: 1.9787e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.2931e-05 - val_loss: 2.5187e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.0094e-05 - val_loss: 1.8642e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 7.6774e-05 - val_loss: 7.0275e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.2305e-05 - val_loss: 1.8911e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7543e-05 - val_loss: 2.7180e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.9747e-05 - val_loss: 2.5264e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.8815e-05 - val_loss: 1.7175e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.8314e-05 - val_loss: 6.4393e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.6965e-05 - val_loss: 1.9935e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.6651e-05 - val_loss: 1.6225e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 4s 92us/step - loss: 5.6980e-05 - val_loss: 3.7077e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 4s 87us/step - loss: 2.5822e-05 - val_loss: 1.5689e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 4s 86us/step - loss: 5.0900e-05 - val_loss: 2.4188e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.2286e-05 - val_loss: 1.8755e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.9798e-05 - val_loss: 1.8477e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.6986e-05 - val_loss: 1.7975e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.8173e-05 - val_loss: 2.3226e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6235e-05 - val_loss: 1.5419e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.0726e-05 - val_loss: 2.8058e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.5799e-05 - val_loss: 1.4382e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.3428e-05 - val_loss: 2.2360e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 4s 87us/step - loss: 6.5884e-05 - val_loss: 1.4677e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.3349e-05 - val_loss: 1.3419e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.5760e-05 - val_loss: 7.0496e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.2656e-05 - val_loss: 1.4544e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.5019e-05 - val_loss: 1.3120e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.2715e-05 - val_loss: 1.5613e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.3280e-05 - val_loss: 1.2013e-04\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 3.1460e-05 - val_loss: 1.3646e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.2264e-05 - val_loss: 1.2235e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 6.1877e-05 - val_loss: 5.5009e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 4s 85us/step - loss: 2.1904e-05 - val_loss: 1.2464e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 1.1999e-05 - val_loss: 1.6541e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 4s 87us/step - loss: 6.4489e-05 - val_loss: 1.3863e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.2581e-05 - val_loss: 1.1740e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 1.1928e-05 - val_loss: 3.0930e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 7.0012e-05 - val_loss: 1.7043e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.1848e-05 - val_loss: 1.1415e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.2156e-05 - val_loss: 6.7854e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.1609e-05 - val_loss: 1.5855e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.5351e-05 - val_loss: 2.0508e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.3842e-05 - val_loss: 3.2004e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.8050e-05 - val_loss: 1.0769e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.1672e-05 - val_loss: 2.3025e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 7.6680e-05 - val_loss: 1.4699e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.1094e-05 - val_loss: 1.0344e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1954e-05 - val_loss: 5.7606e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.1356e-05 - val_loss: 1.3147e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.0503e-05 - val_loss: 1.1140e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.7195e-05 - val_loss: 2.1320e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.1653e-05 - val_loss: 1.0012e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 4.3705e-05 - val_loss: 1.8740e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.3496e-05 - val_loss: 1.0720e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 9.2344e-06 - val_loss: 9.4881e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.4555e-05 - val_loss: 2.6961e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.1520e-05 - val_loss: 9.2786e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.8146e-06 - val_loss: 9.7492e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.0548e-05 - val_loss: 1.5779e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.1685e-05 - val_loss: 9.5442e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.9112e-06 - val_loss: 9.3905e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.8483e-05 - val_loss: 9.9893e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.4839e-06 - val_loss: 9.1165e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.5105e-06 - val_loss: 1.2559e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.1648e-05 - val_loss: 1.1608e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.3746e-06 - val_loss: 8.4715e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.7078e-06 - val_loss: 1.9502e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.2526e-05 - val_loss: 1.0270e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 8.3864e-0 - 3s 72us/step - loss: 8.3926e-06 - val_loss: 1.0578e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.7841e-05 - val_loss: 1.5533e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 8.9587e-06 - val_loss: 8.0020e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6973e-05 - val_loss: 1.8061e-04\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.6298e-05 - val_loss: 8.7687e-06\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.8251e-06 - val_loss: 7.6848e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.0991e-05 - val_loss: 1.1686e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.0919e-05 - val_loss: 8.6279e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.6814e-06 - val_loss: 7.4249e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.0815e-05 - val_loss: 1.0771e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.3106e-05 - val_loss: 4.2027e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.4100e-05 - val_loss: 7.6825e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.5703e-05 - val_loss: 1.1065e-04\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.5656e-05 - val_loss: 7.7527e-06\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.0779e-06 - val_loss: 7.0323e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.2617e-05 - val_loss: 2.1480e-05\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.1342e-05 - val_loss: 7.5990e-06\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.7563e-06 - val_loss: 7.4759e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.6734e-05 - val_loss: 1.0559e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 7.4419e-06 - val_loss: 7.0610e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.7094e-05 - val_loss: 1.6459e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.9071e-06 - val_loss: 6.8985e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.3284e-06 - val_loss: 6.7542e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 3.5497e-05 - val_loss: 7.7295e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.9947e-06 - val_loss: 6.4265e-06\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 6.1735e-06 - val_loss: 8.0880e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.7797e-05 - val_loss: 8.0190e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 7.0237e-06 - val_loss: 9.4368e-06\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.2926e-05 - val_loss: 7.2061e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.5040e-06 - val_loss: 7.1366e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.3814e-06 - val_loss: 1.5852e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 3.8827e-05 - val_loss: 9.2138e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 6.3140e-06 - val_loss: 5.9025e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.3545e-06 - val_loss: 6.8338e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 3.5835e-05 - val_loss: 6.3841e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.8154e-06 - val_loss: 5.7227e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.4668e-06 - val_loss: 6.0301e-06\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.3682e-05 - val_loss: 1.6167e-05\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 8.4018e-06 - val_loss: 6.1875e-06\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 4s 85us/step - loss: 5.6561e-06 - val_loss: 5.7557e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.4048e-06 - val_loss: 5.6642e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.4260e-06 - val_loss: 6.9667e-06\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.9838e-05 - val_loss: 6.3746e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.6919e-06 - val_loss: 5.3930e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.1119e-06 - val_loss: 5.3075e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.0591e-05 - val_loss: 2.7947e-05\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 8.6839e-06 - val_loss: 5.3573e-06\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.0982e-06 - val_loss: 5.8369e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.6136e-05 - val_loss: 1.3289e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 7.1732e-06 - val_loss: 8.2090e-06\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.7496e-05 - val_loss: 1.1057e-05\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 6.2010e-06 - val_loss: 5.1610e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 8.9709e-06 - val_loss: 7.4064e-05\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.5057e-05 - val_loss: 5.4416e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.8568e-06 - val_loss: 4.7979e-06\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.8136e-05 - val_loss: 1.2572e-05\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 3s 80us/step - loss: 7.7502e-06 - val_loss: 4.9432e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 8.3579e-06 - val_loss: 2.0501e-05\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.1691e-05 - val_loss: 6.6343e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.6308e-05 - val_loss: 7.8099e-06\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.8371e-06 - val_loss: 1.0595e-05\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6173e-05 - val_loss: 6.0504e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.3767e-05 - val_loss: 1.0602e-04\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.7624e-05 - val_loss: 5.4512e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.0203e-05 - val_loss: 1.1783e-05\n",
      "Epoch 00207: early stopping\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_4 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 37, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 37, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 19, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 19, 512)           393728    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9728)              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 19, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 19, 512)           786944    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1 (None, 38, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 38, 256)           393472    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1 (None, 76, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 76, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1 (None, 152, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 152, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling (None, 304, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 304, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 304, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,833,089\n",
      "Trainable params: 1,833,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 7s 158us/step - loss: 0.0456 - val_loss: 0.0291\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 4s 100us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 4s 104us/step - loss: 0.0289 - val_loss: 0.0293\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0290 - val_loss: 0.0291\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 0.0290 - val_loss: 0.0286\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 0.0211 - val_loss: 0.0038\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 5s 108us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 5s 104us/step - loss: 0.0011 - val_loss: 8.1051e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 7.3877e-04 - val_loss: 6.5228e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 6.7872e-04 - val_loss: 5.7870e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 6.5329e-04 - val_loss: 5.5143e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 5.5499e-04 - val_loss: 4.6314e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.2121e-04 - val_loss: 3.5085e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.5170e-04 - val_loss: 2.8482e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 4s 104us/step - loss: 3.0568e-04 - val_loss: 2.6830e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.2814e-04 - val_loss: 1.6966e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.1428e-04 - val_loss: 1.6293e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.2031e-04 - val_loss: 1.7379e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.3783e-04 - val_loss: 1.3696e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 1.6054e-04 - val_loss: 1.3116e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 4s 104us/step - loss: 1.4416e-04 - val_loss: 1.7117e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 5s 115us/step - loss: 1.9806e-04 - val_loss: 2.3809e-04\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 5s 107us/step - loss: 1.1236e-04 - val_loss: 8.7957e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 5s 105us/step - loss: 1.0049e-04 - val_loss: 4.2239e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.4349e-04 - val_loss: 7.7910e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 7.6051e-05 - val_loss: 9.5982e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.4970e-04 - val_loss: 8.1605e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 7.8932e-05 - val_loss: 2.4284e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 5s 106us/step - loss: 1.3111e-04 - val_loss: 7.1008e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 5s 105us/step - loss: 1.1693e-04 - val_loss: 9.0748e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 8.3550e-05 - val_loss: 5.9061e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 6.1840e-05 - val_loss: 2.2895e-04\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.6666e-04 - val_loss: 6.0571e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 5.3519e-05 - val_loss: 5.2576e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.6466e-04 - val_loss: 6.1203e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 6.1401e-05 - val_loss: 5.1019e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.8105e-05 - val_loss: 4.9295e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.0348e-04 - val_loss: 7.6829e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.7287e-05 - val_loss: 4.4158e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.6299e-04 - val_loss: 1.1382e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 5.1435e-05 - val_loss: 4.1949e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.0021e-05 - val_loss: 4.0864e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 8.4073e-05 - val_loss: 5.7667e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.5135e-05 - val_loss: 5.8794e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.1309e-04 - val_loss: 4.3073e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.7047e-05 - val_loss: 3.6095e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.4999e-04 - val_loss: 6.0071e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.1364e-05 - val_loss: 3.5079e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.3503e-05 - val_loss: 3.4883e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.1370e-04 - val_loss: 5.5330e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.8663e-05 - val_loss: 3.2889e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.4016e-05 - val_loss: 3.7396e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.0339e-04 - val_loss: 3.3777e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.0377e-05 - val_loss: 3.1378e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 6.5742e-05 - val_loss: 3.5686e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 5.0435e-05 - val_loss: 2.0345e-04\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 5.4791e-05 - val_loss: 3.0537e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 7.0888e-05 - val_loss: 4.6960e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.1506e-05 - val_loss: 2.8518e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.3345e-04 - val_loss: 3.9629e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.2755e-05 - val_loss: 2.7612e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.6055e-05 - val_loss: 2.6531e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 8.9394e-05 - val_loss: 4.5414e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.8174e-05 - val_loss: 2.5908e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 7.1594e-05 - val_loss: 1.2732e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.0808e-05 - val_loss: 2.6942e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 2.4309e-05 - val_loss: 2.8664e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.0408e-04 - val_loss: 2.7311e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.4187e-05 - val_loss: 2.3160e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.2117e-05 - val_loss: 2.3487e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.1078e-04 - val_loss: 2.9164e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.4223e-05 - val_loss: 2.2127e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.1347e-05 - val_loss: 2.3045e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 9.8079e-05 - val_loss: 4.0970e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.4235e-05 - val_loss: 2.1815e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 2.0267e-05 - val_loss: 2.1711e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 5s 105us/step - loss: 7.4189e-05 - val_loss: 3.2984e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 2.5016e-05 - val_loss: 2.0085e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 7.3554e-05 - val_loss: 1.2604e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 5.5060e-05 - val_loss: 2.0528e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 1.9340e-05 - val_loss: 1.9177e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 2.3345e-05 - val_loss: 1.4509e-04\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 4s 102us/step - loss: 8.1722e-05 - val_loss: 2.2115e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.8440e-05 - val_loss: 1.8188e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 4.0184e-05 - val_loss: 1.6318e-04\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.4518e-05 - val_loss: 1.7822e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 5.3101e-05 - val_loss: 4.5746e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 5s 114us/step - loss: 2.9148e-05 - val_loss: 1.7226e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 5s 106us/step - loss: 1.6796e-05 - val_loss: 1.8138e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 5s 108us/step - loss: 8.7052e-05 - val_loss: 2.3892e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 1.9050e-05 - val_loss: 1.6837e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 6.3041e-05 - val_loss: 4.2903e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 3.4544e-05 - val_loss: 1.6668e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.5807e-05 - val_loss: 1.5866e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 1.8029e-05 - val_loss: 7.8374e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 7.2848e-04 - val_loss: 2.5391e-04\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 1.5704e-04 - val_loss: 1.0306e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 8.2522e-05 - val_loss: 6.9365e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 5.9902e-05 - val_loss: 5.3920e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 4.8448e-05 - val_loss: 4.5529e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 4s 103us/step - loss: 4.1656e-05 - val_loss: 3.9599e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 3.6896e-05 - val_loss: 3.5968e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 4s 102us/step - loss: 3.3729e-05 - val_loss: 3.2771e-05\n",
      "Epoch 00111: early stopping\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_5 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 37, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 37, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 19, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 19, 512)           393728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 10, 1024)          1573888   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 10, 1024)          3146752   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_11 (UpSampling (None, 20, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 20, 512)           1573376   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_12 (UpSampling (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 40, 256)           393472    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_13 (UpSampling (None, 80, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 80, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling (None, 160, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 160, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling (None, 320, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 320, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 320, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_5 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 7,340,161\n",
      "Trainable params: 7,340,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 10s 233us/step - loss: 0.0674 - val_loss: 0.0297\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 0.0291 - val_loss: 0.0291\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 0.0283 - val_loss: 0.0204\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 7s 160us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 7s 160us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 0.0017 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 7s 158us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 9.9498e-04 - val_loss: 7.9213e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 8.0351e-04 - val_loss: 7.3659e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 7.1658e-04 - val_loss: 6.5575e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 7s 152us/step - loss: 6.5501e-04 - val_loss: 6.1767e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 7s 158us/step - loss: 6.5547e-04 - val_loss: 6.0410e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 7s 163us/step - loss: 4.6569e-04 - val_loss: 4.1470e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 4.2667e-04 - val_loss: 3.8779e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.8838e-04 - val_loss: 3.5356e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 7s 154us/step - loss: 3.5496e-04 - val_loss: 2.9905e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 3.5998e-04 - val_loss: 2.5787e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 2.9281e-04 - val_loss: 2.4599e-04\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 2.4745e-04 - val_loss: 2.9302e-04\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 2.1757e-04 - val_loss: 1.8402e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 2.3062e-04 - val_loss: 1.8463e-04\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 7s 160us/step - loss: 1.8465e-04 - val_loss: 2.0271e-04\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 1.5890e-04 - val_loss: 1.3240e-04\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 7s 164us/step - loss: 1.8838e-04 - val_loss: 1.2249e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.1891e-04 - val_loss: 2.6169e-04\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 7s 155us/step - loss: 1.5797e-04 - val_loss: 1.0650e-04\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 1.3063e-04 - val_loss: 1.3101e-04\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 1.1161e-04 - val_loss: 1.6990e-04\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 1.4429e-04 - val_loss: 1.0482e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 9.6259e-05 - val_loss: 9.3774e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 1.2884e-04 - val_loss: 9.3250e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 1.1043e-04 - val_loss: 4.2801e-04\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 1.3226e-04 - val_loss: 8.5200e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 7.8143e-05 - val_loss: 7.8182e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 7s 160us/step - loss: 1.1057e-04 - val_loss: 8.8823e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 7s 158us/step - loss: 9.4576e-05 - val_loss: 9.0164e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 7s 155us/step - loss: 1.1365e-04 - val_loss: 1.1848e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 8.6923e-05 - val_loss: 7.3551e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 1.2719e-04 - val_loss: 1.7207e-04\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 7s 165us/step - loss: 8.2606e-05 - val_loss: 6.8551e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 7s 164us/step - loss: 6.6705e-05 - val_loss: 9.4148e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 1.4812e-04 - val_loss: 6.6467e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 6.3981e-05 - val_loss: 6.4666e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 1.5529e-04 - val_loss: 8.9257e-04\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 2.9853e-04 - val_loss: 9.8135e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 7.8485e-05 - val_loss: 7.1250e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 7s 155us/step - loss: 6.6888e-05 - val_loss: 7.6351e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 7s 154us/step - loss: 1.1944e-04 - val_loss: 6.9547e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 6.1358e-05 - val_loss: 5.9962e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 8.0947e-05 - val_loss: 6.1072e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 1.0628e-04 - val_loss: 1.0402e-04\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 7s 155us/step - loss: 6.5060e-05 - val_loss: 5.5227e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 8s 182us/step - loss: 8.0324e-05 - val_loss: 8.3239e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 7s 171us/step - loss: 6.2338e-05 - val_loss: 6.8733e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 7s 157us/step - loss: 8.3746e-05 - val_loss: 5.6041e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 8.8176e-05 - val_loss: 1.3306e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 6.6592e-05 - val_loss: 4.9472e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 7s 156us/step - loss: 8.2669e-05 - val_loss: 1.0595e-04\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 5.5127e-05 - val_loss: 5.0474e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 7s 158us/step - loss: 6.9661e-05 - val_loss: 6.2094e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 9.9753e-05 - val_loss: 7.6003e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 5.1761e-05 - val_loss: 4.3627e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 7.3582e-05 - val_loss: 9.7713e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.8602e-05 - val_loss: 4.1764e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 9.5390e-05 - val_loss: 4.3975e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 4.2710e-05 - val_loss: 4.0387e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.2780e-04 - val_loss: 1.5327e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 5.8869e-05 - val_loss: 3.9181e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 7s 173us/step - loss: 3.7317e-05 - val_loss: 3.7823e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.2752e-05 - val_loss: 1.3033e-04\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 5.4837e-05 - val_loss: 3.6064e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.4816e-05 - val_loss: 3.5279e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.0768e-04 - val_loss: 4.9482e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 3.8463e-05 - val_loss: 3.4188e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 7s 152us/step - loss: 3.5796e-05 - val_loss: 7.4903e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 7s 169us/step - loss: 6.8110e-05 - val_loss: 3.9517e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 8.7894e-05 - val_loss: 5.2064e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 7s 163us/step - loss: 3.5404e-05 - val_loss: 3.3203e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 7.5072e-05 - val_loss: 7.7212e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 7s 166us/step - loss: 3.7676e-05 - val_loss: 3.1108e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 8s 182us/step - loss: 6.4599e-05 - val_loss: 7.3507e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 8s 178us/step - loss: 4.5771e-05 - val_loss: 3.0289e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 6.0653e-05 - val_loss: 3.6437e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 7s 165us/step - loss: 4.0656e-05 - val_loss: 3.1946e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 8s 176us/step - loss: 7.7126e-05 - val_loss: 5.6502e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 7s 161us/step - loss: 3.5168e-05 - val_loss: 2.8362e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 7s 164us/step - loss: 7.3710e-05 - val_loss: 1.2687e-04\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 8s 180us/step - loss: 4.0943e-05 - val_loss: 2.7664e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 7s 159us/step - loss: 2.9450e-05 - val_loss: 7.6387e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 7s 162us/step - loss: 5.8277e-05 - val_loss: 2.8878e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 6.3230e-05 - val_loss: 3.5507e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.1632e-05 - val_loss: 2.7358e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.5347e-05 - val_loss: 2.5397e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 7s 152us/step - loss: 3.4263e-04 - val_loss: 4.2221e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.5739e-04 - val_loss: 5.3134e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 4.1487e-05 - val_loss: 3.6223e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 3.3103e-05 - val_loss: 3.1827e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 3.0104e-05 - val_loss: 2.9585e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 5.7583e-05 - val_loss: 5.7953e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 3.7377e-05 - val_loss: 2.7829e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.6080e-05 - val_loss: 2.6088e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 8.1644e-05 - val_loss: 5.1537e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.8400e-05 - val_loss: 2.4895e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.4224e-05 - val_loss: 2.5816e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.0148e-05 - val_loss: 4.3256e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.5908e-05 - val_loss: 2.3435e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 7s 154us/step - loss: 2.3599e-05 - val_loss: 3.8690e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 6.9267e-05 - val_loss: 2.6946e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2355e-05 - val_loss: 2.2014e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 6.0857e-05 - val_loss: 3.5947e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.4518e-05 - val_loss: 2.2233e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 2.0981e-05 - val_loss: 2.1309e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 4.9097e-05 - val_loss: 3.5772e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.4481e-05 - val_loss: 3.6420e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.1474e-05 - val_loss: 2.2297e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 6.3679e-05 - val_loss: 8.9871e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.7661e-05 - val_loss: 2.0571e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 1.9266e-05 - val_loss: 1.9477e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.9706e-05 - val_loss: 3.0109e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 7.9643e-05 - val_loss: 3.1241e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 2.0750e-05 - val_loss: 1.8878e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.9804e-05 - val_loss: 1.7590e-04\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 4.0143e-05 - val_loss: 1.9024e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.7958e-05 - val_loss: 1.8151e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 8.8581e-05 - val_loss: 3.6140e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.7853e-05 - val_loss: 1.8297e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.7257e-05 - val_loss: 1.7884e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.7889e-05 - val_loss: 2.6388e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.2538e-05 - val_loss: 1.7922e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.4830e-05 - val_loss: 2.6076e-04\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 5.1326e-05 - val_loss: 1.7337e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.6429e-05 - val_loss: 1.6435e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.6531e-05 - val_loss: 3.1286e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 6.5570e-05 - val_loss: 1.7717e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.6026e-05 - val_loss: 1.5873e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 2.3567e-05 - val_loss: 1.4021e-04\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 4.3038e-05 - val_loss: 1.6633e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.5154e-05 - val_loss: 1.5131e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 6.3845e-05 - val_loss: 2.0649e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.7267e-05 - val_loss: 1.5269e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.4618e-05 - val_loss: 1.7515e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.9075e-05 - val_loss: 1.5362e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.3035e-05 - val_loss: 2.8511e-05\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.6851e-05 - val_loss: 1.4725e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 3.2623e-05 - val_loss: 2.2548e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.6298e-05 - val_loss: 1.7467e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.4806e-05 - val_loss: 2.7355e-04\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.9706e-05 - val_loss: 1.5483e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.3978e-05 - val_loss: 1.3749e-05\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.8644e-05 - val_loss: 2.1044e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 3.7610e-05 - val_loss: 1.6882e-05\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.4015e-05 - val_loss: 1.3885e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 5.9786e-05 - val_loss: 4.6208e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.1108e-05 - val_loss: 1.4016e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.2730e-05 - val_loss: 1.3078e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 5.0810e-05 - val_loss: 2.1226e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.7271e-05 - val_loss: 1.3731e-05\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 3.0946e-05 - val_loss: 1.0613e-04\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.2651e-05 - val_loss: 1.3231e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.2034e-05 - val_loss: 1.2060e-05\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 4.2977e-05 - val_loss: 3.9229e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.8392e-05 - val_loss: 1.3183e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.2476e-05 - val_loss: 1.5903e-05\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 3.6270e-05 - val_loss: 1.3628e-05\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 1.2690e-05 - val_loss: 1.4545e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.0862e-05 - val_loss: 8.3514e-05\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.9494e-05 - val_loss: 1.3125e-05\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.1633e-05 - val_loss: 1.1403e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.3226e-05 - val_loss: 6.9619e-05\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 4.1659e-05 - val_loss: 1.2767e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.1182e-05 - val_loss: 1.0974e-05\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.5913e-05 - val_loss: 4.4103e-05\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.9554e-05 - val_loss: 1.1460e-05\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.0433e-05 - val_loss: 1.0619e-05\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 5.1001e-05 - val_loss: 3.5619e-05\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.6642e-05 - val_loss: 1.1286e-05\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.0439e-05 - val_loss: 1.0356e-05\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2383e-05 - val_loss: 1.5955e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.4344e-05 - val_loss: 1.0777e-05\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.3958e-05 - val_loss: 4.9109e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.6784e-05 - val_loss: 1.0477e-05\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.4553e-05 - val_loss: 1.7950e-05\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.3824e-05 - val_loss: 1.2704e-05\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.8703e-05 - val_loss: 1.3506e-05\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.0753e-05 - val_loss: 9.8354e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 2.3283e-05 - val_loss: 1.2532e-04\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 3.8446e-05 - val_loss: 1.1000e-05\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 9.6977e-06 - val_loss: 9.4501e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 9.7046e-06 - val_loss: 1.4745e-05\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2660e-05 - val_loss: 1.6833e-05\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.8625e-05 - val_loss: 8.8181e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 2.4763e-05 - val_loss: 9.9448e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 9.1275e-06 - val_loss: 1.4792e-05\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.7870e-05 - val_loss: 1.5486e-05\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.0203e-05 - val_loss: 8.9571e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.7696e-05 - val_loss: 3.9803e-05\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.3354e-05 - val_loss: 9.4706e-06\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 8.7512e-06 - val_loss: 1.0205e-05\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.3441e-05 - val_loss: 1.3409e-05\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.0386e-05 - val_loss: 8.5850e-06\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 8.5170e-06 - val_loss: 1.1630e-05\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.3801e-05 - val_loss: 1.0345e-05\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.2343e-05 - val_loss: 4.8021e-05\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.8771e-05 - val_loss: 1.0324e-05\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.8265e-05 - val_loss: 7.2727e-05\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.3858e-05 - val_loss: 9.7015e-06\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 8.2032e-06 - val_loss: 7.9798e-06\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 8.0037e-06 - val_loss: 1.0974e-05\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2747e-05 - val_loss: 1.0006e-05\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.3496e-05 - val_loss: 1.2796e-05\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.4662e-05 - val_loss: 3.0341e-05\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.1762e-05 - val_loss: 7.7139e-06\n",
      "Epoch 224/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.4011e-05 - val_loss: 6.7540e-05\n",
      "Epoch 225/1000\n",
      "43200/43200 [==============================] - 6s 147us/step - loss: 2.0638e-05 - val_loss: 8.5186e-06\n",
      "Epoch 226/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.6088e-06 - val_loss: 7.7172e-06\n",
      "Epoch 227/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.1846e-05 - val_loss: 8.6652e-06\n",
      "Epoch 228/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.6749e-06 - val_loss: 7.7728e-06\n",
      "Epoch 229/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 4.6731e-05 - val_loss: 2.3768e-05\n",
      "Epoch 230/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.1447e-05 - val_loss: 7.9738e-06\n",
      "Epoch 231/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.1756e-05 - val_loss: 8.0847e-05\n",
      "Epoch 232/1000\n",
      "43200/43200 [==============================] - 7s 153us/step - loss: 2.2512e-05 - val_loss: 7.9409e-06\n",
      "Epoch 233/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.2713e-06 - val_loss: 7.3199e-06\n",
      "Epoch 234/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2072e-05 - val_loss: 1.3650e-04\n",
      "Epoch 235/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 3.9910e-05 - val_loss: 9.4495e-06\n",
      "Epoch 236/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 7.5200e-06 - val_loss: 7.2794e-06\n",
      "Epoch 237/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 7.3171e-06 - val_loss: 7.5199e-06\n",
      "Epoch 238/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.1412e-06 - val_loss: 7.4716e-06\n",
      "Epoch 239/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.2742e-05 - val_loss: 8.6201e-06\n",
      "Epoch 240/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 9.8696e-06 - val_loss: 7.3173e-06\n",
      "Epoch 241/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.4326e-05 - val_loss: 1.0214e-05\n",
      "Epoch 242/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.7779e-06 - val_loss: 6.8758e-06\n",
      "Epoch 243/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.3631e-05 - val_loss: 4.2302e-05\n",
      "Epoch 244/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.2248e-05 - val_loss: 8.2177e-06\n",
      "Epoch 245/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.7027e-05 - val_loss: 6.1115e-05\n",
      "Epoch 246/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.6678e-05 - val_loss: 6.9184e-06\n",
      "Epoch 247/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 6.4910e-06 - val_loss: 6.4604e-06\n",
      "Epoch 248/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.8902e-05 - val_loss: 8.1236e-06\n",
      "Epoch 249/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 6.6764e-06 - val_loss: 6.4761e-06\n",
      "Epoch 250/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.8239e-05 - val_loss: 1.2964e-05\n",
      "Epoch 251/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 7.7836e-06 - val_loss: 6.4471e-06\n",
      "Epoch 252/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 7.2801e-06 - val_loss: 4.0235e-05\n",
      "Epoch 253/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 2.1093e-05 - val_loss: 7.3573e-06\n",
      "Epoch 254/1000\n",
      "43200/43200 [==============================] - 7s 152us/step - loss: 6.3653e-06 - val_loss: 6.9361e-06\n",
      "Epoch 255/1000\n",
      "43200/43200 [==============================] - 7s 151us/step - loss: 1.5490e-05 - val_loss: 1.1125e-05\n",
      "Epoch 256/1000\n",
      "43200/43200 [==============================] - 6s 148us/step - loss: 1.0289e-05 - val_loss: 4.0826e-05\n",
      "Epoch 257/1000\n",
      "43200/43200 [==============================] - 6s 150us/step - loss: 1.6509e-05 - val_loss: 7.3778e-06\n",
      "Epoch 258/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 8.3532e-06 - val_loss: 3.4062e-05\n",
      "Epoch 259/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 2.2366e-05 - val_loss: 9.0371e-06\n",
      "Epoch 260/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 7.1878e-06 - val_loss: 1.2394e-05\n",
      "Epoch 261/1000\n",
      "43200/43200 [==============================] - 6s 149us/step - loss: 1.4470e-05 - val_loss: 6.6298e-06\n",
      "Epoch 00261: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,6):\n",
    "    numOfLayers = i\n",
    "    filtersCountInFirstLayer = 32\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.312497897747865e-06, 3.279004251529235e-06, 4.797896716960774e-06, 1.5865972576042015e-05, 6.447064947678882e-06]\n",
      "[107, 211, 207, 111, 261]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(modelsLoss)\n",
    "print(modelsEpochs)\n",
    "\n",
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. encoder/decoder depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('encoder/decoder depth')\n",
    "plt.xticks(np.arange(5), [1,2,3,4,5])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('figures_differential/conv_depth_tuning.eps', format='eps', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthParam = modelsLoss.index(min(modelsLoss)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network filter size tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_6 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 290, 32)           96        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 145, 64)           4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 73, 128)           16512     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 73, 128)           32896     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 146, 64)           16448     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 292, 32)           4128      \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 292, 1)            65        \n",
      "_________________________________________________________________\n",
      "cropping1d_6 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 74,305\n",
      "Trainable params: 74,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 89us/step - loss: 0.0594 - val_loss: 0.0296\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0280 - val_loss: 0.0248\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0118 - val_loss: 0.0035\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 0.0011 - val_loss: 9.9347e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 9.1037e-04 - val_loss: 8.2636e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.0939e-04 - val_loss: 6.6529e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.0778e-04 - val_loss: 5.7990e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.5084e-04 - val_loss: 5.2508e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.0914e-04 - val_loss: 4.9781e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.7961e-04 - val_loss: 4.7009e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.4476e-04 - val_loss: 4.2410e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.1254e-04 - val_loss: 4.1418e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.8888e-04 - val_loss: 3.7233e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.5971e-04 - val_loss: 3.6494e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.4496e-04 - val_loss: 3.3751e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.3616e-04 - val_loss: 3.3904e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.2961e-04 - val_loss: 3.1228e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.0354e-04 - val_loss: 3.0308e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.9507e-04 - val_loss: 3.0215e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.9034e-04 - val_loss: 2.8787e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8873e-04 - val_loss: 2.9074e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.7385e-04 - val_loss: 2.8066e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.7132e-04 - val_loss: 2.6547e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.5762e-04 - val_loss: 2.7637e-04\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.6676e-04 - val_loss: 2.5834e-04\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.4971e-04 - val_loss: 2.5444e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.6185e-04 - val_loss: 2.5188e-04\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4549e-04 - val_loss: 2.4970e-04\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.5346e-04 - val_loss: 2.5639e-04\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3755e-04 - val_loss: 2.3687e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.6264e-04 - val_loss: 2.4029e-04\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3385e-04 - val_loss: 2.3726e-04\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.4580e-04 - val_loss: 2.4775e-04\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3106e-04 - val_loss: 2.3018e-04\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3597e-04 - val_loss: 2.2975e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2637e-04 - val_loss: 2.2740e-04\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4663e-04 - val_loss: 2.2999e-04\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2124e-04 - val_loss: 2.4120e-04\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.3414e-04 - val_loss: 2.2272e-04\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2779e-04 - val_loss: 2.5039e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2580e-04 - val_loss: 2.2764e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3360e-04 - val_loss: 2.1921e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2012e-04 - val_loss: 2.2577e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2620e-04 - val_loss: 2.9448e-04\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2176e-04 - val_loss: 2.1973e-04\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1928e-04 - val_loss: 2.1566e-04\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2413e-04 - val_loss: 2.1387e-04\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2616e-04 - val_loss: 2.3455e-04\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1745e-04 - val_loss: 2.1248e-04\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1751e-04 - val_loss: 2.1104e-04\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3190e-04 - val_loss: 2.4226e-04\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1101e-04 - val_loss: 2.1344e-04\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0831e-04 - val_loss: 2.3887e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1790e-04 - val_loss: 2.1646e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1163e-04 - val_loss: 2.5411e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2590e-04 - val_loss: 2.0946e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1317e-04 - val_loss: 2.9731e-04\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1529e-04 - val_loss: 2.0709e-04\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1083e-04 - val_loss: 2.1004e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0943e-04 - val_loss: 2.3465e-04\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1334e-04 - val_loss: 2.0830e-04\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1058e-04 - val_loss: 2.3649e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2023e-04 - val_loss: 2.3116e-04\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0219e-04 - val_loss: 2.0370e-04\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1790e-04 - val_loss: 2.2282e-04\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0298e-04 - val_loss: 2.0325e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0866e-04 - val_loss: 2.0265e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1060e-04 - val_loss: 2.0650e-04\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0262e-04 - val_loss: 2.9192e-04\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2388e-04 - val_loss: 2.0053e-04\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9613e-04 - val_loss: 2.0145e-04\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0211e-04 - val_loss: 2.1761e-04\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0623e-04 - val_loss: 2.0387e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1448e-04 - val_loss: 3.1306e-04\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1189e-04 - val_loss: 2.0214e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9459e-04 - val_loss: 1.9780e-04\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0314e-04 - val_loss: 1.9677e-04\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1391e-04 - val_loss: 2.2901e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9792e-04 - val_loss: 1.9962e-04\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9445e-04 - val_loss: 2.1108e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0230e-04 - val_loss: 2.6667e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0641e-04 - val_loss: 1.9509e-04\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9961e-04 - val_loss: 3.8208e-04\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.2025e-04 - val_loss: 1.9482e-04\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9038e-04 - val_loss: 1.9374e-04\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0715e-04 - val_loss: 1.9442e-04\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8935e-04 - val_loss: 1.9581e-04\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0854e-04 - val_loss: 1.9241e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9015e-04 - val_loss: 1.9487e-04\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0626e-04 - val_loss: 2.1226e-04\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9345e-04 - val_loss: 2.1622e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0426e-04 - val_loss: 1.9255e-04\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9200e-04 - val_loss: 2.1022e-04\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0515e-04 - val_loss: 1.9112e-04\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0272e-04 - val_loss: 1.9763e-04\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9111e-04 - val_loss: 1.9027e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0245e-04 - val_loss: 2.1769e-04\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9117e-04 - val_loss: 1.8921e-04\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0116e-04 - val_loss: 2.0024e-04\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9136e-04 - val_loss: 1.9078e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9537e-04 - val_loss: 2.0562e-04\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9008e-04 - val_loss: 2.3387e-04\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1184e-04 - val_loss: 1.8744e-04\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8504e-04 - val_loss: 1.8763e-04\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0624e-04 - val_loss: 1.9343e-04\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8433e-04 - val_loss: 1.8705e-04\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0878e-04 - val_loss: 1.8826e-04\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8360e-04 - val_loss: 1.8787e-04\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8883e-04 - val_loss: 1.9011e-04\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1007e-04 - val_loss: 2.2352e-04\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8665e-04 - val_loss: 1.8557e-04\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8209e-04 - val_loss: 1.8527e-04\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.1215e-04 - val_loss: 1.9170e-04\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8566e-04 - val_loss: 1.8533e-04\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8384e-04 - val_loss: 1.9914e-04\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9421e-04 - val_loss: 2.1175e-04\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.8938e-04 - val_loss: 1.9254e-04\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.9020e-04 - val_loss: 2.0814e-04\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.9070e-04 - val_loss: 1.8372e-04\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.0851e-04 - val_loss: 2.3731e-04\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8903e-04 - val_loss: 1.8348e-04\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8746e-04 - val_loss: 1.8592e-04\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8039e-04 - val_loss: 1.8334e-04\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0990e-04 - val_loss: 2.2094e-04\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8716e-04 - val_loss: 1.8312e-04\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7995e-04 - val_loss: 1.8291e-04\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9612e-04 - val_loss: 1.8978e-04\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.8078e-04 - val_loss: 1.8168e-04\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9085e-04 - val_loss: 2.5551e-04\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8755e-04 - val_loss: 1.8155e-04\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8925e-04 - val_loss: 2.0014e-04\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8270e-04 - val_loss: 1.8379e-04\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9961e-04 - val_loss: 1.8494e-04\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7942e-04 - val_loss: 1.8099e-04\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8477e-04 - val_loss: 2.2801e-04\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.9597e-04 - val_loss: 1.8144e-04\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.8525e-04 - val_loss: 1.8713e-04\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.8180e-04 - val_loss: 1.9256e-04\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.9314e-04 - val_loss: 1.8451e-04\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.8095e-04 - val_loss: 1.8417e-04\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9983e-04 - val_loss: 1.9093e-04\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.8067e-04 - val_loss: 1.7944e-04\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7831e-04 - val_loss: 1.8042e-04\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8892e-04 - val_loss: 2.3213e-04\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8571e-04 - val_loss: 1.8232e-04\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8207e-04 - val_loss: 2.1347e-04\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8654e-04 - val_loss: 1.8059e-04\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8700e-04 - val_loss: 1.8740e-04\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8282e-04 - val_loss: 2.6648e-04\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.9535e-04 - val_loss: 1.8050e-04\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7645e-04 - val_loss: 1.7885e-04\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9251e-04 - val_loss: 1.8540e-04\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7671e-04 - val_loss: 1.7995e-04\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.9412e-04 - val_loss: 1.7880e-04\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7616e-04 - val_loss: 1.8097e-04\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8176e-04 - val_loss: 1.9218e-04\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8328e-04 - val_loss: 2.9141e-04\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.0136e-04 - val_loss: 1.8022e-04\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7519e-04 - val_loss: 1.7798e-04\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7882e-04 - val_loss: 1.8082e-04\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8198e-04 - val_loss: 1.8094e-04\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8506e-04 - val_loss: 1.8036e-04\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8886e-04 - val_loss: 1.8855e-04\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7779e-04 - val_loss: 1.7664e-04\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.7921e-04 - val_loss: 2.2081e-04\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.8315e-04 - val_loss: 1.7687e-04\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.9444e-04 - val_loss: 1.9061e-04\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7697e-04 - val_loss: 1.8012e-04\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7649e-04 - val_loss: 1.7779e-04\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8169e-04 - val_loss: 1.8777e-04\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8154e-04 - val_loss: 1.7700e-04\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.8892e-04 - val_loss: 1.9842e-04\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7649e-04 - val_loss: 1.7604e-04\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7805e-04 - val_loss: 2.0152e-04\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.8316e-04 - val_loss: 1.7831e-04\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.8696e-04 - val_loss: 1.8207e-04\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.7643e-04 - val_loss: 1.7725e-04\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7692e-04 - val_loss: 1.7821e-04\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8642e-04 - val_loss: 1.7632e-04\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7653e-04 - val_loss: 1.8029e-04\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8117e-04 - val_loss: 1.8066e-04\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8103e-04 - val_loss: 1.9483e-04\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.7703e-04 - val_loss: 1.8271e-04\n",
      "Epoch 00188: early stopping\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_7 (ZeroPaddin (None, 290, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 290, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 145, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 145, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 73, 128)           24704     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 73, 128)           49280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_18 (UpSampling (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 146, 64)           24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_19 (UpSampling (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 292, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 292, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_7 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 111,233\n",
      "Trainable params: 111,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0543 - val_loss: 0.0292\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0281 - val_loss: 0.0241\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.9563e-04 - val_loss: 9.8367e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 0.0010 - val_loss: 9.6177e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.4845e-04 - val_loss: 9.2159e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.0986e-04 - val_loss: 8.5877e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.3051e-04 - val_loss: 7.6511e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.8412e-04 - val_loss: 4.2670e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.4526e-04 - val_loss: 2.4789e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.9428e-04 - val_loss: 1.4556e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2693e-04 - val_loss: 1.1237e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.3321e-05 - val_loss: 6.0145e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.0792e-05 - val_loss: 6.6833e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.4177e-05 - val_loss: 1.4981e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.8714e-05 - val_loss: 4.2280e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.8661e-05 - val_loss: 4.3622e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.6676e-05 - val_loss: 3.7650e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.3055e-05 - val_loss: 3.2799e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.8507e-05 - val_loss: 4.0299e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.0197e-05 - val_loss: 2.8993e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.0479e-05 - val_loss: 1.4940e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.0982e-05 - val_loss: 2.7409e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.5436e-05 - val_loss: 2.5196e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.1178e-05 - val_loss: 2.7819e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.6667e-05 - val_loss: 2.3631e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.7978e-05 - val_loss: 1.0453e-04\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.4439e-05 - val_loss: 2.2077e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.5769e-05 - val_loss: 2.2362e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.6712e-05 - val_loss: 2.1108e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.8435e-05 - val_loss: 2.1489e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3067e-05 - val_loss: 2.1644e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.3663e-05 - val_loss: 2.7541e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.0285e-05 - val_loss: 2.0188e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 6.1081e-05 - val_loss: 1.9522e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.8487e-05 - val_loss: 1.7473e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.7388e-05 - val_loss: 2.5271e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.3947e-05 - val_loss: 2.0165e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.1558e-05 - val_loss: 1.1886e-04\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.8450e-05 - val_loss: 1.5897e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.6200e-05 - val_loss: 2.3733e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.5683e-05 - val_loss: 1.7738e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7649e-05 - val_loss: 8.4040e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.7348e-05 - val_loss: 1.4914e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.4041e-05 - val_loss: 1.4156e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.5233e-05 - val_loss: 2.6036e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.6224e-05 - val_loss: 1.3962e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.2988e-05 - val_loss: 1.3248e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 7.5890e-05 - val_loss: 5.4211e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.8220e-05 - val_loss: 1.3353e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2412e-05 - val_loss: 1.2574e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 1.2082e-05 - val_loss: 1.2696e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.3626e-05 - val_loss: 1.5001e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.2895e-05 - val_loss: 1.2579e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.4338e-05 - val_loss: 1.4694e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.7541e-05 - val_loss: 1.1806e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.1219e-05 - val_loss: 1.1356e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.4700e-05 - val_loss: 1.2970e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.3678e-05 - val_loss: 1.2097e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.3694e-05 - val_loss: 1.8105e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.2336e-05 - val_loss: 1.6174e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.0801e-05 - val_loss: 1.1006e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7246e-05 - val_loss: 1.6181e-04\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.8697e-05 - val_loss: 1.3181e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.0522e-05 - val_loss: 1.0943e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.1771e-05 - val_loss: 1.7075e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0802e-05 - val_loss: 1.1078e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.8283e-05 - val_loss: 1.3272e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0004e-05 - val_loss: 9.4503e-06\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.8966e-05 - val_loss: 2.8214e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1804e-05 - val_loss: 9.4035e-06\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 8.9796e-06 - val_loss: 9.0168e-06\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2775e-05 - val_loss: 3.8517e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 6.7943e-05 - val_loss: 9.6527e-06\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 9.2820e-06 - val_loss: 8.9070e-06\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.3469e-06 - val_loss: 8.5878e-06\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 8.1944e-06 - val_loss: 8.5465e-06\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.0464e-05 - val_loss: 2.1884e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0435e-05 - val_loss: 8.3775e-06\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.2555e-05 - val_loss: 3.2560e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2980e-05 - val_loss: 8.3530e-06\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.6928e-06 - val_loss: 7.9435e-06\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.3440e-05 - val_loss: 2.2241e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0117e-05 - val_loss: 7.8319e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.3830e-06 - val_loss: 7.6874e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.0378e-05 - val_loss: 2.3848e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.2203e-05 - val_loss: 8.3747e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 7.2669e-06 - val_loss: 7.4786e-06\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.7001e-05 - val_loss: 8.8826e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 8.9507e-06 - val_loss: 7.3003e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.1296e-05 - val_loss: 3.6332e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.5129e-05 - val_loss: 7.2484e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.0148e-06 - val_loss: 3.0039e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6353e-05 - val_loss: 9.0418e-06\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6862e-05 - val_loss: 1.4378e-04\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8683e-05 - val_loss: 7.6824e-06\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.7656e-06 - val_loss: 6.8625e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8750e-05 - val_loss: 1.5997e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.2919e-06 - val_loss: 6.9804e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.6131e-05 - val_loss: 1.5441e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.0423e-06 - val_loss: 6.8428e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.1135e-06 - val_loss: 6.6017e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.3484e-05 - val_loss: 7.3676e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.1812e-06 - val_loss: 6.1688e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 2.8672e-05 - val_loss: 6.9094e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.5891e-05 - val_loss: 6.3689e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.8927e-06 - val_loss: 5.9448e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.5258e-05 - val_loss: 1.2641e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 9.0626e-06 - val_loss: 5.9011e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.9389e-06 - val_loss: 9.6475e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.8992e-05 - val_loss: 1.0392e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.6656e-06 - val_loss: 9.3961e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.5988e-05 - val_loss: 1.0345e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 7.3276e-06 - val_loss: 2.5449e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.5352e-05 - val_loss: 7.5376e-06\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.6462e-06 - val_loss: 2.6822e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.4892e-05 - val_loss: 6.6138e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.7355e-06 - val_loss: 5.4194e-06\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 1.8349e-05 - val_loss: 1.9693e-04\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.3026e-05 - val_loss: 6.1610e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.3323e-06 - val_loss: 5.1718e-06\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.1853e-06 - val_loss: 9.1189e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 2.2618e-05 - val_loss: 7.7413e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.2289e-05 - val_loss: 3.9051e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0278e-05 - val_loss: 9.7807e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6627e-05 - val_loss: 9.8584e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.5809e-06 - val_loss: 5.2367e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.4657e-05 - val_loss: 8.0248e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.3743e-06 - val_loss: 5.0570e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.5984e-06 - val_loss: 4.7421e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.5150e-05 - val_loss: 1.0810e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.1390e-06 - val_loss: 4.9324e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 4.4679e-06 - val_loss: 4.5503e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.6079e-06 - val_loss: 1.1357e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.5255e-05 - val_loss: 7.9263e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.9408e-06 - val_loss: 4.4704e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.5729e-06 - val_loss: 1.1500e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.4782e-05 - val_loss: 5.9728e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 4.4814e-06 - val_loss: 4.7517e-06\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 50us/step - loss: 3.4497e-05 - val_loss: 8.1990e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.3144e-06 - val_loss: 4.3996e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.4406e-06 - val_loss: 1.7770e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.5527e-05 - val_loss: 5.5425e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6867e-05 - val_loss: 3.4982e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0917e-05 - val_loss: 4.7796e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.1299e-06 - val_loss: 4.8532e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.4935e-05 - val_loss: 6.1387e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.8158e-06 - val_loss: 4.2215e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.4063e-06 - val_loss: 1.4973e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.8184e-05 - val_loss: 7.0673e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.4132e-06 - val_loss: 3.9586e-06\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.8028e-06 - val_loss: 4.5723e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.8805e-05 - val_loss: 4.4408e-06\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.2795e-06 - val_loss: 5.3197e-06\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.8562e-05 - val_loss: 5.4505e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 1.0659e-05 - val_loss: 1.1023e-04\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3938e-05 - val_loss: 4.4280e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 3.7691e-06 - val_loss: 3.7683e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 9.1060e-06 - val_loss: 4.9297e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2828e-05 - val_loss: 4.8859e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.5599e-05 - val_loss: 1.1754e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.8984e-06 - val_loss: 4.3759e-06\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3920e-05 - val_loss: 4.8540e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.2043e-06 - val_loss: 3.7702e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 51us/step - loss: 5.9499e-06 - val_loss: 4.4546e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7656e-05 - val_loss: 4.1457e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.4673e-06 - val_loss: 2.4604e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.5656e-05 - val_loss: 4.2107e-06\n",
      "Epoch 00173: early stopping\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_8 (ZeroPaddin (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 292, 32)           160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 146, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 146, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 73, 128)           32896     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 73, 128)           65664     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 146, 64)           32832     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_21 (UpSampling (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 292, 32)           8224      \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 292, 1)            129       \n",
      "_________________________________________________________________\n",
      "cropping1d_8 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 148,161\n",
      "Trainable params: 148,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 104us/step - loss: 0.0562 - val_loss: 0.0295\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0285 - val_loss: 0.0263\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 0.0105 - val_loss: 0.0028\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 0.0011 - val_loss: 9.9867e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 9.4785e-04 - val_loss: 8.4568e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 7.8819e-04 - val_loss: 8.7816e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.7213e-04 - val_loss: 5.9261e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 5.3371e-04 - val_loss: 4.8393e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 4.3608e-04 - val_loss: 3.7661e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 3.9147e-04 - val_loss: 2.9388e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 2.4450e-04 - val_loss: 2.0564e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 1.9687e-04 - val_loss: 1.8278e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.4902e-04 - val_loss: 1.2049e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.1812e-04 - val_loss: 1.1544e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.5313e-04 - val_loss: 8.6632e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.0234e-05 - val_loss: 7.4260e-05\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 62us/step - loss: 7.1245e-05 - val_loss: 1.0504e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.2968e-05 - val_loss: 6.0555e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 6.3152e-05 - val_loss: 1.7386e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 1.1577e-04 - val_loss: 5.3648e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 5.0120e-05 - val_loss: 4.8648e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.6944e-05 - val_loss: 4.6208e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.2236e-04 - val_loss: 6.1629e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 5.4680e-05 - val_loss: 4.3360e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.0806e-05 - val_loss: 4.0248e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.8899e-05 - val_loss: 3.8907e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.9855e-05 - val_loss: 6.8603e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 4.0367e-05 - val_loss: 3.6093e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.3970e-05 - val_loss: 7.8642e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 3.9856e-05 - val_loss: 3.4176e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 3.2752e-05 - val_loss: 3.2767e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 9.1446e-05 - val_loss: 3.6105e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 3.3763e-05 - val_loss: 3.1392e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.0096e-05 - val_loss: 3.0110e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 9.1099e-05 - val_loss: 5.9118e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 3.4067e-05 - val_loss: 2.9553e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 2.8331e-05 - val_loss: 2.8459e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 7.0068e-05 - val_loss: 8.2741e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 3.6752e-05 - val_loss: 2.9303e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 2.6527e-05 - val_loss: 2.9601e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.2941e-05 - val_loss: 2.8136e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.6096e-05 - val_loss: 2.5313e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.2500e-05 - val_loss: 5.1214e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.9341e-05 - val_loss: 2.4528e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.4012e-05 - val_loss: 2.4346e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.0776e-04 - val_loss: 2.9866e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.5824e-05 - val_loss: 2.3491e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.2393e-05 - val_loss: 2.2664e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.7930e-05 - val_loss: 2.7319e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.7139e-05 - val_loss: 2.3632e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 6.2179e-05 - val_loss: 2.5328e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.2131e-05 - val_loss: 2.1221e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 7.9503e-05 - val_loss: 4.6623e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.4325e-05 - val_loss: 2.1213e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9999e-05 - val_loss: 2.0384e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.5741e-05 - val_loss: 3.0595e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2106e-05 - val_loss: 2.0293e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9047e-05 - val_loss: 1.9340e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.6323e-05 - val_loss: 3.6639e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2727e-05 - val_loss: 1.8852e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.8603e-05 - val_loss: 2.2211e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.0486e-05 - val_loss: 2.0347e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9239e-05 - val_loss: 1.8322e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.9669e-05 - val_loss: 2.4248e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.3382e-05 - val_loss: 1.8813e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.7330e-05 - val_loss: 1.7396e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.6756e-05 - val_loss: 5.9135e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.4774e-05 - val_loss: 1.7651e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.6473e-05 - val_loss: 1.6902e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.7058e-05 - val_loss: 2.8106e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.2435e-05 - val_loss: 2.4402e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.7009e-05 - val_loss: 1.6093e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.0755e-05 - val_loss: 1.8505e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.7236e-05 - val_loss: 1.7874e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.7109e-05 - val_loss: 3.8286e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 5.4199e-05 - val_loss: 1.8673e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.5792e-05 - val_loss: 2.3839e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 8.6945e-05 - val_loss: 1.7080e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.7915e-05 - val_loss: 1.4939e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.4355e-05 - val_loss: 1.4615e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 9.7696e-05 - val_loss: 2.0945e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.8597e-05 - val_loss: 1.4684e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.3903e-05 - val_loss: 1.4135e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.3920e-05 - val_loss: 1.6935e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 7.1163e-05 - val_loss: 2.6326e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.5102e-05 - val_loss: 1.3729e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.4300e-05 - val_loss: 3.1257e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.3765e-05 - val_loss: 1.4864e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.3985e-05 - val_loss: 1.3637e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.5994e-05 - val_loss: 2.2355e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.6733e-05 - val_loss: 1.3199e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.2654e-05 - val_loss: 1.3070e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 6.5645e-05 - val_loss: 2.6919e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.8639e-05 - val_loss: 1.2971e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.2366e-05 - val_loss: 1.4163e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.2260e-05 - val_loss: 1.7597e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.3646e-05 - val_loss: 1.2531e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.8495e-05 - val_loss: 2.6137e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.4288e-05 - val_loss: 1.2198e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.1563e-05 - val_loss: 1.3075e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 5.9625e-05 - val_loss: 2.3093e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.3160e-05 - val_loss: 1.1679e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 2.4877e-05 - val_loss: 1.7167e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 3.2500e-05 - val_loss: 1.3579e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.2981e-05 - val_loss: 3.7207e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.9520e-05 - val_loss: 1.3688e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.1606e-05 - val_loss: 1.1374e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.4150e-05 - val_loss: 3.3188e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 1.4312e-05 - val_loss: 1.0959e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.2229e-05 - val_loss: 5.9778e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.2856e-05 - val_loss: 1.4729e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.1051e-05 - val_loss: 1.0476e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.0091e-05 - val_loss: 1.2250e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.6257e-05 - val_loss: 3.0650e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.4608e-05 - val_loss: 1.0579e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.8923e-06 - val_loss: 1.0025e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.2239e-05 - val_loss: 2.8032e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.1516e-05 - val_loss: 1.1164e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.7223e-06 - val_loss: 9.7456e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.1763e-05 - val_loss: 1.9355e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.0961e-05 - val_loss: 1.0676e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.6849e-06 - val_loss: 9.8574e-06\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.5134e-05 - val_loss: 1.7876e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.4316e-05 - val_loss: 9.7249e-06\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.4746e-06 - val_loss: 1.5610e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.6353e-05 - val_loss: 9.7142e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.0970e-05 - val_loss: 3.4981e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.3294e-05 - val_loss: 1.2551e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.4465e-05 - val_loss: 6.2420e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.5208e-05 - val_loss: 9.0619e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 5.4023e-05 - val_loss: 7.9437e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 2.1300e-05 - val_loss: 9.4801e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 8.3860e-06 - val_loss: 8.5021e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 8.1385e-06 - val_loss: 8.4055e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.1893e-05 - val_loss: 6.6144e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.8094e-05 - val_loss: 9.3580e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 8.1174e-06 - val_loss: 8.1830e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 7.8172e-06 - val_loss: 8.0040e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 5.0822e-05 - val_loss: 5.2975e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.3564e-05 - val_loss: 7.9999e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.6925e-06 - val_loss: 8.0559e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.6957e-06 - val_loss: 1.2302e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 3.2571e-05 - val_loss: 1.0178e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 7.9072e-06 - val_loss: 9.8539e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 4.2690e-05 - val_loss: 9.6752e-06\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 8.4642e-06 - val_loss: 7.5366e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 7.2174e-06 - val_loss: 1.3878e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 5.7787e-05 - val_loss: 1.5199e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 8.0803e-06 - val_loss: 7.2243e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.8998e-06 - val_loss: 7.2656e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.1178e-05 - val_loss: 9.7191e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.8814e-05 - val_loss: 7.7635e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.9725e-06 - val_loss: 6.9370e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.5862e-05 - val_loss: 1.1433e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.9488e-05 - val_loss: 7.6748e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.7018e-06 - val_loss: 6.7185e-06\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.0875e-05 - val_loss: 4.6062e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.1154e-05 - val_loss: 7.4496e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.3948e-06 - val_loss: 6.6915e-06\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.9878e-05 - val_loss: 1.2932e-05\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 8.6393e-06 - val_loss: 6.6623e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.3939e-06 - val_loss: 8.2833e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.4957e-05 - val_loss: 1.0519e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 7.1778e-06 - val_loss: 6.6444e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 2.8307e-05 - val_loss: 2.3808e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.7320e-05 - val_loss: 6.7299e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 6.0853e-06 - val_loss: 6.2018e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 2.8724e-05 - val_loss: 4.6763e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.4436e-05 - val_loss: 6.7720e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.8584e-06 - val_loss: 6.0226e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 2.4439e-05 - val_loss: 9.6670e-06\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 8.1545e-06 - val_loss: 5.7899e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 3.1136e-05 - val_loss: 6.5161e-05\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.9181e-05 - val_loss: 6.3921e-06\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.7238e-06 - val_loss: 5.6967e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 2.5667e-05 - val_loss: 1.8397e-05\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 7.4358e-06 - val_loss: 5.8934e-06\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 5.3664e-06 - val_loss: 6.1906e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 5.5807e-05 - val_loss: 1.4098e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.2389e-06 - val_loss: 5.5800e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 5.2283e-06 - val_loss: 5.3995e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.1868e-06 - val_loss: 6.8481e-06\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.5304e-05 - val_loss: 1.0716e-05\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.5968e-05 - val_loss: 9.4676e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 9.0856e-06 - val_loss: 3.3808e-05\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 2.0730e-05 - val_loss: 6.5578e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 6.7527e-06 - val_loss: 2.9270e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.4237e-05 - val_loss: 5.3587e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 5.3894e-06 - val_loss: 1.0854e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 2.2415e-05 - val_loss: 6.4982e-06\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.5903e-05 - val_loss: 1.3384e-05\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 7.9377e-06 - val_loss: 5.1939e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.9218e-05 - val_loss: 1.3778e-05\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.8579e-06 - val_loss: 4.9239e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 2.6125e-05 - val_loss: 2.1636e-05\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 7.9573e-06 - val_loss: 5.4195e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.4129e-05 - val_loss: 1.2006e-05\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 7.0461e-06 - val_loss: 5.7663e-06\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.7249e-05 - val_loss: 6.6016e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 7.2030e-06 - val_loss: 3.1846e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.8952e-05 - val_loss: 5.2430e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.5174e-05 - val_loss: 1.7793e-05\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.2410e-06 - val_loss: 4.7855e-06\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 2.3226e-05 - val_loss: 9.6785e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 5.9047e-06 - val_loss: 4.3974e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 1.6477e-05 - val_loss: 1.1775e-05\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 6.3635e-06 - val_loss: 4.4314e-06\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 2.7529e-0 - 3s 63us/step - loss: 2.7518e-05 - val_loss: 2.2164e-05\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.2470e-05 - val_loss: 4.8238e-06\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 4.2082e-06 - val_loss: 4.4993e-06\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.4722e-05 - val_loss: 5.6869e-06\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 5.1702e-06 - val_loss: 4.0080e-06\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 3.2225e-05 - val_loss: 3.1441e-05\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.2643e-06 - val_loss: 4.1886e-06\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.8350e-06 - val_loss: 3.9226e-06\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 3.9539e-06 - val_loss: 4.6026e-06\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.5438e-05 - val_loss: 8.1906e-06\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.6222e-06 - val_loss: 3.9717e-06\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 4.2680e-06 - val_loss: 1.7606e-05\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.1342e-05 - val_loss: 5.4285e-06\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.0595e-06 - val_loss: 3.7603e-06\n",
      "Epoch 224/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.4700e-05 - val_loss: 1.1052e-04\n",
      "Epoch 225/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.2795e-05 - val_loss: 4.1490e-06\n",
      "Epoch 226/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 3.7376e-06 - val_loss: 3.6609e-06\n",
      "Epoch 227/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 3.4914e-06 - val_loss: 3.7603e-06\n",
      "Epoch 228/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 2.5555e-05 - val_loss: 1.1159e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 4.9862e-06 - val_loss: 3.7307e-06\n",
      "Epoch 230/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 3.4471e-06 - val_loss: 3.8848e-06\n",
      "Epoch 231/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.1469e-05 - val_loss: 8.1726e-06\n",
      "Epoch 232/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 6.4329e-06 - val_loss: 2.8805e-05\n",
      "Epoch 233/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.5616e-05 - val_loss: 5.0173e-06\n",
      "Epoch 234/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.1203e-06 - val_loss: 2.6417e-05\n",
      "Epoch 235/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 6.8343e-06 - val_loss: 4.5741e-06\n",
      "Epoch 236/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.5971e-05 - val_loss: 9.4010e-06\n",
      "Epoch 00236: early stopping\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_9 (ZeroPaddin (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 292, 32)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 146, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 146, 64)           10304     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 73, 128)           41088     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 73, 128)           82048     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_22 (UpSampling (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 146, 64)           41024     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_23 (UpSampling (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 292, 32)           10272     \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 292, 1)            161       \n",
      "_________________________________________________________________\n",
      "cropping1d_9 (Cropping1D)    (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 185,089\n",
      "Trainable params: 185,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 0.0430 - val_loss: 0.0287\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 0.0182 - val_loss: 0.0034\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 9.7478e-04 - val_loss: 9.1664e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 8.3295e-04 - val_loss: 7.2949e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.3328e-04 - val_loss: 5.7081e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.0997e-04 - val_loss: 2.9633e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.3127e-04 - val_loss: 4.6772e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 1.6079e-04 - val_loss: 9.9390e-05\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.3313e-05 - val_loss: 7.2175e-05\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.3974e-05 - val_loss: 6.2020e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 5.7553e-05 - val_loss: 5.4442e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 6.9164e-05 - val_loss: 6.3893e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.3422e-05 - val_loss: 6.0599e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.8188e-05 - val_loss: 4.7840e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.9187e-05 - val_loss: 4.1855e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.0458e-05 - val_loss: 1.6079e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.3409e-05 - val_loss: 3.9702e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 6.8157e-05 - val_loss: 1.1387e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 4.6208e-05 - val_loss: 3.5463e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 3.4179e-05 - val_loss: 9.3175e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.6284e-05 - val_loss: 3.7385e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.1364e-05 - val_loss: 3.0542e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.0914e-05 - val_loss: 3.7456e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 4.3864e-05 - val_loss: 3.1431e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 2.9391e-05 - val_loss: 7.3390e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.1251e-04 - val_loss: 2.8796e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 2.6787e-05 - val_loss: 2.6046e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 58us/step - loss: 2.5504e-05 - val_loss: 3.7541e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.4880e-05 - val_loss: 2.7944e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.0095e-05 - val_loss: 3.4774e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.5239e-05 - val_loss: 2.5700e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.2164e-05 - val_loss: 1.9284e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.2995e-05 - val_loss: 2.2310e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.1221e-05 - val_loss: 2.2547e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.7369e-05 - val_loss: 2.4588e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.8079e-05 - val_loss: 1.9680e-04\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.4167e-05 - val_loss: 2.3644e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 2.3880e-0 - 3s 59us/step - loss: 2.4147e-05 - val_loss: 1.0500e-04\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.8686e-05 - val_loss: 2.1658e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.3614e-05 - val_loss: 5.9399e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.0882e-05 - val_loss: 1.9958e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 4.4193e-05 - val_loss: 3.0174e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 4.5544e-05 - val_loss: 1.2902e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.0815e-05 - val_loss: 1.6529e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 6.2361e-05 - val_loss: 2.8547e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.8789e-05 - val_loss: 2.0006e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.3097e-05 - val_loss: 2.4216e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.8248e-05 - val_loss: 9.8554e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.7509e-05 - val_loss: 2.1084e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 4.9808e-05 - val_loss: 7.9225e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.4719e-05 - val_loss: 1.5840e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 6.1489e-05 - val_loss: 1.4966e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.7666e-05 - val_loss: 1.4142e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 5.4321e-05 - val_loss: 3.4981e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.6996e-05 - val_loss: 1.3335e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.8840e-05 - val_loss: 1.8708e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.6288e-05 - val_loss: 1.3183e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.2205e-05 - val_loss: 1.6995e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 8.2605e-05 - val_loss: 2.4393e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3299e-05 - val_loss: 1.1802e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.5804e-05 - val_loss: 2.6465e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.7656e-05 - val_loss: 1.1285e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.4471e-05 - val_loss: 4.4041e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.1905e-05 - val_loss: 1.1221e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 5.1498e-05 - val_loss: 3.1909e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9968e-05 - val_loss: 1.1687e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 4.5924e-05 - val_loss: 2.2629e-04\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.5110e-05 - val_loss: 1.0388e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.8534e-06 - val_loss: 9.6622e-06\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.9028e-05 - val_loss: 2.0144e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.4470e-05 - val_loss: 1.0017e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 2.2945e-05 - val_loss: 1.4781e-04\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.3838e-05 - val_loss: 1.1106e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.3816e-05 - val_loss: 7.8552e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 2.3933e-05 - val_loss: 9.1050e-06\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.0130e-05 - val_loss: 4.0451e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.9782e-05 - val_loss: 1.0178e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.2164e-05 - val_loss: 3.8444e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.1060e-05 - val_loss: 9.6227e-06\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.5197e-05 - val_loss: 9.7245e-06\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.9091e-05 - val_loss: 1.4133e-04\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 4.3924e-05 - val_loss: 1.0086e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 7.6286e-06 - val_loss: 7.5334e-06\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0434e-04 - val_loss: 1.4846e-04\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.9202e-05 - val_loss: 9.4524e-06\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 7.8040e-06 - val_loss: 7.5691e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.1218e-06 - val_loss: 7.3151e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.7145e-05 - val_loss: 7.9917e-06\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0728e-05 - val_loss: 7.6638e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.1560e-05 - val_loss: 2.3181e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.3367e-05 - val_loss: 6.8249e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.0916e-05 - val_loss: 2.6442e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 9.2022e-06 - val_loss: 8.6195e-06\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.1704e-05 - val_loss: 9.3292e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.4820e-06 - val_loss: 7.3072e-06\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.1814e-05 - val_loss: 1.3702e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.3510e-06 - val_loss: 1.5275e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.0979e-05 - val_loss: 1.0148e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.6524e-06 - val_loss: 7.2553e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.3011e-05 - val_loss: 1.2451e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.5363e-06 - val_loss: 6.1873e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.7663e-05 - val_loss: 1.2542e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2808e-05 - val_loss: 6.1954e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 60us/step - loss: 5.6450e-06 - val_loss: 5.6497e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.3813e-06 - val_loss: 5.7346e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 4.7219e-05 - val_loss: 2.2522e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 8.5457e-06 - val_loss: 5.7051e-06\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 6.6544e-06 - val_loss: 3.0334e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.8769e-05 - val_loss: 7.3208e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.5183e-06 - val_loss: 6.1062e-06\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 5.7629e-05 - val_loss: 1.6908e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 6.7862e-06 - val_loss: 5.1859e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.9942e-06 - val_loss: 5.8175e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.5341e-05 - val_loss: 1.5485e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 58us/step - loss: 7.9037e-06 - val_loss: 2.1444e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.4157e-05 - val_loss: 6.8768e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.6979e-05 - val_loss: 1.9867e-04\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.8564e-05 - val_loss: 6.4844e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.1485e-06 - val_loss: 4.8128e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 3.3205e-05 - val_loss: 2.7532e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 59us/step - loss: 1.0247e-05 - val_loss: 4.8112e-06\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.6149e-06 - val_loss: 5.1539e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.8315e-05 - val_loss: 1.5983e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 5.9151e-06 - val_loss: 4.3819e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 4.4996e-05 - val_loss: 5.9786e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.6894e-05 - val_loss: 5.1906e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 4.3143e-06 - val_loss: 4.2930e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.2393e-05 - val_loss: 2.4169e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 6.6470e-06 - val_loss: 4.1864e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.1604e-05 - val_loss: 1.2155e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.7423e-05 - val_loss: 5.2075e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 4.1197e-06 - val_loss: 4.0232e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 2.8727e-05 - val_loss: 4.5250e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 1.2203e-05 - val_loss: 4.5788e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 3.9557e-06 - val_loss: 4.3114e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.9117e-05 - val_loss: 6.7552e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 5.4385e-06 - val_loss: 6.9435e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.8406e-05 - val_loss: 7.2555e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 1.2759e-05 - val_loss: 9.9802e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 2.4011e-05 - val_loss: 5.4070e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 54us/step - loss: 4.3632e-06 - val_loss: 1.2144e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 55us/step - loss: 3.6993e-05 - val_loss: 6.4348e-06\n",
      "Epoch 00145: early stopping\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_10 (ZeroPaddi (None, 294, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 294, 32)           224       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 147, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 147, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 74, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 74, 128)           49280     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 74, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_24 (UpSampling (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 148, 64)           49216     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_25 (UpSampling (None, 296, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 296, 32)           12320     \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 296, 1)            193       \n",
      "_________________________________________________________________\n",
      "cropping1d_10 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 222,017\n",
      "Trainable params: 222,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 109us/step - loss: 0.0495 - val_loss: 0.0287\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 0.0179 - val_loss: 0.0039\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 80us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 80us/step - loss: 0.0010 - val_loss: 9.4582e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 4s 83us/step - loss: 8.3999e-04 - val_loss: 7.1754e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 4s 89us/step - loss: 6.3948e-04 - val_loss: 5.8572e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 80us/step - loss: 5.1496e-04 - val_loss: 3.5788e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.2673e-04 - val_loss: 2.7510e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.0444e-04 - val_loss: 1.6109e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 4s 91us/step - loss: 1.8590e-04 - val_loss: 1.3322e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 4s 100us/step - loss: 1.0969e-04 - val_loss: 9.7173e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.1062e-04 - val_loss: 8.4364e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 4s 83us/step - loss: 8.9189e-05 - val_loss: 9.8389e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 4s 101us/step - loss: 1.0283e-04 - val_loss: 7.2565e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 4s 98us/step - loss: 8.3272e-05 - val_loss: 6.3088e-05\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 4s 91us/step - loss: 9.0814e-05 - val_loss: 5.9561e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 4s 88us/step - loss: 6.6434e-05 - val_loss: 5.8785e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 4s 86us/step - loss: 7.2325e-05 - val_loss: 8.6191e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 4s 85us/step - loss: 7.3150e-05 - val_loss: 5.7912e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 4s 84us/step - loss: 8.4105e-05 - val_loss: 4.8360e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 4s 84us/step - loss: 8.2530e-05 - val_loss: 9.9538e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.4934e-05 - val_loss: 4.6033e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.2517e-04 - val_loss: 5.3449e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.4829e-05 - val_loss: 4.2712e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 4.0131e-05 - val_loss: 4.0376e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.8757e-05 - val_loss: 4.4272e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.3114e-04 - val_loss: 4.8846e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 3.8696e-05 - val_loss: 3.6893e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 3.6030e-05 - val_loss: 3.6772e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 9.8224e-05 - val_loss: 5.5551e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.6689e-05 - val_loss: 3.5963e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 9.5911e-05 - val_loss: 6.0683e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 4.3961e-05 - val_loss: 3.6154e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.3457e-05 - val_loss: 4.4674e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.1062e-04 - val_loss: 3.3703e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.1618e-05 - val_loss: 3.0410e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 7.1585e-05 - val_loss: 6.8909e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.4915e-05 - val_loss: 3.5121e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 8.0858e-05 - val_loss: 3.0130e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 3.0847e-05 - val_loss: 3.1004e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.0528e-04 - val_loss: 2.9602e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.8854e-05 - val_loss: 2.7998e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.1697e-05 - val_loss: 2.0325e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.5132e-05 - val_loss: 2.7276e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.5453e-05 - val_loss: 2.5927e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.4360e-05 - val_loss: 4.6544e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 2.8954e-05 - val_loss: 2.4289e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 2.8464e-05 - val_loss: 1.6973e-04\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 4s 83us/step - loss: 1.0687e-04 - val_loss: 2.8252e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.3444e-05 - val_loss: 2.2822e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 8.2175e-05 - val_loss: 3.6890e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 4.3548e-05 - val_loss: 2.2653e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 2.2142e-05 - val_loss: 2.4601e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.0665e-04 - val_loss: 3.8508e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 2.8731e-05 - val_loss: 2.3899e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 8.5930e-05 - val_loss: 4.9211e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 2.8227e-05 - val_loss: 2.0443e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.9941e-05 - val_loss: 1.9987e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.5142e-04 - val_loss: 1.0241e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.0840e-05 - val_loss: 1.9635e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.8974e-05 - val_loss: 1.9069e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.8525e-05 - val_loss: 2.0669e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.1429e-05 - val_loss: 9.6207e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.8884e-05 - val_loss: 2.0299e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.9451e-05 - val_loss: 1.9847e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.4526e-05 - val_loss: 1.9674e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.7881e-05 - val_loss: 1.8225e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.5645e-05 - val_loss: 3.5196e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 2.1036e-05 - val_loss: 1.6952e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.8172e-05 - val_loss: 6.6039e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.0530e-04 - val_loss: 2.6069e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.7446e-05 - val_loss: 1.6291e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.5676e-05 - val_loss: 1.6464e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 9.6726e-05 - val_loss: 2.4590e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.8230e-05 - val_loss: 1.5756e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.5302e-05 - val_loss: 2.1568e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.9099e-05 - val_loss: 1.8235e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.6354e-05 - val_loss: 1.6396e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.4365e-05 - val_loss: 6.0342e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 2.6870e-05 - val_loss: 1.5282e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.4116e-05 - val_loss: 1.7804e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.0336e-04 - val_loss: 2.2865e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.6316e-05 - val_loss: 1.4537e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.3645e-05 - val_loss: 1.3740e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.0163e-04 - val_loss: 7.1943e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 2.1782e-05 - val_loss: 1.3853e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.3123e-05 - val_loss: 1.3280e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.3994e-05 - val_loss: 3.5716e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.0473e-05 - val_loss: 1.9582e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.4684e-05 - val_loss: 1.6458e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 6.9269e-05 - val_loss: 1.3921e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.5019e-05 - val_loss: 1.2996e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.2810e-05 - val_loss: 2.1833e-04\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 5.2748e-05 - val_loss: 1.5398e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.3140e-05 - val_loss: 1.4466e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 5.9667e-05 - val_loss: 1.8357e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.3481e-05 - val_loss: 1.1861e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.3086e-05 - val_loss: 4.7707e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.6866e-05 - val_loss: 1.2247e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.2302e-05 - val_loss: 2.8541e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.1119e-05 - val_loss: 1.2838e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.1523e-05 - val_loss: 1.1165e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 5.4181e-05 - val_loss: 2.1886e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.4878e-05 - val_loss: 1.1171e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 5.0651e-05 - val_loss: 3.9051e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.9840e-05 - val_loss: 1.1136e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.0363e-05 - val_loss: 1.0737e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 8.6851e-05 - val_loss: 1.5558e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.2850e-05 - val_loss: 1.0490e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 9.9701e-06 - val_loss: 1.0244e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.9686e-05 - val_loss: 2.4150e-04\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 6.3543e-05 - val_loss: 1.1330e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.0918e-05 - val_loss: 1.1151e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 9.9300e-06 - val_loss: 1.2564e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 5.9660e-05 - val_loss: 1.6329e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.0955e-05 - val_loss: 9.5969e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 4.1565e-05 - val_loss: 8.0016e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.3974e-05 - val_loss: 1.1123e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.4476e-06 - val_loss: 9.8359e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.3156e-05 - val_loss: 3.4385e-04\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.2645e-04 - val_loss: 2.7252e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 2.5077e-05 - val_loss: 1.7743e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.5869e-05 - val_loss: 1.4816e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3861e-05 - val_loss: 1.3381e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2727e-05 - val_loss: 1.2790e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.4643e-05 - val_loss: 1.2310e-05\n",
      "Epoch 00128: early stopping\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_11 (ZeroPaddi (None, 294, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 294, 32)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 147, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 147, 64)           14400     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 74, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 74, 128)           57472     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 74, 128)           114816    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_26 (UpSampling (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 148, 64)           57408     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_27 (UpSampling (None, 296, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 296, 32)           14368     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 296, 1)            225       \n",
      "_________________________________________________________________\n",
      "cropping1d_11 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 258,945\n",
      "Trainable params: 258,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 116us/step - loss: 0.0503 - val_loss: 0.0291\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 0.026 - 3s 64us/step - loss: 0.0267 - val_loss: 0.0091\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 0.0010 - val_loss: 9.9428e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 9.2523e-04 - val_loss: 8.6456e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.2485e-04 - val_loss: 6.2543e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 5.4831e-04 - val_loss: 4.3404e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.7811e-04 - val_loss: 4.2945e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 2.2962e-04 - val_loss: 1.6701e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.4005e-04 - val_loss: 1.1982e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.2026e-04 - val_loss: 1.0634e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.0793e-04 - val_loss: 1.6682e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.6702e-05 - val_loss: 8.0437e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 9.2796e-05 - val_loss: 8.3683e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 7.1774e-05 - val_loss: 1.8314e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 8.9232e-05 - val_loss: 5.9136e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.7845e-05 - val_loss: 8.7529e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 5.8346e-05 - val_loss: 4.9946e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.4331e-05 - val_loss: 5.0359e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 4.6103e-05 - val_loss: 4.4258e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.9203e-05 - val_loss: 5.8238e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 4.2801e-05 - val_loss: 4.2480e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.8190e-05 - val_loss: 4.3516e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 4.3730e-05 - val_loss: 1.1793e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 5.5838e-05 - val_loss: 4.2699e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 4.6523e-05 - val_loss: 5.0136e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 8.8601e-05 - val_loss: 4.0944e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.1571e-05 - val_loss: 3.0539e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 5.8715e-05 - val_loss: 5.7337e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.4039e-05 - val_loss: 3.4883e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.3526e-05 - val_loss: 2.7542e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.6111e-05 - val_loss: 2.1538e-04\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 4.8030e-05 - val_loss: 2.6758e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.7635e-05 - val_loss: 2.5411e-04\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.8192e-05 - val_loss: 2.4903e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 4.0528e-05 - val_loss: 7.3632e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.6609e-05 - val_loss: 3.2360e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 6.1762e-0 - 3s 65us/step - loss: 6.1590e-05 - val_loss: 2.6176e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 4.4283e-05 - val_loss: 2.7871e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.4542e-05 - val_loss: 5.8771e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.4500e-05 - val_loss: 2.7162e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 5.6356e-05 - val_loss: 6.2413e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 2.7981e-05 - val_loss: 4.9120e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.1869e-05 - val_loss: 2.0731e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 2.7361e-05 - val_loss: 1.2727e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.6310e-05 - val_loss: 2.2496e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.9447e-05 - val_loss: 3.1043e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.0959e-04 - val_loss: 2.1814e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 1.9453e-05 - val_loss: 1.7859e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 3.1291e-05 - val_loss: 2.6564e-04\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 7.6496e-05 - val_loss: 2.4185e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.7821e-05 - val_loss: 1.7597e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.0267e-04 - val_loss: 1.0810e-04\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 3.4283e-05 - val_loss: 1.7671e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.6312e-05 - val_loss: 1.6829e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 6.4637e-05 - val_loss: 1.9153e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 2.8616e-05 - val_loss: 1.5743e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 4.1035e-05 - val_loss: 4.1006e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 7.1426e-05 - val_loss: 1.7380e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.5215e-05 - val_loss: 1.5335e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 8.2599e-05 - val_loss: 9.1901e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.1427e-05 - val_loss: 1.5942e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.6204e-05 - val_loss: 5.2719e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 8.1721e-05 - val_loss: 1.8449e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.5442e-05 - val_loss: 1.6497e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 6.4915e-05 - val_loss: 3.4240e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.8921e-05 - val_loss: 1.4240e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 9.0142e-05 - val_loss: 4.2437e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.8263e-05 - val_loss: 1.3483e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 2.0413e-05 - val_loss: 1.7119e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 8.2785e-05 - val_loss: 1.8831e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.3548e-05 - val_loss: 1.3102e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 8.3302e-05 - val_loss: 5.3319e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 1.9901e-05 - val_loss: 1.2616e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 1.2191e-0 - 3s 67us/step - loss: 1.2209e-05 - val_loss: 1.8676e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.0402e-04 - val_loss: 1.3769e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.3308e-05 - val_loss: 1.2368e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.6544e-05 - val_loss: 9.0795e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.7169e-05 - val_loss: 1.3839e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.1851e-05 - val_loss: 1.3753e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 8.9657e-05 - val_loss: 1.9711e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.3552e-05 - val_loss: 1.1463e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.8028e-05 - val_loss: 1.9711e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 2.9220e-05 - val_loss: 1.1386e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.0722e-05 - val_loss: 1.0832e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 9.3448e-05 - val_loss: 4.4181e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.9144e-05 - val_loss: 1.0952e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 1.0270e-05 - val_loss: 1.0263e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.1940e-05 - val_loss: 6.3264e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.8709e-05 - val_loss: 1.1269e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 4.4137e-05 - val_loss: 3.8848e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 5.5795e-05 - val_loss: 1.3035e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 1.0114e-05 - val_loss: 9.8283e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.0138e-05 - val_loss: 2.9939e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.7478e-05 - val_loss: 1.4601e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.9852e-06 - val_loss: 9.5030e-06\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 3.9940e-05 - val_loss: 1.4990e-04\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 2.5708e-05 - val_loss: 1.1261e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.3784e-05 - val_loss: 1.1538e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 6.9518e-05 - val_loss: 9.8971e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 9.2820e-06 - val_loss: 9.1556e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 6.9539e-05 - val_loss: 1.1263e-04\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 61us/step - loss: 5.0307e-05 - val_loss: 1.2306e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 9.3708e-06 - val_loss: 8.8535e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 62us/step - loss: 1.1265e-05 - val_loss: 5.1584e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 4.9324e-05 - val_loss: 1.0298e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 9.0850e-06 - val_loss: 1.2138e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.4782e-05 - val_loss: 1.7168e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 9.7664e-06 - val_loss: 8.2129e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.7934e-05 - val_loss: 2.2911e-04\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.7234e-05 - val_loss: 1.3100e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 8.6221e-06 - val_loss: 8.0414e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.7410e-06 - val_loss: 7.8411e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 8.6377e-05 - val_loss: 3.1954e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 1.3221e-05 - val_loss: 7.9773e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 7.6664e-06 - val_loss: 7.7024e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.4820e-06 - val_loss: 8.8826e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.8263e-05 - val_loss: 1.7514e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.1609e-06 - val_loss: 7.6500e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.5271e-06 - val_loss: 1.1699e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 66us/step - loss: 6.0739e-05 - val_loss: 1.4300e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 9.8431e-06 - val_loss: 7.4850e-06\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 7.3125e-06 - val_loss: 1.3087e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.6377e-05 - val_loss: 1.1880e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.7936e-06 - val_loss: 7.1205e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.8014e-06 - val_loss: 7.1981e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4020e-05 - val_loss: 2.2258e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 9.5777e-06 - val_loss: 7.1934e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.7612e-06 - val_loss: 9.5630e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.2771e-05 - val_loss: 1.2063e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.8968e-06 - val_loss: 6.7120e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.1471e-05 - val_loss: 1.1080e-04\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.9276e-05 - val_loss: 7.7250e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.6164e-06 - val_loss: 6.4487e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 4.2462e-05 - val_loss: 1.3418e-04\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 3.7849e-05 - val_loss: 9.3785e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.7638e-06 - val_loss: 6.3548e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.3980e-06 - val_loss: 1.7421e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.4316e-05 - val_loss: 8.1778e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 3.7821e-05 - val_loss: 2.8570e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.4142e-05 - val_loss: 6.5509e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.8828e-06 - val_loss: 5.9380e-06\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 8.9120e-05 - val_loss: 8.4855e-04\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 2.4115e-0 - 3s 68us/step - loss: 2.4013e-04 - val_loss: 2.4465e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.4587e-05 - val_loss: 1.1216e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.0032e-05 - val_loss: 9.4383e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.6322e-06 - val_loss: 8.3434e-06\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 65us/step - loss: 7.8484e-06 - val_loss: 7.7767e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.3947e-06 - val_loss: 7.3829e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 7.0725e-06 - val_loss: 7.1085e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 3s 64us/step - loss: 6.8177e-06 - val_loss: 6.9255e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 3s 63us/step - loss: 6.5999e-06 - val_loss: 6.6455e-06\n",
      "Epoch 00154: early stopping\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_12 (ZeroPaddi (None, 296, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 296, 32)           288       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 148, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 148, 64)           16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 74, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 74, 128)           65664     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 74, 128)           131200    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_28 (UpSampling (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 148, 64)           65600     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_29 (UpSampling (None, 296, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 296, 32)           16416     \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 296, 1)            257       \n",
      "_________________________________________________________________\n",
      "cropping1d_12 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 295,873\n",
      "Trainable params: 295,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 124us/step - loss: 0.0623 - val_loss: 0.0294\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0282 - val_loss: 0.0220\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.1034e-04 - val_loss: 8.1329e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 6.9531e-04 - val_loss: 5.6974e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 4.7738e-04 - val_loss: 3.6926e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 3.2201e-04 - val_loss: 2.3690e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 2.0208e-04 - val_loss: 1.7407e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.5337e-04 - val_loss: 1.3064e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 1.2032e-04 - val_loss: 2.8643e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.2526e-04 - val_loss: 9.0411e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.6196e-05 - val_loss: 1.0534e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.6488e-05 - val_loss: 7.7139e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.5064e-05 - val_loss: 2.2954e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.5796e-05 - val_loss: 6.6374e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.4396e-05 - val_loss: 7.3360e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 7.3257e-05 - val_loss: 6.7170e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 7.9049e-05 - val_loss: 5.9752e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.9317e-05 - val_loss: 1.9210e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.7577e-05 - val_loss: 5.1861e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.4125e-05 - val_loss: 7.1020e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.6122e-05 - val_loss: 7.2221e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.0113e-05 - val_loss: 4.6431e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.5999e-05 - val_loss: 4.6560e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 4.4996e-05 - val_loss: 4.5987e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.0593e-05 - val_loss: 4.6480e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.1299e-05 - val_loss: 4.4901e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.5252e-05 - val_loss: 4.7187e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 3.9055e-05 - val_loss: 3.8664e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.3783e-05 - val_loss: 5.1399e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.0095e-05 - val_loss: 3.7014e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.3346e-05 - val_loss: 5.4402e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.0036e-05 - val_loss: 5.3592e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.3046e-05 - val_loss: 1.4855e-04\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.6671e-05 - val_loss: 3.3571e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.1966e-05 - val_loss: 3.1796e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.4139e-05 - val_loss: 1.1997e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.0337e-05 - val_loss: 3.4787e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.0732e-05 - val_loss: 2.9149e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.1677e-05 - val_loss: 4.4570e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.2653e-05 - val_loss: 2.8567e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.6872e-05 - val_loss: 2.7689e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 8.3392e-05 - val_loss: 3.1940e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.7790e-05 - val_loss: 2.6650e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 6.0618e-05 - val_loss: 3.7049e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8818e-05 - val_loss: 2.8339e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 5.5008e-05 - val_loss: 3.2978e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 4.4293e-05 - val_loss: 3.7523e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 4.9693e-05 - val_loss: 5.8225e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 3.3065e-05 - val_loss: 7.3653e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 4.9196e-05 - val_loss: 2.6040e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 5.3001e-05 - val_loss: 2.7874e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.1504e-05 - val_loss: 1.7693e-04\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.3690e-05 - val_loss: 2.2703e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 5.3680e-05 - val_loss: 4.1792e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.6187e-05 - val_loss: 1.0826e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.5628e-05 - val_loss: 4.8696e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.8206e-05 - val_loss: 2.0203e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 3.5407e-05 - val_loss: 2.0116e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.9307e-05 - val_loss: 6.1948e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.7464e-05 - val_loss: 1.9991e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 4.6647e-05 - val_loss: 2.6860e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.1156e-05 - val_loss: 4.0455e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.8660e-05 - val_loss: 1.9200e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.1798e-05 - val_loss: 5.7648e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.0811e-05 - val_loss: 1.7694e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 5.7740e-05 - val_loss: 6.6613e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 2.5031e-05 - val_loss: 1.7187e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.3047e-05 - val_loss: 3.9116e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 2.6723e-05 - val_loss: 1.7415e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 1.8540e-05 - val_loss: 3.8213e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.0232e-05 - val_loss: 1.6378e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.1516e-05 - val_loss: 2.2259e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 3.0099e-05 - val_loss: 1.6823e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.9265e-05 - val_loss: 2.0092e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.7054e-05 - val_loss: 1.8718e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 4.6847e-05 - val_loss: 3.0617e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.5309e-05 - val_loss: 3.1602e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.6407e-05 - val_loss: 4.9679e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 5.0294e-05 - val_loss: 2.5117e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.5317e-05 - val_loss: 6.7307e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.3272e-05 - val_loss: 3.1751e-05\n",
      "Epoch 00085: early stopping\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_13 (ZeroPaddi (None, 296, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 296, 32)           320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 148, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 148, 64)           18496     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 74, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 74, 128)           73856     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 74, 128)           147584    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_30 (UpSampling (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 148, 64)           73792     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_31 (UpSampling (None, 296, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 296, 32)           18464     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 296, 1)            289       \n",
      "_________________________________________________________________\n",
      "cropping1d_13 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 332,801\n",
      "Trainable params: 332,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 120us/step - loss: 0.0456 - val_loss: 0.0290\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 0.0211 - val_loss: 0.0038\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0010 - val_loss: 9.9233e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 9.7781e-04 - val_loss: 9.8231e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.9709e-04 - val_loss: 8.7171e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.6309e-04 - val_loss: 5.9614e-04\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.8755e-04 - val_loss: 3.8644e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 3.3019e-04 - val_loss: 4.2487e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 2.1210e-04 - val_loss: 1.2714e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.5412e-04 - val_loss: 1.6616e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 9.6960e-05 - val_loss: 8.9162e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.4906e-04 - val_loss: 7.7205e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 7.5035e-0 - 3s 68us/step - loss: 7.5303e-05 - val_loss: 1.7880e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.7900e-04 - val_loss: 6.9898e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.5829e-05 - val_loss: 6.7110e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.0779e-04 - val_loss: 6.0775e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.5227e-05 - val_loss: 1.9875e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 9.3344e-05 - val_loss: 2.7070e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.9922e-05 - val_loss: 5.2946e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.3597e-05 - val_loss: 6.5981e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7062e-04 - val_loss: 1.6683e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.4194e-05 - val_loss: 4.9578e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 4.4452e-05 - val_loss: 4.7686e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.6413e-04 - val_loss: 4.8333e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.3949e-05 - val_loss: 4.5554e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.6890e-05 - val_loss: 5.3360e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 8.8320e-05 - val_loss: 6.1107e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.3570e-05 - val_loss: 5.0293e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.4748e-04 - val_loss: 3.7113e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.7568e-05 - val_loss: 4.5076e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.2294e-04 - val_loss: 4.2939e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 4.6494e-05 - val_loss: 2.4480e-04\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.3926e-05 - val_loss: 4.1087e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 9.1559e-05 - val_loss: 4.1796e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.0991e-05 - val_loss: 8.0380e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6920e-04 - val_loss: 4.3234e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.9835e-05 - val_loss: 2.7461e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.1964e-04 - val_loss: 5.1745e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.5927e-05 - val_loss: 2.5817e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.1530e-04 - val_loss: 2.8744e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.4315e-05 - val_loss: 2.5559e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.7273e-05 - val_loss: 2.9335e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.5812e-05 - val_loss: 2.4758e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.2411e-04 - val_loss: 3.7109e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.7452e-05 - val_loss: 2.2009e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.0859e-05 - val_loss: 2.1210e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.1825e-04 - val_loss: 3.4917e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 3.0032e-05 - val_loss: 2.0509e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.4291e-05 - val_loss: 1.9033e-04\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7637e-04 - val_loss: 2.0472e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 2.0130e-05 - val_loss: 2.0270e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 2.3116e-05 - val_loss: 8.6849e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 1.0019e-04 - val_loss: 2.1694e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 2.3494e-05 - val_loss: 9.7908e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 74us/step - loss: 9.9850e-05 - val_loss: 2.9796e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 4.6637e-05 - val_loss: 2.9513e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.5416e-05 - val_loss: 2.4527e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.6038e-05 - val_loss: 3.5904e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 2.8557e-05 - val_loss: 1.7139e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.8770e-05 - val_loss: 1.1526e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.2741e-05 - val_loss: 1.9264e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5366e-05 - val_loss: 2.7970e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.3511e-04 - val_loss: 4.2636e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.8862e-05 - val_loss: 1.5293e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4381e-05 - val_loss: 1.4522e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6115e-05 - val_loss: 6.9906e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 9.3885e-05 - val_loss: 2.2520e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.4896e-05 - val_loss: 1.3764e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0753e-04 - val_loss: 4.6506e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 76us/step - loss: 1.8379e-05 - val_loss: 1.6036e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.5332e-05 - val_loss: 4.1427e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.7666e-05 - val_loss: 1.3231e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.3106e-05 - val_loss: 2.3180e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9996e-05 - val_loss: 5.4415e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.9653e-05 - val_loss: 1.9119e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.3862e-05 - val_loss: 1.8348e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.6859e-05 - val_loss: 1.5299e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6082e-05 - val_loss: 1.5032e-04\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.1934e-04 - val_loss: 1.2321e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1888e-05 - val_loss: 1.1436e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 3.6738e-05 - val_loss: 4.4839e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.0350e-05 - val_loss: 1.3301e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.0808e-05 - val_loss: 1.0920e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.9755e-05 - val_loss: 1.9429e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.4272e-05 - val_loss: 1.2348e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 75us/step - loss: 7.3377e-05 - val_loss: 2.8090e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 1.6571e-05 - val_loss: 1.1750e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.9065e-05 - val_loss: 3.6301e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8931e-05 - val_loss: 1.7973e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.6185e-05 - val_loss: 1.2912e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.8428e-05 - val_loss: 4.2552e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6355e-05 - val_loss: 1.0766e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.6619e-05 - val_loss: 5.2554e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 1.8091e-05 - val_loss: 2.6666e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.3094e-05 - val_loss: 1.0932e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5817e-05 - val_loss: 7.8291e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.3377e-05 - val_loss: 9.3825e-06\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.1807e-05 - val_loss: 1.5640e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7493e-05 - val_loss: 1.0681e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.0943e-05 - val_loss: 1.6279e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9318e-05 - val_loss: 2.8277e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0828e-04 - val_loss: 1.2528e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.1756e-06 - val_loss: 8.0550e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 7.7295e-06 - val_loss: 9.6239e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 7.1010e-05 - val_loss: 1.6230e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 8.8336e-06 - val_loss: 8.0915e-06\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 5.9621e-05 - val_loss: 6.8853e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.2223e-05 - val_loss: 8.0004e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 8.1249e-06 - val_loss: 3.1771e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.7126e-05 - val_loss: 1.1183e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 9.8159e-06 - val_loss: 1.6557e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 3.8791e-05 - val_loss: 9.2128e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 4.5117e-05 - val_loss: 1.2365e-04\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 2.0596e-05 - val_loss: 8.3335e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.0202e-05 - val_loss: 7.6579e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 1.4216e-04 - val_loss: 5.9118e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.0953e-05 - val_loss: 7.3332e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.7260e-06 - val_loss: 6.7565e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.3470e-06 - val_loss: 6.5503e-06\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 6.8650e-06 - val_loss: 1.5951e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.2165e-05 - val_loss: 7.5300e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 7.2963e-06 - val_loss: 6.6860e-06\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 67us/step - loss: 8.3321e-06 - val_loss: 8.6305e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.8099e-05 - val_loss: 7.3296e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 6.6939e-06 - val_loss: 6.4442e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 71us/step - loss: 5.9544e-06 - val_loss: 6.3490e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.9657e-05 - val_loss: 2.0674e-04\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 70us/step - loss: 2.4692e-04 - val_loss: 2.2845e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3472e-05 - val_loss: 1.0110e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.8864e-06 - val_loss: 8.4648e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.7160e-06 - val_loss: 7.6666e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.1035e-06 - val_loss: 7.1467e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 6.6995e-0 - 3s 69us/step - loss: 6.6976e-06 - val_loss: 6.8032e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.4818e-06 - val_loss: 6.7756e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4399e-05 - val_loss: 1.4193e-04\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.9061e-05 - val_loss: 8.2858e-06\n",
      "Epoch 00140: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(2,10,1):\n",
    "    numOfLayers = depthParam\n",
    "    filtersCountInFirstLayer = 32\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer, filterSize = i)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001760433897288749, 3.768289550028688e-06, 3.6609433967290292e-06, 4.0231569755633245e-06, 9.596947279533197e-06, 5.938012407114002e-06, 1.637789303761868e-05, 6.349043284596216e-06]\n",
      "[188, 173, 236, 145, 128, 154, 85, 140]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001760433897288749, 3.768289550028688e-06, 3.6609433967290292e-06, 4.0231569755633245e-06, 9.596947279533197e-06, 5.938012407114002e-06, 1.637789303761868e-05, 6.349043284596216e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(modelsLoss)\n",
    "print(modelsEpochs)\n",
    "\n",
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. filter size')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Filter Size')\n",
    "plt.xticks(np.arange(8), [2,3,4,5,6,7,8,9])\n",
    "plt.show()\n",
    "print(modelsLoss)\n",
    "plt.savefig('figures_differential/conv_filter_size_tuning.eps', format='eps', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterParam = modelsLoss.index(min(modelsLoss)) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network first layer filter count tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_14 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 292, 4)            20        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 146, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 146, 8)            136       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 73, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 73, 16)            528       \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1168)              0         \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 73, 16)            1040      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_32 (UpSampling (None, 146, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 146, 8)            520       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_33 (UpSampling (None, 292, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 292, 4)            132       \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 292, 1)            17        \n",
      "_________________________________________________________________\n",
      "cropping1d_14 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 2,393\n",
      "Trainable params: 2,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 90us/step - loss: 0.1085 - val_loss: 0.0382\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0347 - val_loss: 0.0324\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0306 - val_loss: 0.0294\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0291 - val_loss: 0.0290\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0287 - val_loss: 0.0286\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0282 - val_loss: 0.0279\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0268 - val_loss: 0.0253\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0207 - val_loss: 0.0143\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0108 - val_loss: 0.0071\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 0.001 - 1s 31us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 0.0010 - val_loss: 9.8271e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.3175e-04 - val_loss: 8.7260e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.3561e-04 - val_loss: 7.9936e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.7678e-04 - val_loss: 7.5221e-04\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.3268e-04 - val_loss: 7.0927e-04\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 6.9718e-04 - val_loss: 6.7459e-04\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 6.6442e-04 - val_loss: 6.4831e-04\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 6.3572e-04 - val_loss: 6.2165e-04\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 1s 33us/step - loss: 6.1160e-04 - val_loss: 6.2628e-04\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 5.9321e-04 - val_loss: 5.7366e-04\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 5.6325e-04 - val_loss: 5.5466e-04\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 5.4631e-04 - val_loss: 5.3377e-04\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 5.2494e-04 - val_loss: 5.1852e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 5.1057e-04 - val_loss: 4.9985e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 4.8971e-04 - val_loss: 4.8245e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 4.7343e-04 - val_loss: 4.6698e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 4.5869e-04 - val_loss: 4.5294e-04\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 4.4557e-04 - val_loss: 4.3814e-04\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 4.3214e-04 - val_loss: 4.2483e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 4.2094e-04 - val_loss: 4.1704e-04\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 4.1103e-04 - val_loss: 4.0368e-04\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.9800e-04 - val_loss: 3.9638e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.8897e-04 - val_loss: 3.8643e-04\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.8054e-04 - val_loss: 3.7808e-04\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 3.7261e-04 - val_loss: 3.7019e-04\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 3.6800e-04 - val_loss: 3.6230e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.5553e-04 - val_loss: 3.5494e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 3.5018e-04 - val_loss: 3.4493e-04\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.4024e-04 - val_loss: 3.3996e-04\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 3.3257e-04 - val_loss: 3.2991e-04\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.2464e-04 - val_loss: 3.2207e-04\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.1764e-04 - val_loss: 3.1248e-04\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 3.0789e-04 - val_loss: 3.0536e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.9875e-04 - val_loss: 2.9714e-04\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.9052e-04 - val_loss: 2.9016e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.8513e-04 - val_loss: 2.8451e-04\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.7994e-04 - val_loss: 2.7832e-04\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.7261e-04 - val_loss: 2.7493e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.6732e-04 - val_loss: 2.6855e-04\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 2.6296e-04 - val_loss: 2.6199e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.5693e-04 - val_loss: 2.5745e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.5582e-04 - val_loss: 2.5654e-04\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.4949e-04 - val_loss: 2.5454e-04\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.4591e-04 - val_loss: 2.4709e-04\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.4382e-04 - val_loss: 2.4340e-04\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.4234e-04 - val_loss: 2.3947e-04\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.3572e-04 - val_loss: 2.4135e-04\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.3297e-04 - val_loss: 2.3477e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.3486e-04 - val_loss: 2.3671e-04\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.2777e-04 - val_loss: 2.4310e-04\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.2789e-04 - val_loss: 2.2751e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.2243e-04 - val_loss: 2.2756e-04\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.2217e-04 - val_loss: 2.2435e-04\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.1858e-04 - val_loss: 2.2068e-04\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.1700e-04 - val_loss: 2.1566e-04\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 2.1780e-04 - val_loss: 2.2055e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.1318e-04 - val_loss: 2.1284e-04\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.0680e-04 - val_loss: 2.0966e-04\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.0633e-04 - val_loss: 2.0666e-04\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 2.0748e-04 - val_loss: 2.0795e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.0253e-04 - val_loss: 2.0636e-04\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.0091e-04 - val_loss: 2.0279e-04\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 2.0114e-04 - val_loss: 1.9921e-04\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.9889e-04 - val_loss: 2.0415e-04\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.9418e-04 - val_loss: 1.9467e-04\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.9012e-04 - val_loss: 1.9263e-04\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.9000e-04 - val_loss: 2.0477e-04\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.9090e-04 - val_loss: 1.9453e-04\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.8690e-04 - val_loss: 1.9420e-04\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.8434e-04 - val_loss: 1.8626e-04\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.8265e-04 - val_loss: 1.8315e-04\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.8253e-04 - val_loss: 1.9010e-04\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.8177e-04 - val_loss: 1.8188e-04\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7828e-04 - val_loss: 1.8670e-04\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7734e-04 - val_loss: 2.0583e-04\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7831e-04 - val_loss: 1.7738e-04\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7490e-04 - val_loss: 1.7462e-04\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7223e-04 - val_loss: 1.7546e-04\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7199e-04 - val_loss: 1.7065e-04\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6939e-04 - val_loss: 1.6833e-04\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.7006e-04 - val_loss: 1.6654e-04\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6739e-04 - val_loss: 1.6527e-04\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6610e-04 - val_loss: 1.7462e-04\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6462e-04 - val_loss: 1.6793e-04\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6536e-04 - val_loss: 1.8359e-04\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6367e-04 - val_loss: 1.6614e-04\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.6059e-04 - val_loss: 1.6115e-04\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.6031e-04 - val_loss: 1.5787e-04\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.5943e-04 - val_loss: 1.6109e-04\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.5612e-04 - val_loss: 1.5659e-04\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.5816e-04 - val_loss: 1.5714e-04\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.5669e-04 - val_loss: 1.5458e-04\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.5352e-04 - val_loss: 1.5909e-04\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.5263e-04 - val_loss: 1.5510e-04\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.5785e-04 - val_loss: 1.5139e-04\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.5180e-04 - val_loss: 1.4934e-04\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4803e-04 - val_loss: 1.4908e-04\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.4699e-04 - val_loss: 1.4818e-04\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.5802e-04 - val_loss: 1.4682e-04\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.4593e-04 - val_loss: 1.4575e-04\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.4403e-04 - val_loss: 1.4810e-04\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.4561e-04 - val_loss: 1.4917e-04\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.4594e-04 - val_loss: 1.4340e-04\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4422e-04 - val_loss: 1.4335e-04\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4468e-04 - val_loss: 1.4542e-04\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4108e-04 - val_loss: 1.4659e-04\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4209e-04 - val_loss: 1.4049e-04\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4246e-04 - val_loss: 1.4353e-04\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.3811e-04 - val_loss: 1.3823e-04\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.4891e-04 - val_loss: 1.4178e-04\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.3594e-04 - val_loss: 1.3771e-04\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.3561e-04 - val_loss: 1.3924e-04\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3626e-04 - val_loss: 1.3643e-04\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3637e-04 - val_loss: 1.3630e-04\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3984e-04 - val_loss: 1.4090e-04\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3359e-04 - val_loss: 1.3333e-04\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3359e-04 - val_loss: 1.3661e-04\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3818e-04 - val_loss: 1.3586e-04\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3055e-04 - val_loss: 1.3069e-04\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.3280e-04 - val_loss: 1.5387e-04\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.3293e-04 - val_loss: 1.2989e-04\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2920e-04 - val_loss: 1.2839e-04\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.3412e-04 - val_loss: 1.2819e-04\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.2762e-04 - val_loss: 1.3229e-04\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2770e-04 - val_loss: 1.3720e-04\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.3097e-04 - val_loss: 1.2622e-04\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2659e-04 - val_loss: 1.2567e-04\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2961e-04 - val_loss: 1.2676e-04\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2577e-04 - val_loss: 1.2462e-04\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2472e-04 - val_loss: 1.2417e-04\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2798e-04 - val_loss: 1.2485e-04\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.2263e-04 - val_loss: 1.2411e-04\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2452e-04 - val_loss: 1.2237e-04\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.2654e-04 - val_loss: 1.2911e-04\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.2451e-04 - val_loss: 1.2194e-04\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1984e-04 - val_loss: 1.2837e-04\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2513e-04 - val_loss: 1.2053e-04\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1818e-04 - val_loss: 1.1878e-04\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2146e-04 - val_loss: 1.2072e-04\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 1.2271e-0 - 1s 32us/step - loss: 1.2270e-04 - val_loss: 1.1948e-04\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1759e-04 - val_loss: 1.1773e-04\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.2272e-04 - val_loss: 1.2054e-04\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1645e-04 - val_loss: 1.1602e-04\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1693e-04 - val_loss: 1.1538e-04\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1955e-04 - val_loss: 1.1887e-04\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1573e-04 - val_loss: 1.1845e-04\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1713e-04 - val_loss: 1.1797e-04\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1419e-04 - val_loss: 1.1795e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1931e-04 - val_loss: 1.1303e-04\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1343e-04 - val_loss: 1.1470e-04\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1279e-04 - val_loss: 1.1260e-04\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1251e-04 - val_loss: 1.1182e-04\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1446e-04 - val_loss: 1.1135e-04\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1370e-04 - val_loss: 1.1211e-04\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1060e-04 - val_loss: 1.1031e-04\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.1609e-04 - val_loss: 1.1802e-04\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.1212e-04 - val_loss: 1.0975e-04\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0840e-04 - val_loss: 1.0848e-04\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.1126e-04 - val_loss: 1.0997e-04\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0851e-04 - val_loss: 1.1036e-04\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0903e-04 - val_loss: 1.0884e-04\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0806e-04 - val_loss: 1.0873e-04\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.1264e-04 - val_loss: 1.0667e-04\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0463e-04 - val_loss: 1.0567e-04\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.1450e-04 - val_loss: 1.0671e-04\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0595e-04 - val_loss: 1.0537e-04\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0432e-04 - val_loss: 1.0444e-04\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.0596e-04 - val_loss: 1.0566e-04\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0757e-04 - val_loss: 1.2369e-04\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0534e-04 - val_loss: 1.0361e-04\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0391e-04 - val_loss: 1.0753e-04\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0427e-04 - val_loss: 1.0291e-04\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0816e-04 - val_loss: 1.0361e-04\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0161e-04 - val_loss: 1.0350e-04\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0344e-04 - val_loss: 1.1350e-04\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0463e-04 - val_loss: 1.0121e-04\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0401e-04 - val_loss: 1.0179e-04\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0136e-04 - val_loss: 1.0110e-04\n",
      "Epoch 224/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.0358e-04 - val_loss: 1.0382e-04\n",
      "Epoch 225/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0057e-04 - val_loss: 1.0079e-04\n",
      "Epoch 226/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0002e-04 - val_loss: 9.9495e-05\n",
      "Epoch 227/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0530e-04 - val_loss: 1.0144e-04\n",
      "Epoch 228/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.8511e-05 - val_loss: 1.0134e-04\n",
      "Epoch 229/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0043e-04 - val_loss: 1.0672e-04\n",
      "Epoch 230/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.9039e-05 - val_loss: 1.0304e-04\n",
      "Epoch 231/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.8853e-05 - val_loss: 9.9470e-05\n",
      "Epoch 232/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.9657e-05 - val_loss: 9.7469e-05\n",
      "Epoch 233/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.0482e-04 - val_loss: 9.8302e-05\n",
      "Epoch 234/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.8461e-05 - val_loss: 9.6699e-05\n",
      "Epoch 235/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.5028e-05 - val_loss: 9.7974e-05\n",
      "Epoch 236/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.8593e-05 - val_loss: 9.6750e-05\n",
      "Epoch 237/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.4958e-05 - val_loss: 1.0018e-04\n",
      "Epoch 238/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 1.0245e-04 - val_loss: 1.0043e-04\n",
      "Epoch 239/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.5285e-05 - val_loss: 9.4936e-05\n",
      "Epoch 240/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.3772e-05 - val_loss: 9.4703e-05\n",
      "Epoch 241/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 1.0197e-04 - val_loss: 1.0221e-04\n",
      "Epoch 242/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.3994e-05 - val_loss: 9.3994e-05\n",
      "Epoch 243/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.3102e-05 - val_loss: 9.3487e-05\n",
      "Epoch 244/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.4445e-05 - val_loss: 9.3266e-05\n",
      "Epoch 245/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.2825e-05 - val_loss: 9.3183e-05\n",
      "Epoch 246/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 1.0240e-04 - val_loss: 9.4719e-05\n",
      "Epoch 247/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 9.1344e-05 - val_loss: 9.2401e-05\n",
      "Epoch 248/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.0701e-05 - val_loss: 9.5560e-05\n",
      "Epoch 249/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.5318e-05 - val_loss: 9.2599e-05\n",
      "Epoch 250/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.2021e-05 - val_loss: 9.1706e-05\n",
      "Epoch 251/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.4035e-05 - val_loss: 9.5057e-05\n",
      "Epoch 252/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.0765e-05 - val_loss: 9.1241e-05\n",
      "Epoch 253/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.3721e-05 - val_loss: 9.6356e-05\n",
      "Epoch 254/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.9945e-05 - val_loss: 9.0459e-05\n",
      "Epoch 255/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.4134e-05 - val_loss: 9.4792e-05\n",
      "Epoch 256/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.8791e-05 - val_loss: 8.9731e-05\n",
      "Epoch 257/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 9.4211e-05 - val_loss: 8.9312e-05\n",
      "Epoch 258/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.8786e-05 - val_loss: 8.8695e-05\n",
      "Epoch 259/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.9651e-05 - val_loss: 9.1569e-05\n",
      "Epoch 260/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 9.3492e-05 - val_loss: 8.8397e-05\n",
      "Epoch 261/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.8019e-05 - val_loss: 8.8487e-05\n",
      "Epoch 262/1000\n",
      "43200/43200 [==============================] - 1s 33us/step - loss: 8.7526e-05 - val_loss: 8.8013e-05\n",
      "Epoch 263/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 9.9336e-05 - val_loss: 8.7442e-05\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.6585e-05 - val_loss: 8.7049e-05\n",
      "Epoch 265/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.6056e-05 - val_loss: 8.6845e-05\n",
      "Epoch 266/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.9869e-05 - val_loss: 9.2932e-05\n",
      "Epoch 267/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.7104e-05 - val_loss: 8.6470e-05\n",
      "Epoch 268/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.5754e-05 - val_loss: 8.6087e-05\n",
      "Epoch 269/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.9026e-05 - val_loss: 8.9331e-05\n",
      "Epoch 270/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.6888e-05 - val_loss: 8.5891e-05\n",
      "Epoch 271/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.5853e-05 - val_loss: 1.0370e-04\n",
      "Epoch 272/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.7020e-05 - val_loss: 8.4876e-05\n",
      "Epoch 273/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.6121e-05 - val_loss: 9.0497e-05\n",
      "Epoch 274/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.7110e-05 - val_loss: 8.5439e-05\n",
      "Epoch 275/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.6901e-05 - val_loss: 8.8001e-05\n",
      "Epoch 276/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.4026e-05 - val_loss: 8.4642e-05\n",
      "Epoch 277/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.6129e-05 - val_loss: 8.3632e-05\n",
      "Epoch 278/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.4690e-05 - val_loss: 8.4724e-05\n",
      "Epoch 279/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.9231e-05 - val_loss: 8.6039e-05\n",
      "Epoch 280/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.2932e-05 - val_loss: 8.4642e-05\n",
      "Epoch 281/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.2510e-05 - val_loss: 8.7819e-05\n",
      "Epoch 282/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.4881e-05 - val_loss: 1.0708e-04\n",
      "Epoch 283/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.4493e-05 - val_loss: 8.4336e-05\n",
      "Epoch 284/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.2767e-05 - val_loss: 8.8542e-05\n",
      "Epoch 285/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.4925e-05 - val_loss: 9.1189e-05\n",
      "Epoch 286/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.1729e-05 - val_loss: 8.1767e-05\n",
      "Epoch 287/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.3512e-05 - val_loss: 8.3292e-05\n",
      "Epoch 288/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.1048e-05 - val_loss: 8.2640e-05\n",
      "Epoch 289/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.5911e-05 - val_loss: 8.1266e-05\n",
      "Epoch 290/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.1290e-05 - val_loss: 8.0913e-05\n",
      "Epoch 291/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.0983e-05 - val_loss: 9.2515e-05\n",
      "Epoch 292/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.4038e-05 - val_loss: 8.0105e-05\n",
      "Epoch 293/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9581e-05 - val_loss: 8.1699e-05\n",
      "Epoch 294/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.6527e-05 - val_loss: 7.9870e-05\n",
      "Epoch 295/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.0087e-05 - val_loss: 8.1817e-05\n",
      "Epoch 296/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.1365e-05 - val_loss: 7.9351e-05\n",
      "Epoch 297/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.9110e-05 - val_loss: 8.3142e-05\n",
      "Epoch 298/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.8642e-05 - val_loss: 8.4502e-05\n",
      "Epoch 299/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 8.7550e-05 - val_loss: 7.9197e-05\n",
      "Epoch 300/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.7211e-05 - val_loss: 7.8013e-05\n",
      "Epoch 301/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.7245e-05 - val_loss: 8.2199e-05\n",
      "Epoch 302/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9767e-05 - val_loss: 7.7955e-05\n",
      "Epoch 303/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9579e-05 - val_loss: 7.8166e-05\n",
      "Epoch 304/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.7735e-05 - val_loss: 7.8123e-05\n",
      "Epoch 305/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.2155e-05 - val_loss: 7.7617e-05\n",
      "Epoch 306/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.6629e-05 - val_loss: 7.6870e-05\n",
      "Epoch 307/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 8.0843e-0 - 1s 32us/step - loss: 8.0830e-05 - val_loss: 8.2796e-05\n",
      "Epoch 308/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.6589e-05 - val_loss: 7.7034e-05\n",
      "Epoch 309/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.8174e-05 - val_loss: 9.7053e-05\n",
      "Epoch 310/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.7544e-05 - val_loss: 7.6288e-05\n",
      "Epoch 311/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.7985e-05 - val_loss: 7.6920e-05\n",
      "Epoch 312/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.5051e-05 - val_loss: 8.1090e-05\n",
      "Epoch 313/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.6226e-05 - val_loss: 8.6819e-05\n",
      "Epoch 314/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.2380e-05 - val_loss: 7.5692e-05\n",
      "Epoch 315/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.3863e-05 - val_loss: 7.5475e-05\n",
      "Epoch 316/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4911e-05 - val_loss: 8.7913e-05\n",
      "Epoch 317/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.6127e-05 - val_loss: 7.4605e-05\n",
      "Epoch 318/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9384e-05 - val_loss: 8.4743e-05\n",
      "Epoch 319/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4363e-05 - val_loss: 7.5809e-05\n",
      "Epoch 320/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4440e-05 - val_loss: 9.1363e-05\n",
      "Epoch 321/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.8569e-05 - val_loss: 7.5098e-05\n",
      "Epoch 322/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.2340e-05 - val_loss: 7.5862e-05\n",
      "Epoch 323/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.6470e-05 - val_loss: 7.7355e-05\n",
      "Epoch 324/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.3892e-05 - val_loss: 7.6406e-05\n",
      "Epoch 325/1000\n",
      "43200/43200 [==============================] - 1s 32us/step - loss: 7.2756e-05 - val_loss: 7.5134e-05\n",
      "Epoch 326/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9676e-05 - val_loss: 7.3018e-05\n",
      "Epoch 327/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.2543e-05 - val_loss: 7.3129e-05\n",
      "Epoch 328/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.3231e-05 - val_loss: 7.5027e-05\n",
      "Epoch 329/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4058e-05 - val_loss: 7.2324e-05\n",
      "Epoch 330/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 8.2601e-05 - val_loss: 8.6621e-05\n",
      "Epoch 331/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4011e-05 - val_loss: 7.2326e-05\n",
      "Epoch 332/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0485e-05 - val_loss: 7.1679e-05\n",
      "Epoch 333/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0545e-05 - val_loss: 7.3089e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4236e-05 - val_loss: 7.5426e-05\n",
      "Epoch 335/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.1554e-05 - val_loss: 7.1287e-05\n",
      "Epoch 336/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0645e-05 - val_loss: 7.2425e-05\n",
      "Epoch 337/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.9476e-05 - val_loss: 7.5343e-05\n",
      "Epoch 338/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.1007e-05 - val_loss: 7.0782e-05\n",
      "Epoch 339/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.9921e-05 - val_loss: 8.7552e-05\n",
      "Epoch 340/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4897e-05 - val_loss: 7.0909e-05\n",
      "Epoch 341/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.9054e-05 - val_loss: 7.0244e-05\n",
      "Epoch 342/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4165e-05 - val_loss: 6.9912e-05\n",
      "Epoch 343/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.9801e-05 - val_loss: 7.2673e-05\n",
      "Epoch 344/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.3025e-05 - val_loss: 7.2079e-05\n",
      "Epoch 345/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.9674e-05 - val_loss: 7.0306e-05\n",
      "Epoch 346/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.4522e-05 - val_loss: 6.9775e-05\n",
      "Epoch 347/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8506e-05 - val_loss: 7.0130e-05\n",
      "Epoch 348/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0674e-05 - val_loss: 7.3376e-05\n",
      "Epoch 349/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.1854e-05 - val_loss: 7.0609e-05\n",
      "Epoch 350/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0568e-05 - val_loss: 1.0901e-04\n",
      "Epoch 351/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.5859e-05 - val_loss: 6.9411e-05\n",
      "Epoch 352/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.7814e-05 - val_loss: 6.8484e-05\n",
      "Epoch 353/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.7016e-05 - val_loss: 6.9664e-05\n",
      "Epoch 354/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.5459e-05 - val_loss: 6.8762e-05\n",
      "Epoch 355/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.7687e-05 - val_loss: 6.8217e-05\n",
      "Epoch 356/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.2133e-05 - val_loss: 6.9290e-05\n",
      "Epoch 357/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8996e-05 - val_loss: 6.7492e-05\n",
      "Epoch 358/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.6839e-05 - val_loss: 6.9522e-05\n",
      "Epoch 359/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.0914e-05 - val_loss: 7.1376e-05\n",
      "Epoch 360/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8504e-05 - val_loss: 7.0654e-05\n",
      "Epoch 361/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8264e-05 - val_loss: 7.1040e-05\n",
      "Epoch 362/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8293e-05 - val_loss: 8.2547e-05\n",
      "Epoch 363/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.9828e-05 - val_loss: 6.9218e-05\n",
      "Epoch 364/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.7993e-05 - val_loss: 6.9498e-05\n",
      "Epoch 365/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 7.1998e-05 - val_loss: 7.4372e-05\n",
      "Epoch 366/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.6790e-05 - val_loss: 6.7551e-05\n",
      "Epoch 367/1000\n",
      "43200/43200 [==============================] - 1s 31us/step - loss: 6.8022e-05 - val_loss: 1.0336e-04\n",
      "Epoch 00367: early stopping\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_15 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 292, 8)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 146, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 146, 16)           528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 73, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 73, 32)            2080      \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2336)              0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 73, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 73, 32)            4128      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_34 (UpSampling (None, 146, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 146, 16)           2064      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_35 (UpSampling (None, 292, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 292, 8)            520       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 292, 1)            33        \n",
      "_________________________________________________________________\n",
      "cropping1d_15 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 9,393\n",
      "Trainable params: 9,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 88us/step - loss: 0.0642 - val_loss: 0.0330\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0300 - val_loss: 0.0285\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0220 - val_loss: 0.0059\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 0.0010 - val_loss: 9.9386e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.6943e-04 - val_loss: 9.1670e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 8.7652e-04 - val_loss: 8.2386e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 8.1377e-04 - val_loss: 7.4502e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 7.1372e-04 - val_loss: 6.6878e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 6.7860e-04 - val_loss: 6.0029e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.5663e-04 - val_loss: 5.1988e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.0941e-04 - val_loss: 4.4425e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 4.2140e-04 - val_loss: 3.9566e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.9855e-04 - val_loss: 3.6687e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.4154e-04 - val_loss: 3.2468e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.4498e-04 - val_loss: 2.9846e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8709e-04 - val_loss: 2.7659e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.6775e-04 - val_loss: 3.0522e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8531e-04 - val_loss: 2.4133e-04\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3258e-04 - val_loss: 2.2512e-04\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1877e-04 - val_loss: 2.3205e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3423e-04 - val_loss: 1.9958e-04\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.9454e-04 - val_loss: 1.8851e-04\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9863e-04 - val_loss: 1.8293e-04\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7522e-04 - val_loss: 1.6838e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.8683e-04 - val_loss: 1.6270e-04\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.5674e-04 - val_loss: 1.5264e-04\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.6548e-04 - val_loss: 1.4996e-04\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4483e-04 - val_loss: 1.4013e-04\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4960e-04 - val_loss: 1.3537e-04\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.3420e-04 - val_loss: 1.3333e-04\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4620e-04 - val_loss: 1.2890e-04\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.2317e-04 - val_loss: 1.2115e-04\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.3641e-04 - val_loss: 1.1724e-04\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.1502e-04 - val_loss: 1.1278e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.3376e-04 - val_loss: 1.1085e-04\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.0764e-04 - val_loss: 1.0603e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.1367e-04 - val_loss: 1.0307e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.0559e-04 - val_loss: 1.0047e-04\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.1903e-04 - val_loss: 9.9023e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.6948e-05 - val_loss: 9.5149e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.2910e-05 - val_loss: 9.2436e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4733e-04 - val_loss: 1.1084e-04\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 9.1165e-05 - val_loss: 8.8962e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.6604e-05 - val_loss: 8.6857e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.4521e-05 - val_loss: 8.4673e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.2625e-05 - val_loss: 8.2748e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.4210e-05 - val_loss: 9.8821e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.2214e-05 - val_loss: 9.1117e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.7388e-05 - val_loss: 7.8146e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.5416e-05 - val_loss: 8.2688e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.8270e-05 - val_loss: 7.5093e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.0936e-04 - val_loss: 9.1293e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.5164e-05 - val_loss: 7.2968e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.0995e-05 - val_loss: 7.1134e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.2569e-05 - val_loss: 9.2071e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.2771e-05 - val_loss: 6.9051e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.3660e-05 - val_loss: 6.7913e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.7317e-05 - val_loss: 6.6913e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.6332e-05 - val_loss: 6.8349e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.7590e-05 - val_loss: 7.2354e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.4773e-05 - val_loss: 6.3867e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 9.4475e-05 - val_loss: 6.7291e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.3228e-05 - val_loss: 6.2418e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.0948e-05 - val_loss: 6.1485e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.9495e-05 - val_loss: 6.9984e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 6.0382e-05 - val_loss: 6.1236e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.9142e-05 - val_loss: 6.4384e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.9070e-05 - val_loss: 6.1334e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.0199e-05 - val_loss: 8.3971e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.9752e-05 - val_loss: 5.7475e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.8631e-05 - val_loss: 5.7377e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.8033e-05 - val_loss: 6.0446e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.5000e-05 - val_loss: 5.4983e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.3608e-05 - val_loss: 5.4196e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 6.5827e-05 - val_loss: 6.4130e-05\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.6740e-05 - val_loss: 5.3329e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 5.8878e-05 - val_loss: 6.1883e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.6215e-05 - val_loss: 8.8888e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.0976e-05 - val_loss: 5.2680e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.0356e-05 - val_loss: 5.1248e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.7614e-05 - val_loss: 5.0471e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9838e-05 - val_loss: 5.1657e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 8.4295e-05 - val_loss: 5.4123e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9100e-05 - val_loss: 4.8863e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7813e-05 - val_loss: 4.8691e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.8449e-05 - val_loss: 6.4877e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.6886e-05 - val_loss: 4.7467e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.5525e-05 - val_loss: 5.0506e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.8327e-05 - val_loss: 4.6547e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 7.1542e-05 - val_loss: 4.9075e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7421e-05 - val_loss: 4.5675e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.4468e-05 - val_loss: 4.5115e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.4190e-05 - val_loss: 5.4000e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.6295e-05 - val_loss: 4.5599e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.6465e-05 - val_loss: 5.1924e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.5070e-05 - val_loss: 5.2630e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.2531e-05 - val_loss: 6.7453e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.5490e-05 - val_loss: 4.5983e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.2817e-05 - val_loss: 4.3030e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.8616e-05 - val_loss: 1.1221e-04\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.2002e-05 - val_loss: 4.2809e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.1072e-05 - val_loss: 4.4284e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9302e-05 - val_loss: 4.7522e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.6210e-05 - val_loss: 1.1286e-04\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.2203e-05 - val_loss: 4.0532e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.0649e-05 - val_loss: 4.0713e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.2873e-05 - val_loss: 4.0027e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.0223e-05 - val_loss: 3.9655e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.7677e-05 - val_loss: 4.1744e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.1354e-05 - val_loss: 3.9205e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.7777e-05 - val_loss: 3.8381e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7207e-05 - val_loss: 5.0658e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.0256e-05 - val_loss: 4.1994e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9909e-05 - val_loss: 4.8039e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.8885e-05 - val_loss: 3.7383e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.9144e-05 - val_loss: 3.8082e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.3564e-05 - val_loss: 3.6649e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.5993e-05 - val_loss: 3.7118e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7322e-05 - val_loss: 3.8494e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.6983e-05 - val_loss: 3.6617e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 5.1913e-05 - val_loss: 4.0121e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.6844e-05 - val_loss: 3.5838e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.4652e-05 - val_loss: 3.4970e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 5.4695e-05 - val_loss: 4.1465e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.4904e-05 - val_loss: 3.4908e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.3688e-05 - val_loss: 3.4817e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.8107e-05 - val_loss: 3.4070e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.3828e-05 - val_loss: 3.4707e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.5811e-05 - val_loss: 4.3266e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.4448e-05 - val_loss: 3.3299e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.1644e-05 - val_loss: 1.6492e-04\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.8003e-05 - val_loss: 3.3141e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.2218e-05 - val_loss: 3.2597e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1790e-05 - val_loss: 3.2473e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9890e-05 - val_loss: 4.5765e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.3301e-05 - val_loss: 3.1959e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1178e-05 - val_loss: 3.1748e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.2830e-05 - val_loss: 3.9396e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.3208e-05 - val_loss: 3.4534e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1335e-05 - val_loss: 3.5341e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.9645e-05 - val_loss: 3.2049e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.0440e-05 - val_loss: 3.0679e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.0641e-05 - val_loss: 4.0009e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.7827e-05 - val_loss: 3.2083e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.9761e-05 - val_loss: 3.0048e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.9750e-05 - val_loss: 3.6335e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 5.3525e-05 - val_loss: 3.0524e-05\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.9276e-05 - val_loss: 2.9488e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8724e-05 - val_loss: 2.9617e-05\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.5041e-05 - val_loss: 3.7874e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.0159e-05 - val_loss: 3.2756e-05\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 4.4522e-05 - val_loss: 2.9640e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8584e-05 - val_loss: 3.0457e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.0426e-05 - val_loss: 5.9948e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.0597e-05 - val_loss: 2.9004e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8121e-05 - val_loss: 3.1689e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.9106e-05 - val_loss: 4.5792e-05\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.9548e-05 - val_loss: 2.7528e-05\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8872e-05 - val_loss: 7.3589e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.4570e-05 - val_loss: 2.8217e-05\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.6773e-05 - val_loss: 2.7363e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.7618e-05 - val_loss: 2.9122e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.5008e-05 - val_loss: 3.1866e-05\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8100e-05 - val_loss: 2.9701e-05\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.4963e-05 - val_loss: 3.0521e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.7135e-05 - val_loss: 3.2290e-05\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 4.0417e-05 - val_loss: 2.6863e-05\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5907e-05 - val_loss: 2.5958e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.6011e-05 - val_loss: 2.6780e-05\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5949e-05 - val_loss: 2.6514e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.1516e-05 - val_loss: 2.8045e-05\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.6572e-05 - val_loss: 3.8957e-05\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.5873e-05 - val_loss: 2.5924e-05\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.5052e-05 - val_loss: 2.4993e-05\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.4977e-05 - val_loss: 2.4925e-05\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.4331e-05 - val_loss: 2.5526e-05\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.7253e-05 - val_loss: 2.4842e-05\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.0994e-05 - val_loss: 2.6228e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.6181e-05 - val_loss: 2.4471e-05\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.6179e-05 - val_loss: 3.8053e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.6285e-05 - val_loss: 2.4422e-05\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8796e-05 - val_loss: 2.5181e-05\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5631e-05 - val_loss: 3.9913e-05\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8257e-05 - val_loss: 2.4142e-05\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.5741e-05 - val_loss: 3.2353e-05\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5045e-05 - val_loss: 2.3474e-05\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5133e-05 - val_loss: 2.6994e-05\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.9469e-05 - val_loss: 2.3451e-05\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.0736e-05 - val_loss: 2.6252e-05\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.3830e-05 - val_loss: 2.3295e-05\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 4.0598e-05 - val_loss: 2.9460e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4928e-05 - val_loss: 2.3031e-05\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.2566e-05 - val_loss: 2.2933e-05\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.1268e-05 - val_loss: 2.4447e-05\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.2765e-05 - val_loss: 2.2585e-05\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.0231e-05 - val_loss: 2.6532e-05\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3948e-05 - val_loss: 2.3351e-05\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4813e-05 - val_loss: 8.6561e-05\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.6719e-05 - val_loss: 2.2934e-05\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1756e-05 - val_loss: 2.1901e-05\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.4844e-05 - val_loss: 9.4589e-05\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.5638e-05 - val_loss: 2.1978e-05\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1533e-05 - val_loss: 2.1695e-05\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.1255e-05 - val_loss: 2.1812e-05\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5988e-05 - val_loss: 2.3158e-05\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.1711e-05 - val_loss: 2.2208e-05\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.7522e-05 - val_loss: 2.1600e-05\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0831e-05 - val_loss: 2.1165e-05\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.7989e-05 - val_loss: 2.1258e-05\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.0742e-05 - val_loss: 2.1747e-05\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.9710e-05 - val_loss: 2.1654e-05\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.1228e-05 - val_loss: 2.1122e-05\n",
      "Epoch 224/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.7290e-05 - val_loss: 2.1371e-05\n",
      "Epoch 225/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.2084e-05 - val_loss: 2.1919e-05\n",
      "Epoch 226/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.8661e-05 - val_loss: 2.0635e-05\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.0573e-05 - val_loss: 2.4817e-05\n",
      "Epoch 228/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 3.0525e-05 - val_loss: 2.0712e-05\n",
      "Epoch 229/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.1390e-05 - val_loss: 3.8795e-05\n",
      "Epoch 230/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4337e-05 - val_loss: 2.0014e-05\n",
      "Epoch 231/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 3.1664e-05 - val_loss: 2.2192e-05\n",
      "Epoch 232/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4960e-05 - val_loss: 2.0472e-05\n",
      "Epoch 233/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9544e-05 - val_loss: 1.9636e-05\n",
      "Epoch 234/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.0907e-05 - val_loss: 3.7023e-05\n",
      "Epoch 235/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.4159e-05 - val_loss: 1.9741e-05\n",
      "Epoch 236/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.7275e-05 - val_loss: 2.9745e-05\n",
      "Epoch 237/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0939e-05 - val_loss: 2.0400e-05\n",
      "Epoch 238/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.2482e-05 - val_loss: 2.1256e-05\n",
      "Epoch 239/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.5363e-05 - val_loss: 2.1736e-05\n",
      "Epoch 240/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0260e-05 - val_loss: 2.2572e-05\n",
      "Epoch 241/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4927e-05 - val_loss: 2.0989e-05\n",
      "Epoch 242/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.3270e-05 - val_loss: 8.9489e-05\n",
      "Epoch 243/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.7442e-05 - val_loss: 1.9287e-05\n",
      "Epoch 244/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9940e-05 - val_loss: 1.9396e-05\n",
      "Epoch 245/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.0425e-05 - val_loss: 1.9051e-05\n",
      "Epoch 246/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.5580e-05 - val_loss: 2.1628e-05\n",
      "Epoch 247/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8667e-05 - val_loss: 1.8629e-05\n",
      "Epoch 248/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1677e-05 - val_loss: 1.9220e-05\n",
      "Epoch 249/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8600e-05 - val_loss: 1.8259e-05\n",
      "Epoch 250/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.9452e-05 - val_loss: 2.2953e-05\n",
      "Epoch 251/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.3277e-05 - val_loss: 1.9599e-05\n",
      "Epoch 252/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0829e-05 - val_loss: 2.8015e-05\n",
      "Epoch 253/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4983e-05 - val_loss: 2.6356e-05\n",
      "Epoch 254/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.0245e-05 - val_loss: 1.8118e-05\n",
      "Epoch 255/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9733e-05 - val_loss: 2.2078e-05\n",
      "Epoch 256/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.7921e-05 - val_loss: 1.8426e-05\n",
      "Epoch 257/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7903e-05 - val_loss: 1.7841e-05\n",
      "Epoch 258/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.9558e-05 - val_loss: 2.0350e-05\n",
      "Epoch 259/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8491e-05 - val_loss: 1.7881e-05\n",
      "Epoch 260/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9206e-05 - val_loss: 1.7962e-05\n",
      "Epoch 261/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0026e-05 - val_loss: 5.2889e-05\n",
      "Epoch 262/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.4531e-05 - val_loss: 1.7944e-05\n",
      "Epoch 263/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8218e-05 - val_loss: 2.0403e-05\n",
      "Epoch 264/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.1143e-05 - val_loss: 1.7421e-05\n",
      "Epoch 265/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.1448e-05 - val_loss: 2.0334e-05\n",
      "Epoch 266/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.2139e-05 - val_loss: 2.1612e-05\n",
      "Epoch 267/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9152e-05 - val_loss: 1.7813e-05\n",
      "Epoch 268/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.4717e-05 - val_loss: 2.2089e-05\n",
      "Epoch 269/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7971e-05 - val_loss: 1.7517e-05\n",
      "Epoch 270/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.3240e-05 - val_loss: 1.7082e-05\n",
      "Epoch 271/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.6785e-05 - val_loss: 1.6656e-05\n",
      "Epoch 272/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 3.1143e-05 - val_loss: 2.8861e-05\n",
      "Epoch 273/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8380e-05 - val_loss: 1.6748e-05\n",
      "Epoch 274/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7793e-05 - val_loss: 2.9095e-05\n",
      "Epoch 275/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8518e-05 - val_loss: 1.6671e-05\n",
      "Epoch 276/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9007e-05 - val_loss: 1.8418e-05\n",
      "Epoch 277/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.3072e-05 - val_loss: 1.8517e-05\n",
      "Epoch 278/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.8230e-05 - val_loss: 1.6273e-05\n",
      "Epoch 279/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.2018e-05 - val_loss: 2.2553e-05\n",
      "Epoch 280/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.7759e-05 - val_loss: 1.6600e-05\n",
      "Epoch 281/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.2046e-05 - val_loss: 2.5220e-05\n",
      "Epoch 282/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9158e-05 - val_loss: 1.7581e-05\n",
      "Epoch 283/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7174e-05 - val_loss: 1.5974e-05\n",
      "Epoch 284/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.3742e-05 - val_loss: 1.6171e-05\n",
      "Epoch 285/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.9153e-05 - val_loss: 2.0030e-05\n",
      "Epoch 286/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.7118e-05 - val_loss: 1.5683e-05\n",
      "Epoch 287/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.5577e-05 - val_loss: 2.4579e-05\n",
      "Epoch 288/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.6796e-05 - val_loss: 1.6480e-05\n",
      "Epoch 289/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.6003e-05 - val_loss: 2.5185e-05\n",
      "Epoch 290/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.9757e-05 - val_loss: 1.5907e-05\n",
      "Epoch 291/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 2.7536e-05 - val_loss: 1.5722e-05\n",
      "Epoch 292/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.6398e-05 - val_loss: 1.5385e-05\n",
      "Epoch 293/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.5190e-05 - val_loss: 1.5356e-05\n",
      "Epoch 294/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.8474e-05 - val_loss: 3.5314e-05\n",
      "Epoch 295/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.7836e-05 - val_loss: 1.6044e-05\n",
      "Epoch 296/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.9194e-05 - val_loss: 1.5638e-05\n",
      "Epoch 297/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.6472e-05 - val_loss: 1.7543e-05\n",
      "Epoch 298/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.7809e-05 - val_loss: 1.7277e-05\n",
      "Epoch 299/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.5247e-05 - val_loss: 1.6578e-05\n",
      "Epoch 300/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8661e-05 - val_loss: 1.6943e-05\n",
      "Epoch 301/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.5397e-05 - val_loss: 1.4916e-05\n",
      "Epoch 302/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.2083e-05 - val_loss: 1.7051e-05\n",
      "Epoch 303/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.5456e-05 - val_loss: 1.5551e-05\n",
      "Epoch 304/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7437e-05 - val_loss: 1.4930e-05\n",
      "Epoch 305/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.0050e-05 - val_loss: 5.0481e-05\n",
      "Epoch 306/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.0737e-05 - val_loss: 1.5150e-05\n",
      "Epoch 307/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.4533e-05 - val_loss: 1.4571e-05\n",
      "Epoch 308/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.3458e-05 - val_loss: 3.6949e-05\n",
      "Epoch 309/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.7375e-05 - val_loss: 1.4711e-05\n",
      "Epoch 310/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4333e-05 - val_loss: 1.4699e-05\n",
      "Epoch 311/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.4667e-05 - val_loss: 1.5551e-05\n",
      "Epoch 312/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4452e-05 - val_loss: 1.4293e-05\n",
      "Epoch 313/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.4109e-05 - val_loss: 1.4602e-05\n",
      "Epoch 314/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 2.1798e-05 - val_loss: 1.6480e-05\n",
      "Epoch 315/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4608e-05 - val_loss: 1.4447e-05\n",
      "Epoch 316/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8659e-05 - val_loss: 2.4894e-05\n",
      "Epoch 317/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.5652e-05 - val_loss: 1.3998e-05\n",
      "Epoch 318/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.3108e-05 - val_loss: 1.9050e-05\n",
      "Epoch 319/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4442e-05 - val_loss: 1.3901e-05\n",
      "Epoch 320/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.5899e-05 - val_loss: 1.6078e-05\n",
      "Epoch 321/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8149e-05 - val_loss: 1.4007e-05\n",
      "Epoch 322/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4861e-05 - val_loss: 1.4779e-05\n",
      "Epoch 323/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 1.9109e-05 - val_loss: 1.6039e-05\n",
      "Epoch 324/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8450e-05 - val_loss: 1.9812e-05\n",
      "Epoch 325/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.4962e-05 - val_loss: 1.5663e-05\n",
      "Epoch 326/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.5071e-05 - val_loss: 2.0811e-05\n",
      "Epoch 327/1000\n",
      "43200/43200 [==============================] - 1s 34us/step - loss: 2.2413e-05 - val_loss: 1.4357e-05\n",
      "Epoch 328/1000\n",
      "43200/43200 [==============================] - 2s 35us/step - loss: 1.3698e-05 - val_loss: 1.4106e-05\n",
      "Epoch 329/1000\n",
      "43200/43200 [==============================] - 1s 35us/step - loss: 1.8265e-05 - val_loss: 1.8672e-05\n",
      "Epoch 00329: early stopping\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_16 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 292, 12)           60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 146, 12)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 146, 24)           1176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 73, 24)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 73, 48)            4656      \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 3504)              0         \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, 73, 48)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 73, 48)            9264      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_36 (UpSampling (None, 146, 48)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 146, 24)           4632      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_37 (UpSampling (None, 292, 24)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 292, 12)           1164      \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 292, 1)            49        \n",
      "_________________________________________________________________\n",
      "cropping1d_16 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 21,001\n",
      "Trainable params: 21,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 86us/step - loss: 0.0752 - val_loss: 0.0316\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0295 - val_loss: 0.0287\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0259 - val_loss: 0.0158\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 0.0010 - val_loss: 9.9803e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.5442e-04 - val_loss: 9.4146e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 8.5170e-04 - val_loss: 7.9783e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.6115e-04 - val_loss: 7.0785e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.6530e-04 - val_loss: 6.4528e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.3047e-04 - val_loss: 4.5874e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.5563e-04 - val_loss: 3.7042e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.4139e-04 - val_loss: 3.1053e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8741e-04 - val_loss: 2.6732e-04\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.4775e-04 - val_loss: 2.3082e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.1739e-04 - val_loss: 2.1172e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.9276e-04 - val_loss: 1.8074e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.7214e-04 - val_loss: 1.7409e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.6294e-04 - val_loss: 1.5289e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.4278e-04 - val_loss: 1.3624e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.4545e-04 - val_loss: 1.2641e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.2053e-04 - val_loss: 1.1673e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.3153e-04 - val_loss: 1.1556e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.0846e-04 - val_loss: 1.0461e-04\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.9147e-05 - val_loss: 9.8081e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.0478e-04 - val_loss: 9.8546e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.4998e-05 - val_loss: 9.0270e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.4362e-05 - val_loss: 9.1687e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.8209e-05 - val_loss: 8.2943e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 8.3565e-05 - val_loss: 7.9545e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.8188e-05 - val_loss: 8.3016e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.9167e-05 - val_loss: 2.2033e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 9.4603e-05 - val_loss: 7.3449e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.0234e-05 - val_loss: 7.0444e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.7962e-05 - val_loss: 6.8268e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.6025e-05 - val_loss: 6.6567e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.5519e-05 - val_loss: 6.4539e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.3857e-05 - val_loss: 6.4879e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.1201e-05 - val_loss: 6.2498e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 8.5338e-05 - val_loss: 6.1982e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.8372e-05 - val_loss: 5.9242e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.7751e-05 - val_loss: 6.6950e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.1867e-05 - val_loss: 5.7848e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.9250e-05 - val_loss: 6.7869e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.5245e-05 - val_loss: 5.2643e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.5148e-05 - val_loss: 9.0544e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.4294e-05 - val_loss: 5.2237e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.9424e-05 - val_loss: 5.0655e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.6460e-05 - val_loss: 5.3485e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.8175e-05 - val_loss: 4.7441e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.6738e-05 - val_loss: 4.8620e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.4810e-05 - val_loss: 5.1372e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.7750e-05 - val_loss: 6.2687e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.8049e-05 - val_loss: 4.4501e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 4.3944e-05 - val_loss: 4.5357e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 7.3822e-05 - val_loss: 1.5040e-04\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.5424e-05 - val_loss: 4.2414e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.1036e-05 - val_loss: 4.1033e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.0185e-05 - val_loss: 4.0564e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.0553e-05 - val_loss: 5.8266e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.0971e-05 - val_loss: 4.1066e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.0143e-05 - val_loss: 5.9356e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.2837e-05 - val_loss: 3.8207e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.7865e-05 - val_loss: 4.1292e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 6.3892e-05 - val_loss: 3.6975e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.6720e-05 - val_loss: 3.6781e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.7513e-05 - val_loss: 3.7983e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.7839e-05 - val_loss: 4.6169e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.8110e-05 - val_loss: 3.5114e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.4794e-05 - val_loss: 3.5512e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.3278e-05 - val_loss: 3.7723e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3735e-05 - val_loss: 3.3876e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.7273e-05 - val_loss: 5.0494e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.6020e-05 - val_loss: 3.2718e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.4188e-05 - val_loss: 4.2199e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3869e-05 - val_loss: 3.2925e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.3995e-05 - val_loss: 3.3937e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3466e-05 - val_loss: 3.1900e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.0537e-05 - val_loss: 3.1227e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.6228e-05 - val_loss: 3.8837e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.1632e-05 - val_loss: 3.0579e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.0283e-05 - val_loss: 4.0406e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.8865e-05 - val_loss: 3.0309e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 5.0031e-05 - val_loss: 4.1430e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.7339e-05 - val_loss: 2.9433e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8317e-05 - val_loss: 2.8469e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.6432e-05 - val_loss: 9.8207e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.7972e-05 - val_loss: 2.7974e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.7364e-05 - val_loss: 2.8305e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.5580e-05 - val_loss: 3.1753e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.7481e-05 - val_loss: 2.7648e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.9888e-05 - val_loss: 2.9475e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.9061e-05 - val_loss: 3.5274e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.2366e-05 - val_loss: 3.9118e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.5505e-05 - val_loss: 2.7109e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 4.1004e-05 - val_loss: 2.7818e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.7095e-05 - val_loss: 2.6784e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 4.8126e-05 - val_loss: 3.1484e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8406e-05 - val_loss: 2.5163e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.4612e-05 - val_loss: 2.5632e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.2432e-05 - val_loss: 2.4837e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.3344e-05 - val_loss: 3.0143e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.6459e-05 - val_loss: 2.4192e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.4916e-05 - val_loss: 2.6602e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.4235e-05 - val_loss: 3.2675e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.4895e-05 - val_loss: 2.3869e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.5955e-05 - val_loss: 7.1708e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.7651e-05 - val_loss: 2.5865e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.3230e-05 - val_loss: 2.4077e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.8808e-05 - val_loss: 3.2833e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.3853e-05 - val_loss: 2.2856e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 4.4747e-05 - val_loss: 5.1131e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.7121e-05 - val_loss: 2.2871e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.1955e-05 - val_loss: 2.2341e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.3607e-05 - val_loss: 4.9188e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.9734e-05 - val_loss: 2.2248e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1565e-05 - val_loss: 2.2098e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.3181e-05 - val_loss: 2.1526e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1319e-05 - val_loss: 2.1614e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 4.2066e-05 - val_loss: 2.5098e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1692e-05 - val_loss: 2.0930e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.5189e-05 - val_loss: 6.9652e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.6522e-05 - val_loss: 2.0831e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3265e-05 - val_loss: 3.8054e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.3280e-05 - val_loss: 2.0479e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8364e-05 - val_loss: 7.3167e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.5208e-05 - val_loss: 2.0874e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1377e-05 - val_loss: 4.2865e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.5457e-05 - val_loss: 2.1667e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.9722e-05 - val_loss: 1.9790e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.6680e-05 - val_loss: 2.6282e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.0474e-05 - val_loss: 1.9558e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.1409e-05 - val_loss: 5.1489e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8855e-05 - val_loss: 2.0076e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.6847e-05 - val_loss: 8.4692e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.7347e-05 - val_loss: 2.0096e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8583e-05 - val_loss: 1.9167e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.6145e-05 - val_loss: 1.9783e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.8081e-05 - val_loss: 5.2792e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.3615e-05 - val_loss: 1.9188e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.9554e-05 - val_loss: 4.6567e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.8239e-05 - val_loss: 1.8865e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8414e-05 - val_loss: 1.8041e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8016e-05 - val_loss: 1.8736e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3407e-05 - val_loss: 2.5120e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8562e-05 - val_loss: 1.8509e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.3007e-05 - val_loss: 1.8393e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.1391e-05 - val_loss: 9.2185e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.4908e-05 - val_loss: 1.7796e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.6791e-05 - val_loss: 1.7178e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.0293e-05 - val_loss: 2.7637e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.0242e-05 - val_loss: 2.1811e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.6747e-05 - val_loss: 1.8211e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.0108e-05 - val_loss: 2.4866e-05\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.3507e-05 - val_loss: 1.9868e-05\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.2129e-05 - val_loss: 1.1530e-04\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.3523e-05 - val_loss: 1.6928e-05\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.6000e-05 - val_loss: 1.6270e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 2.1733e-05 - val_loss: 2.4163e-05\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8223e-05 - val_loss: 1.6864e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.4356e-05 - val_loss: 6.1305e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.2804e-05 - val_loss: 1.6398e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.5457e-05 - val_loss: 1.5737e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.6028e-05 - val_loss: 3.0134e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.7542e-05 - val_loss: 1.6470e-05\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.5322e-05 - val_loss: 1.5489e-05\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 3.4914e-05 - val_loss: 2.8447e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.7097e-05 - val_loss: 1.5302e-05\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.4881e-05 - val_loss: 1.6577e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.8615e-05 - val_loss: 2.1253e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 38us/step - loss: 1.8505e-05 - val_loss: 2.7666e-05\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 39us/step - loss: 2.7637e-05 - val_loss: 1.6418e-05\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.8128e-05 - val_loss: 2.2564e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.7214e-05 - val_loss: 1.5038e-05\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 3.5326e-05 - val_loss: 1.8728e-05\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.5068e-05 - val_loss: 1.4585e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.4157e-05 - val_loss: 1.5527e-05\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.6218e-05 - val_loss: 4.3279e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.5560e-05 - val_loss: 1.4755e-05\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.4102e-05 - val_loss: 1.6754e-05\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.7105e-05 - val_loss: 1.5322e-05\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.4202e-05 - val_loss: 1.5355e-05\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.7704e-05 - val_loss: 2.3752e-05\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.1349e-05 - val_loss: 1.7453e-05\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 1.6559e-05 - val_loss: 1.5014e-05\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 37us/step - loss: 2.6468e-05 - val_loss: 1.8599e-05\n",
      "Epoch 00189: early stopping\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_17 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 292, 16)           80        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 146, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 146, 32)           2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 73, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 73, 64)            8256      \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4672)              0         \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 73, 64)            16448     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_38 (UpSampling (None, 146, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 146, 32)           8224      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_39 (UpSampling (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 292, 16)           2064      \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 292, 1)            65        \n",
      "_________________________________________________________________\n",
      "cropping1d_17 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 37,217\n",
      "Trainable params: 37,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 90us/step - loss: 0.0750 - val_loss: 0.0311\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0275 - val_loss: 0.0213\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 0.0011 - val_loss: 9.9736e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 9.1698e-04 - val_loss: 7.8558e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.2128e-04 - val_loss: 6.5598e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.0809e-04 - val_loss: 5.4666e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.1380e-04 - val_loss: 4.7984e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.7600e-04 - val_loss: 5.4885e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.3166e-04 - val_loss: 3.5652e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.3295e-04 - val_loss: 3.1176e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.9572e-04 - val_loss: 2.8501e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.7243e-04 - val_loss: 2.7708e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.4747e-04 - val_loss: 2.2805e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.3275e-04 - val_loss: 2.2463e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.9829e-04 - val_loss: 1.8779e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.7697e-04 - val_loss: 1.6678e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.6920e-04 - val_loss: 1.5768e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.5461e-04 - val_loss: 1.3885e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.5551e-04 - val_loss: 1.3608e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.2460e-04 - val_loss: 1.1632e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.2471e-04 - val_loss: 1.1722e-04\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.0723e-04 - val_loss: 1.2093e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.1126e-04 - val_loss: 9.5160e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.0245e-04 - val_loss: 1.1607e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 9.4785e-05 - val_loss: 8.5169e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.0056e-04 - val_loss: 8.8902e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 8.0302e-05 - val_loss: 8.0547e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 8.6295e-05 - val_loss: 9.6965e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 8.3500e-05 - val_loss: 7.4124e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.9957e-05 - val_loss: 8.2747e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.2679e-05 - val_loss: 6.6466e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 8.3188e-05 - val_loss: 6.7611e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.8984e-05 - val_loss: 6.3902e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.8227e-05 - val_loss: 6.1710e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.9861e-05 - val_loss: 6.5016e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 9.8428e-05 - val_loss: 7.0391e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.8645e-05 - val_loss: 5.6129e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 6.1083e-05 - val_loss: 5.4545e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.1291e-05 - val_loss: 6.0973e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.3364e-05 - val_loss: 5.1054e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 7.8574e-05 - val_loss: 5.5938e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 5.1139e-05 - val_loss: 4.9381e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.6448e-05 - val_loss: 6.3619e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.0898e-05 - val_loss: 4.8349e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 8.5775e-05 - val_loss: 4.7203e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.5977e-05 - val_loss: 4.5076e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.7446e-05 - val_loss: 8.8591e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 5.5272e-05 - val_loss: 4.4225e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 6.4624e-05 - val_loss: 5.9572e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.7193e-05 - val_loss: 4.2496e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.3120e-05 - val_loss: 9.4940e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.7067e-05 - val_loss: 4.1067e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.3799e-05 - val_loss: 7.7993e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.0230e-05 - val_loss: 4.1731e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.4167e-05 - val_loss: 4.1414e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.9038e-05 - val_loss: 3.8360e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 7.0902e-05 - val_loss: 4.9456e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.8776e-05 - val_loss: 3.6948e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.6041e-05 - val_loss: 7.7840e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.1738e-05 - val_loss: 3.8771e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.9546e-05 - val_loss: 5.9299e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.5665e-05 - val_loss: 3.7330e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.8496e-05 - val_loss: 1.3460e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 6.8865e-05 - val_loss: 3.4407e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.3095e-05 - val_loss: 3.3021e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.5205e-05 - val_loss: 3.6953e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 5.8793e-05 - val_loss: 1.9529e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 6.9069e-05 - val_loss: 3.2628e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.1743e-05 - val_loss: 3.1430e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.1824e-05 - val_loss: 3.8276e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.9041e-05 - val_loss: 3.1452e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.3698e-05 - val_loss: 1.0205e-04\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 7.2063e-05 - val_loss: 3.1201e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.9650e-05 - val_loss: 2.9472e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.8075e-05 - val_loss: 8.7421e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.0404e-05 - val_loss: 2.9255e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.9673e-05 - val_loss: 4.0486e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.2929e-05 - val_loss: 2.9688e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.6362e-05 - val_loss: 2.3398e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.4206e-05 - val_loss: 3.4459e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.8532e-05 - val_loss: 2.7238e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.8635e-05 - val_loss: 4.3367e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.8225e-05 - val_loss: 2.7555e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.6655e-05 - val_loss: 3.1371e-05\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.6534e-05 - val_loss: 3.2732e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.9024e-05 - val_loss: 5.8396e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.3121e-05 - val_loss: 2.8818e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.4331e-05 - val_loss: 2.8936e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.6904e-05 - val_loss: 2.9284e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.9120e-05 - val_loss: 2.9710e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.6206e-05 - val_loss: 2.4784e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.4378e-05 - val_loss: 1.6132e-04\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.3199e-05 - val_loss: 2.4752e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.6882e-05 - val_loss: 5.4264e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.5293e-05 - val_loss: 2.3598e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.4690e-05 - val_loss: 3.8547e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.4766e-05 - val_loss: 2.3214e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.3366e-05 - val_loss: 5.9615e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.9157e-05 - val_loss: 2.3275e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.2276e-05 - val_loss: 2.2416e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.2294e-05 - val_loss: 3.9439e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.1527e-05 - val_loss: 2.5001e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.2302e-05 - val_loss: 2.1828e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.2528e-05 - val_loss: 4.4785e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.7695e-05 - val_loss: 2.1624e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.9405e-05 - val_loss: 2.6619e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.7255e-05 - val_loss: 2.0945e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.5305e-05 - val_loss: 7.0774e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.9277e-05 - val_loss: 2.1027e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.3765e-05 - val_loss: 2.0947e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.8572e-05 - val_loss: 1.2042e-04\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.0071e-05 - val_loss: 2.2401e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.0067e-05 - val_loss: 2.3853e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.2041e-05 - val_loss: 2.2719e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.0532e-05 - val_loss: 1.9698e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.2036e-05 - val_loss: 2.7128e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.3625e-05 - val_loss: 1.9277e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.3600e-05 - val_loss: 1.5468e-04\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 6.9276e-05 - val_loss: 1.9660e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.8857e-05 - val_loss: 1.8765e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.8103e-05 - val_loss: 1.8458e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.2186e-05 - val_loss: 6.2231e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.5034e-05 - val_loss: 1.8402e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 6.6700e-05 - val_loss: 2.5391e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.0200e-05 - val_loss: 1.8190e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.8051e-05 - val_loss: 3.1581e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 5.8958e-05 - val_loss: 2.2545e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.7885e-05 - val_loss: 1.7567e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.7318e-05 - val_loss: 2.0239e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 3.8000e-05 - val_loss: 2.6650e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.7867e-05 - val_loss: 2.1098e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.3100e-05 - val_loss: 1.8975e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.7158e-05 - val_loss: 1.6990e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 4.7801e-05 - val_loss: 2.1269e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.8421e-05 - val_loss: 1.6741e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.6733e-05 - val_loss: 3.0662e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.5025e-05 - val_loss: 1.8435e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.6332e-05 - val_loss: 1.6036e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 4.8383e-05 - val_loss: 4.7995e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.1360e-05 - val_loss: 1.6133e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.8141e-05 - val_loss: 6.0712e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.8637e-05 - val_loss: 1.6079e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.5990e-05 - val_loss: 2.7415e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.9749e-05 - val_loss: 1.6189e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 5.9384e-05 - val_loss: 2.5315e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 1.6807e-05 - val_loss: 1.5200e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 1.5242e-05 - val_loss: 2.0408e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 3.2591e-05 - val_loss: 1.9641e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.1308e-05 - val_loss: 5.8519e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.2967e-05 - val_loss: 3.1044e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.4251e-05 - val_loss: 2.4993e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.7279e-05 - val_loss: 1.9468e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.6163e-05 - val_loss: 1.6341e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 41us/step - loss: 2.7028e-05 - val_loss: 2.1239e-05\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.4478e-05 - val_loss: 2.0604e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 40us/step - loss: 2.1055e-05 - val_loss: 3.0041e-05\n",
      "Epoch 00160: early stopping\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_18 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 292, 20)           100       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 146, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 146, 40)           3240      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 73, 40)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 73, 80)            12880     \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 5840)              0         \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 73, 80)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 73, 80)            25680     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_40 (UpSampling (None, 146, 80)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 146, 40)           12840     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_41 (UpSampling (None, 292, 40)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 292, 20)           3220      \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 292, 1)            81        \n",
      "_________________________________________________________________\n",
      "cropping1d_18 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 58,041\n",
      "Trainable params: 58,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 97us/step - loss: 0.0649 - val_loss: 0.0282\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 46us/step - loss: 0.0184 - val_loss: 0.0043\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 0.0010 - val_loss: 9.9740e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.8555e-04 - val_loss: 9.0243e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.1099e-04 - val_loss: 6.6857e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.2002e-04 - val_loss: 4.7605e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.2854e-04 - val_loss: 3.9652e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.4061e-04 - val_loss: 3.0782e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 46us/step - loss: 2.8616e-04 - val_loss: 2.5808e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3140e-04 - val_loss: 2.2008e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9800e-04 - val_loss: 1.7091e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.6989e-04 - val_loss: 1.7762e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5216e-04 - val_loss: 1.5397e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3093e-04 - val_loss: 1.2526e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2116e-04 - val_loss: 1.1240e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1055e-04 - val_loss: 1.0097e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 1.0634e-0 - 2s 45us/step - loss: 1.0626e-04 - val_loss: 8.9698e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.9649e-05 - val_loss: 8.8100e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.4718e-05 - val_loss: 7.7592e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.4560e-05 - val_loss: 7.7796e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.0792e-05 - val_loss: 8.7030e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6415e-05 - val_loss: 6.3082e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.0299e-05 - val_loss: 9.7221e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.5267e-05 - val_loss: 5.7284e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.5317e-05 - val_loss: 6.1177e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.9467e-05 - val_loss: 5.2229e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.1549e-05 - val_loss: 7.1495e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.2482e-05 - val_loss: 5.0113e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7289e-05 - val_loss: 4.5890e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.5267e-05 - val_loss: 5.6344e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7577e-05 - val_loss: 7.9025e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.0186e-05 - val_loss: 4.2252e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.6948e-05 - val_loss: 5.5939e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.5166e-05 - val_loss: 4.2191e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.8798e-05 - val_loss: 3.9700e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.0170e-05 - val_loss: 5.1843e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.9104e-05 - val_loss: 4.5473e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.2050e-05 - val_loss: 3.6856e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.3883e-05 - val_loss: 4.4805e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.8493e-05 - val_loss: 3.8331e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.0577e-05 - val_loss: 3.6524e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7943e-05 - val_loss: 3.9292e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.5255e-05 - val_loss: 3.2923e-05\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6248e-05 - val_loss: 3.7419e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.2217e-05 - val_loss: 3.0413e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.2720e-05 - val_loss: 9.2055e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.3308e-05 - val_loss: 3.1691e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.4163e-05 - val_loss: 5.8123e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.3067e-05 - val_loss: 3.4691e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.6703e-05 - val_loss: 2.8826e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.9013e-05 - val_loss: 3.1640e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.9502e-05 - val_loss: 9.1328e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.6717e-05 - val_loss: 2.6426e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.5637e-05 - val_loss: 2.5394e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.1763e-05 - val_loss: 1.0426e-04\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.4833e-05 - val_loss: 2.5093e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.9879e-05 - val_loss: 7.6248e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.2873e-05 - val_loss: 2.3945e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3941e-05 - val_loss: 3.1759e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.1950e-05 - val_loss: 2.4861e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3160e-05 - val_loss: 2.2791e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.6427e-05 - val_loss: 3.3205e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.4135e-05 - val_loss: 2.6674e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.6784e-05 - val_loss: 2.2328e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.2060e-05 - val_loss: 2.5263e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.1769e-05 - val_loss: 2.2746e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1692e-05 - val_loss: 2.1504e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.3229e-05 - val_loss: 2.7058e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3037e-05 - val_loss: 3.2337e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.1470e-05 - val_loss: 2.0842e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.8204e-05 - val_loss: 6.2021e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.6633e-05 - val_loss: 2.0535e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.3048e-05 - val_loss: 3.5177e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1814e-05 - val_loss: 2.3011e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7998e-05 - val_loss: 2.4914e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1427e-05 - val_loss: 5.2645e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.8246e-05 - val_loss: 1.8557e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8226e-05 - val_loss: 1.8915e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.8498e-05 - val_loss: 3.1151e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9417e-05 - val_loss: 1.8239e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.1601e-05 - val_loss: 2.1914e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.4615e-05 - val_loss: 1.8169e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7505e-05 - val_loss: 2.0013e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.0860e-05 - val_loss: 1.7777e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9749e-05 - val_loss: 6.2348e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.1830e-05 - val_loss: 1.8785e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.2516e-05 - val_loss: 1.2333e-04\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.1139e-05 - val_loss: 1.6923e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5972e-05 - val_loss: 1.9231e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6914e-05 - val_loss: 1.9661e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7091e-05 - val_loss: 1.5863e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5357e-05 - val_loss: 1.5816e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.6160e-05 - val_loss: 2.8606e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7613e-05 - val_loss: 1.5865e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.0960e-05 - val_loss: 3.1161e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7717e-05 - val_loss: 1.5242e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.6854e-05 - val_loss: 3.8763e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1108e-05 - val_loss: 1.6181e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8788e-05 - val_loss: 1.1867e-04\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.6751e-05 - val_loss: 1.5295e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4367e-05 - val_loss: 1.4370e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.2998e-05 - val_loss: 2.4308e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7459e-05 - val_loss: 1.4341e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3610e-05 - val_loss: 1.3924e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.9705e-05 - val_loss: 2.5998e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5137e-05 - val_loss: 1.5349e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.0698e-05 - val_loss: 2.3962e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4820e-05 - val_loss: 1.3490e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3028e-05 - val_loss: 1.3186e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.6089e-05 - val_loss: 1.7825e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8921e-05 - val_loss: 1.2968e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.4899e-05 - val_loss: 1.6201e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8624e-05 - val_loss: 3.8903e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.9880e-05 - val_loss: 1.4229e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.4738e-05 - val_loss: 3.9979e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7719e-05 - val_loss: 1.3014e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.1191e-05 - val_loss: 1.5005e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.2866e-05 - val_loss: 1.3122e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1995e-05 - val_loss: 1.2229e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.2543e-05 - val_loss: 2.7645e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4356e-05 - val_loss: 1.2229e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2720e-05 - val_loss: 4.7768e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.7268e-05 - val_loss: 1.2812e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1784e-05 - val_loss: 1.1643e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1238e-05 - val_loss: 1.3058e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.4103e-05 - val_loss: 1.8926e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2188e-05 - val_loss: 1.1275e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0901e-05 - val_loss: 1.1259e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.0806e-05 - val_loss: 3.3426e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9837e-05 - val_loss: 1.1358e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0837e-05 - val_loss: 1.1543e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.4902e-05 - val_loss: 2.1703e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1802e-05 - val_loss: 1.1164e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0570e-05 - val_loss: 1.0967e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.9508e-05 - val_loss: 1.8277e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2508e-05 - val_loss: 1.0516e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1042e-05 - val_loss: 1.8702e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.1663e-05 - val_loss: 1.1233e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2653e-05 - val_loss: 5.2918e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.5219e-05 - val_loss: 1.3392e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0380e-05 - val_loss: 1.0143e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.8422e-05 - val_loss: 1.9848e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3597e-05 - val_loss: 1.0297e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0018e-05 - val_loss: 1.4825e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.0343e-05 - val_loss: 1.3430e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0662e-05 - val_loss: 1.3051e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.9066e-05 - val_loss: 1.4310e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0543e-05 - val_loss: 9.7068e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5293e-05 - val_loss: 3.2763e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3579e-05 - val_loss: 1.1343e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.6952e-05 - val_loss: 2.8613e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2129e-05 - val_loss: 1.0033e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.8547e-05 - val_loss: 4.4776e-05\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8076e-05 - val_loss: 9.8643e-06\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.0092e-06 - val_loss: 9.0506e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.2466e-05 - val_loss: 2.7146e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1723e-05 - val_loss: 9.1754e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.6173e-06 - val_loss: 8.8627e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.6379e-05 - val_loss: 1.0553e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3380e-05 - val_loss: 8.7215e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8876e-05 - val_loss: 2.1259e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2490e-05 - val_loss: 1.1998e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3285e-05 - val_loss: 1.3833e-05\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9869e-05 - val_loss: 7.4376e-05\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.6617e-05 - val_loss: 8.7974e-06\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3334e-05 - val_loss: 1.7027e-05\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2357e-05 - val_loss: 9.5396e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.5074e-05 - val_loss: 6.2421e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8414e-05 - val_loss: 8.2420e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.9761e-06 - val_loss: 8.2544e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.0536e-05 - val_loss: 1.8349e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0297e-05 - val_loss: 8.1049e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6744e-06 - val_loss: 7.8663e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.5865e-05 - val_loss: 2.2225e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0696e-05 - val_loss: 8.1409e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 1.7883e-0 - 2s 45us/step - loss: 1.8181e-05 - val_loss: 8.8095e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8273e-05 - val_loss: 8.1191e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.8620e-06 - val_loss: 1.4814e-05\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.8495e-05 - val_loss: 9.1243e-06\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6802e-06 - val_loss: 7.6831e-06\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.4570e-05 - val_loss: 1.7024e-05\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.6066e-06 - val_loss: 7.5853e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.8725e-06 - val_loss: 1.1323e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1841e-05 - val_loss: 1.0352e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.8384e-06 - val_loss: 7.5708e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7000e-05 - val_loss: 1.9786e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.6037e-06 - val_loss: 7.2746e-06\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.9770e-06 - val_loss: 7.2660e-06\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0367e-05 - val_loss: 6.7252e-05\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3218e-05 - val_loss: 7.4698e-06\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.9497e-06 - val_loss: 6.9242e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.9771e-05 - val_loss: 2.0551e-05\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.7417e-06 - val_loss: 7.2600e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.6309e-06 - val_loss: 7.0133e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.4140e-05 - val_loss: 1.1369e-05\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.7622e-06 - val_loss: 6.8097e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1894e-05 - val_loss: 2.3694e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.4117e-06 - val_loss: 6.7880e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.6503e-06 - val_loss: 7.5561e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.2788e-05 - val_loss: 2.3004e-05\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0439e-05 - val_loss: 6.8574e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.3832e-06 - val_loss: 6.5351e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.2030e-06 - val_loss: 6.6138e-06\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.1116e-05 - val_loss: 9.9759e-06\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.6935e-06 - val_loss: 6.4218e-06\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.3923e-06 - val_loss: 8.9621e-06\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4826e-05 - val_loss: 9.2169e-06\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.1260e-06 - val_loss: 2.0534e-05\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.7643e-05 - val_loss: 8.0376e-06\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.1814e-06 - val_loss: 6.0759e-06\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.2914e-05 - val_loss: 1.8765e-05\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.2311e-06 - val_loss: 6.8949e-06\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.8894e-06 - val_loss: 5.8921e-06\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.7553e-05 - val_loss: 1.9282e-05\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.5678e-06 - val_loss: 6.3150e-06\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.7219e-06 - val_loss: 5.8180e-06\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.3317e-06 - val_loss: 3.7594e-05\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8480e-05 - val_loss: 6.4956e-06\n",
      "Epoch 224/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.7874e-06 - val_loss: 7.2725e-06\n",
      "Epoch 225/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 2.0192e-0 - 2s 45us/step - loss: 2.0134e-05 - val_loss: 7.6129e-06\n",
      "Epoch 226/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.1605e-06 - val_loss: 6.7168e-06\n",
      "Epoch 227/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7012e-05 - val_loss: 7.1478e-06\n",
      "Epoch 228/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.0284e-06 - val_loss: 7.7284e-06\n",
      "Epoch 229/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.3081e-05 - val_loss: 7.0614e-06\n",
      "Epoch 230/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.7282e-06 - val_loss: 5.6472e-06\n",
      "Epoch 231/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9411e-05 - val_loss: 1.3942e-05\n",
      "Epoch 232/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.5829e-06 - val_loss: 5.8692e-06\n",
      "Epoch 233/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.2562e-05 - val_loss: 1.1986e-05\n",
      "Epoch 234/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.5509e-06 - val_loss: 5.3899e-06\n",
      "Epoch 235/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.1470e-06 - val_loss: 6.1344e-06\n",
      "Epoch 236/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.3517e-05 - val_loss: 6.2281e-06\n",
      "Epoch 237/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.6493e-06 - val_loss: 5.2870e-06\n",
      "Epoch 238/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.0402e-06 - val_loss: 5.2019e-06\n",
      "Epoch 239/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.9492e-05 - val_loss: 1.8990e-05\n",
      "Epoch 240/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.5377e-06 - val_loss: 5.7178e-06\n",
      "Epoch 241/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.3207e-06 - val_loss: 9.8903e-06\n",
      "Epoch 242/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1150e-05 - val_loss: 6.7362e-06\n",
      "Epoch 243/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.4374e-06 - val_loss: 5.2264e-06\n",
      "Epoch 244/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5829e-05 - val_loss: 9.9531e-06\n",
      "Epoch 245/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.0969e-06 - val_loss: 4.9799e-06\n",
      "Epoch 246/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7908e-05 - val_loss: 1.2493e-05\n",
      "Epoch 247/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.6688e-06 - val_loss: 5.2465e-06\n",
      "Epoch 248/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5017e-05 - val_loss: 1.5964e-05\n",
      "Epoch 249/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.2268e-06 - val_loss: 5.4319e-06\n",
      "Epoch 250/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.9018e-06 - val_loss: 4.5440e-05\n",
      "Epoch 251/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7434e-05 - val_loss: 5.1450e-06\n",
      "Epoch 252/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.9193e-06 - val_loss: 5.6142e-06\n",
      "Epoch 253/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8796e-05 - val_loss: 5.5851e-06\n",
      "Epoch 254/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.2827e-06 - val_loss: 4.8761e-06\n",
      "Epoch 255/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7594e-05 - val_loss: 5.2669e-06\n",
      "Epoch 256/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.0312e-06 - val_loss: 4.6163e-06\n",
      "Epoch 257/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8769e-05 - val_loss: 1.0615e-05\n",
      "Epoch 258/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0508e-05 - val_loss: 4.9395e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.4874e-06 - val_loss: 4.6283e-06\n",
      "Epoch 260/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5087e-05 - val_loss: 6.8656e-06\n",
      "Epoch 261/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.7784e-06 - val_loss: 4.5800e-06\n",
      "Epoch 262/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1646e-05 - val_loss: 5.6286e-06\n",
      "Epoch 263/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.2336e-06 - val_loss: 2.6298e-05\n",
      "Epoch 264/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 9.4871e-06 - val_loss: 6.0999e-06\n",
      "Epoch 265/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1253e-05 - val_loss: 3.4338e-05\n",
      "Epoch 266/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1074e-05 - val_loss: 4.9225e-06\n",
      "Epoch 267/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.2486e-06 - val_loss: 4.2912e-06\n",
      "Epoch 268/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.7046e-05 - val_loss: 2.0382e-05\n",
      "Epoch 269/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.1890e-06 - val_loss: 4.6705e-06\n",
      "Epoch 270/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.2282e-06 - val_loss: 4.6338e-06\n",
      "Epoch 271/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4479e-05 - val_loss: 5.7496e-06\n",
      "Epoch 272/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.9042e-06 - val_loss: 7.0800e-06\n",
      "Epoch 273/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 8.4400e-06 - val_loss: 1.6089e-05\n",
      "Epoch 274/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 2.1512e-05 - val_loss: 5.2675e-06\n",
      "Epoch 275/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.3543e-06 - val_loss: 4.1783e-06\n",
      "Epoch 276/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.7994e-06 - val_loss: 1.8396e-05\n",
      "Epoch 277/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.3521e-05 - val_loss: 4.2394e-06\n",
      "Epoch 278/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.8428e-06 - val_loss: 9.5965e-06\n",
      "Epoch 279/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.8930e-05 - val_loss: 4.9468e-06\n",
      "Epoch 280/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.0650e-06 - val_loss: 3.9408e-06\n",
      "Epoch 281/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.4108e-05 - val_loss: 5.7806e-06\n",
      "Epoch 282/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 5.2629e-06 - val_loss: 4.3771e-06\n",
      "Epoch 283/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 7.2163e-06 - val_loss: 2.6436e-05\n",
      "Epoch 284/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.1141e-05 - val_loss: 4.5061e-06\n",
      "Epoch 285/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.0619e-05 - val_loss: 8.5014e-05\n",
      "Epoch 286/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.5340e-05 - val_loss: 4.2075e-06\n",
      "Epoch 287/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 3.8346e-06 - val_loss: 4.6141e-06\n",
      "Epoch 288/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 1.2373e-05 - val_loss: 1.4059e-05\n",
      "Epoch 289/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 6.2364e-06 - val_loss: 5.2498e-06\n",
      "Epoch 290/1000\n",
      "43200/43200 [==============================] - 2s 45us/step - loss: 4.5111e-06 - val_loss: 4.3613e-06\n",
      "Epoch 00290: early stopping\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_19 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 292, 24)           120       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 146, 24)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 146, 48)           4656      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 73, 48)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 73, 96)            18528     \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7008)              0         \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 73, 96)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 73, 96)            36960     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_42 (UpSampling (None, 146, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 146, 48)           18480     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_43 (UpSampling (None, 292, 48)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 292, 24)           4632      \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 292, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_19 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 83,473\n",
      "Trainable params: 83,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 99us/step - loss: 0.0491 - val_loss: 0.0295\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0273 - val_loss: 0.0196\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.6014e-04 - val_loss: 9.6844e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.0974e-04 - val_loss: 6.6526e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.1757e-04 - val_loss: 5.3614e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.5901e-04 - val_loss: 3.8662e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.0427e-04 - val_loss: 3.3004e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.9490e-04 - val_loss: 2.5157e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.5751e-04 - val_loss: 4.2917e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.0480e-04 - val_loss: 1.6078e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.4484e-04 - val_loss: 1.8999e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.6693e-04 - val_loss: 1.0695e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.0020e-04 - val_loss: 9.2031e-05\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.0738e-04 - val_loss: 8.5689e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.7655e-05 - val_loss: 3.6868e-04\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.0498e-04 - val_loss: 6.8563e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.3686e-05 - val_loss: 6.1069e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 7.6970e-05 - val_loss: 3.0972e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.5600e-05 - val_loss: 5.6352e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.3258e-05 - val_loss: 5.2428e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.3179e-05 - val_loss: 6.5872e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.0320e-05 - val_loss: 4.9118e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.7300e-05 - val_loss: 4.8460e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.1893e-05 - val_loss: 5.1211e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.5234e-05 - val_loss: 4.4148e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.2618e-05 - val_loss: 6.1242e-050s - loss: 4.2383\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.4269e-04 - val_loss: 4.5402e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.2305e-05 - val_loss: 4.0441e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.9327e-05 - val_loss: 3.9681e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 7.3091e-05 - val_loss: 1.6161e-04\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.9582e-05 - val_loss: 3.7235e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.6198e-05 - val_loss: 3.5938e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.1032e-05 - val_loss: 1.3544e-04\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.4902e-05 - val_loss: 3.7942e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.2643e-05 - val_loss: 5.5198e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.2462e-05 - val_loss: 4.0053e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.7129e-05 - val_loss: 1.6513e-04\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.5852e-05 - val_loss: 3.6608e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.2154e-05 - val_loss: 3.1347e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.0450e-05 - val_loss: 3.0438e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.5244e-05 - val_loss: 3.5766e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.2574e-05 - val_loss: 3.1186e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.9392e-05 - val_loss: 2.9100e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.1413e-05 - val_loss: 4.0595e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.9966e-05 - val_loss: 2.8632e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8075e-05 - val_loss: 2.7702e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.3324e-04 - val_loss: 7.5277e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.5592e-05 - val_loss: 2.7505e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6430e-05 - val_loss: 2.6262e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.5637e-05 - val_loss: 2.6111e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.3815e-05 - val_loss: 9.5450e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.4703e-05 - val_loss: 2.5800e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.4647e-05 - val_loss: 2.5057e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.7762e-05 - val_loss: 6.3554e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.9009e-05 - val_loss: 2.4500e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.2204e-05 - val_loss: 1.8722e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.0043e-05 - val_loss: 2.5048e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.3648e-05 - val_loss: 2.3146e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.2683e-05 - val_loss: 2.4399e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.9306e-05 - val_loss: 2.2691e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.1727e-05 - val_loss: 2.2336e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 7.9108e-0 - 2s 48us/step - loss: 7.8873e-05 - val_loss: 2.8151e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.4084e-05 - val_loss: 2.1534e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.1007e-05 - val_loss: 2.1125e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 7.9697e-05 - val_loss: 3.5662e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.3723e-05 - val_loss: 2.1408e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.0319e-05 - val_loss: 2.0415e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.2517e-05 - val_loss: 2.8378e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.5413e-05 - val_loss: 2.0802e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.9724e-05 - val_loss: 2.0121e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.9748e-05 - val_loss: 3.2393e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.3679e-05 - val_loss: 2.2006e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.9656e-05 - val_loss: 2.5797e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 5.2964e-05 - val_loss: 2.6393e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.0616e-05 - val_loss: 3.0236e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.0943e-05 - val_loss: 2.2840e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.8728e-05 - val_loss: 1.8126e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7731e-05 - val_loss: 1.7978e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.0462e-05 - val_loss: 5.9579e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.4334e-05 - val_loss: 1.7820e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.1307e-05 - val_loss: 1.2255e-04\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.7853e-05 - val_loss: 1.8131e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.7189e-05 - val_loss: 1.7387e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.8876e-05 - val_loss: 2.2511e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.7648e-05 - val_loss: 1.6644e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7302e-05 - val_loss: 4.9847e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.4463e-05 - val_loss: 1.7019e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.5918e-05 - val_loss: 1.6152e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 6.3421e-05 - val_loss: 3.5035e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.8508e-05 - val_loss: 1.5845e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.7122e-05 - val_loss: 4.3558e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.8577e-05 - val_loss: 1.8312e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.0575e-05 - val_loss: 1.5355e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.0225e-05 - val_loss: 8.2087e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.5042e-05 - val_loss: 1.5538e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.5492e-05 - val_loss: 2.4716e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7358e-05 - val_loss: 1.4738e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.4312e-05 - val_loss: 2.2901e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.4780e-05 - val_loss: 1.7376e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.5276e-05 - val_loss: 1.4250e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.3729e-05 - val_loss: 1.4368e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8382e-05 - val_loss: 2.1566e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.4542e-05 - val_loss: 4.2628e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7425e-05 - val_loss: 1.3694e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.6431e-05 - val_loss: 1.8112e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.8068e-05 - val_loss: 1.3710e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.3045e-05 - val_loss: 1.3044e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 4.8834e-05 - val_loss: 5.0282e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7761e-05 - val_loss: 1.3164e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.2667e-05 - val_loss: 1.3174e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.3875e-05 - val_loss: 2.1648e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.4612e-05 - val_loss: 1.3083e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.1923e-05 - val_loss: 1.7142e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.4743e-05 - val_loss: 2.0685e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8569e-05 - val_loss: 1.2489e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.3055e-05 - val_loss: 2.4504e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6899e-05 - val_loss: 1.2110e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.1633e-05 - val_loss: 1.2206e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.5331e-05 - val_loss: 1.7699e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.3340e-05 - val_loss: 1.1655e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.1308e-05 - val_loss: 1.1370e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.5006e-05 - val_loss: 6.8237e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.9339e-05 - val_loss: 1.1811e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.1161e-05 - val_loss: 1.1191e-05\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2682e-05 - val_loss: 1.9188e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.7687e-05 - val_loss: 1.3994e-05\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.4046e-05 - val_loss: 9.4244e-05\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.8083e-05 - val_loss: 1.3031e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.1125e-05 - val_loss: 1.0689e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.3163e-05 - val_loss: 1.1722e-04\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.5463e-05 - val_loss: 1.0882e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0216e-05 - val_loss: 1.0324e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.9515e-05 - val_loss: 2.6135e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.5482e-05 - val_loss: 1.0968e-05\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0415e-05 - val_loss: 1.0420e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.0092e-05 - val_loss: 1.0624e-05\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.0451e-05 - val_loss: 1.1523e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.1138e-05 - val_loss: 1.0088e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.7081e-06 - val_loss: 1.0243e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 4.9620e-05 - val_loss: 5.3330e-05\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.7756e-05 - val_loss: 1.0325e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.4850e-06 - val_loss: 9.5979e-06\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.2817e-06 - val_loss: 1.0753e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.8264e-05 - val_loss: 1.1473e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.7216e-06 - val_loss: 9.1583e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.2769e-05 - val_loss: 2.6541e-05\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2267e-05 - val_loss: 9.2844e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.8173e-05 - val_loss: 1.2425e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.9319e-06 - val_loss: 9.1476e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.9739e-05 - val_loss: 2.5153e-05\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.1844e-05 - val_loss: 1.0429e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.0718e-05 - val_loss: 1.2650e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.3495e-05 - val_loss: 4.3569e-05\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.9952e-05 - val_loss: 2.7599e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.4122e-05 - val_loss: 8.6811e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.5486e-05 - val_loss: 4.5742e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.6492e-05 - val_loss: 9.8669e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.1028e-06 - val_loss: 1.0466e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.7165e-05 - val_loss: 1.4667e-05\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 9.4525e-06 - val_loss: 8.5045e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.1428e-06 - val_loss: 8.2388e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.9309e-05 - val_loss: 2.5479e-05\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.1052e-05 - val_loss: 8.0968e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.8729e-06 - val_loss: 8.9319e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 3.9016e-05 - val_loss: 1.3497e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.1934e-06 - val_loss: 7.9194e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.7461e-06 - val_loss: 1.5572e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.7378e-05 - val_loss: 8.2172e-06\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5060e-05 - val_loss: 1.4876e-05\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.7207e-06 - val_loss: 7.5532e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.2545e-06 - val_loss: 7.4274e-06\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.5602e-05 - val_loss: 3.3528e-05\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.0800e-05 - val_loss: 7.7924e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.2395e-06 - val_loss: 7.4457e-06\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6477e-05 - val_loss: 1.2043e-05\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.7516e-06 - val_loss: 7.0757e-06\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.4756e-05 - val_loss: 3.1306e-05\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.0996e-05 - val_loss: 7.7087e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 8.0245e-06 - val_loss: 3.1365e-05\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.8770e-05 - val_loss: 9.0852e-06\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 7.0819e-06 - val_loss: 7.1485e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.7790e-05 - val_loss: 1.4985e-05\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 7.8806e-06 - val_loss: 6.6586e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.4975e-05 - val_loss: 3.6638e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.2705e-05 - val_loss: 7.1206e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 2.5925e-05 - val_loss: 2.4165e-05\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 9.3660e-06 - val_loss: 6.7724e-06\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.3644e-05 - val_loss: 3.3463e-05\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.3866e-05 - val_loss: 6.6443e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.2318e-06 - val_loss: 6.2107e-06\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 3.2385e-05 - val_loss: 2.3356e-05\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.1909e-05 - val_loss: 6.3016e-06\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 5.9541e-06 - val_loss: 6.0640e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 1.5391e-05 - val_loss: 1.4704e-05\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 2s 48us/step - loss: 7.3163e-06 - val_loss: 8.1762e-06\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.9756e-05 - val_loss: 9.8866e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.6138e-06 - val_loss: 7.9684e-06\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.6496e-05 - val_loss: 8.7785e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 6.4489e-06 - val_loss: 1.2484e-05\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.4512e-05 - val_loss: 7.0415e-06\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 1.6457e-05 - val_loss: 1.8920e-05\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 8.1063e-06 - val_loss: 7.2888e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 2s 49us/step - loss: 2.7727e-05 - val_loss: 8.6884e-06\n",
      "Epoch 00208: early stopping\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_20 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 292, 28)           140       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 146, 28)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 146, 56)           6328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 73, 56)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 73, 112)           25200     \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 8176)              0         \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 73, 112)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 73, 112)           50288     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_44 (UpSampling (None, 146, 112)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 146, 56)           25144     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_45 (UpSampling (None, 292, 56)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 292, 28)           6300      \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 292, 1)            113       \n",
      "_________________________________________________________________\n",
      "cropping1d_20 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 113,513\n",
      "Trainable params: 113,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 4s 97us/step - loss: 0.0501 - val_loss: 0.0292\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0288 - val_loss: 0.0285\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0195 - val_loss: 0.0050\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.8509e-04 - val_loss: 8.7841e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.8178e-04 - val_loss: 6.5834e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.8370e-04 - val_loss: 5.1123e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.5850e-04 - val_loss: 4.3379e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.9224e-04 - val_loss: 3.3517e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.3051e-04 - val_loss: 2.7892e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.5504e-04 - val_loss: 2.1835e-04\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.8605e-04 - val_loss: 1.8690e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7004e-04 - val_loss: 1.5569e-04\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4467e-04 - val_loss: 1.4103e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.3573e-04 - val_loss: 1.1360e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1438e-04 - val_loss: 1.2782e-04\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2521e-04 - val_loss: 8.6441e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0373e-04 - val_loss: 2.0681e-04\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.6666e-05 - val_loss: 6.8137e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.5830e-05 - val_loss: 2.0106e-04\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2564e-04 - val_loss: 6.2139e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.4147e-05 - val_loss: 5.3573e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.8192e-05 - val_loss: 1.6618e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.4431e-05 - val_loss: 4.8468e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.6489e-05 - val_loss: 9.5817e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.0843e-05 - val_loss: 4.3600e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.8777e-05 - val_loss: 4.3614e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.9318e-05 - val_loss: 2.3120e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.9071e-05 - val_loss: 4.0441e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.7174e-05 - val_loss: 4.0078e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.3745e-05 - val_loss: 3.7977e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.6517e-05 - val_loss: 3.7299e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.8644e-05 - val_loss: 3.8983e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.2762e-05 - val_loss: 3.2250e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.8419e-05 - val_loss: 7.3077e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.3631e-05 - val_loss: 3.1849e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.9948e-05 - val_loss: 2.9863e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.3778e-05 - val_loss: 7.8748e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.1393e-05 - val_loss: 2.9711e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.4269e-05 - val_loss: 4.1153e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.1366e-05 - val_loss: 2.9882e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.8076e-05 - val_loss: 2.0080e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.7411e-05 - val_loss: 2.6919e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.7176e-05 - val_loss: 4.4683e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.3583e-05 - val_loss: 5.5774e-04\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.8033e-05 - val_loss: 2.7945e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4957e-05 - val_loss: 2.4486e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.3632e-05 - val_loss: 2.5277e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.4162e-05 - val_loss: 3.0431e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4604e-05 - val_loss: 2.3080e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.5773e-05 - val_loss: 4.0251e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4813e-05 - val_loss: 2.2364e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.5432e-05 - val_loss: 6.5488e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8959e-05 - val_loss: 2.1861e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.6702e-05 - val_loss: 1.1455e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.2438e-05 - val_loss: 2.4681e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1195e-05 - val_loss: 2.0568e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.4849e-05 - val_loss: 3.2267e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.5901e-05 - val_loss: 2.0602e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4101e-05 - val_loss: 8.2957e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.9648e-05 - val_loss: 2.2608e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.1214e-05 - val_loss: 3.1369e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1082e-05 - val_loss: 1.9640e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.4804e-05 - val_loss: 6.3340e-04\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.9134e-05 - val_loss: 2.0672e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9160e-05 - val_loss: 1.8404e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7541e-05 - val_loss: 1.7765e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7335e-05 - val_loss: 1.7420e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.7009e-05 - val_loss: 3.1250e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.0956e-05 - val_loss: 1.7603e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.8000e-05 - val_loss: 3.1150e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.8367e-05 - val_loss: 2.0467e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7114e-05 - val_loss: 1.9448e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.1817e-05 - val_loss: 2.5286e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.7009e-05 - val_loss: 1.7179e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.0306e-05 - val_loss: 3.2444e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7511e-05 - val_loss: 1.5922e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.9067e-05 - val_loss: 3.0559e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7201e-05 - val_loss: 1.6667e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.6975e-05 - val_loss: 1.8752e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7959e-05 - val_loss: 1.5479e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.0378e-05 - val_loss: 1.0794e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.6739e-05 - val_loss: 1.6056e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4135e-05 - val_loss: 1.4331e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.3063e-05 - val_loss: 2.1440e-04\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4138e-04 - val_loss: 1.9918e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.4837e-05 - val_loss: 1.3865e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.3212e-05 - val_loss: 1.3326e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2899e-05 - val_loss: 1.3935e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.3891e-05 - val_loss: 1.3776e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.7988e-05 - val_loss: 2.8430e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9110e-05 - val_loss: 1.3777e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.2767e-05 - val_loss: 1.5541e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 5.3699e-05 - val_loss: 1.5414e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.2946e-05 - val_loss: 1.2151e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.1134e-05 - val_loss: 3.0729e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.3951e-05 - val_loss: 1.3179e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 4.0936e-05 - val_loss: 3.3630e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7634e-05 - val_loss: 1.2507e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.9122e-05 - val_loss: 1.2238e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.5438e-05 - val_loss: 1.1763e-05\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4175e-05 - val_loss: 7.5459e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.7450e-05 - val_loss: 1.3565e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1425e-05 - val_loss: 1.0910e-05\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 3.0161e-05 - val_loss: 1.7787e-04\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8597e-05 - val_loss: 1.1241e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0486e-05 - val_loss: 1.1942e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.6200e-05 - val_loss: 1.8732e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1693e-05 - val_loss: 1.0698e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.4640e-05 - val_loss: 4.8016e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7205e-05 - val_loss: 1.0716e-05\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0366e-05 - val_loss: 1.5607e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.5303e-05 - val_loss: 1.2562e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0213e-05 - val_loss: 1.0850e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.3404e-05 - val_loss: 2.1631e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1569e-05 - val_loss: 1.0019e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.9205e-05 - val_loss: 3.4920e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4788e-05 - val_loss: 1.0960e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.7096e-05 - val_loss: 2.7183e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2817e-05 - val_loss: 1.8443e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.0541e-05 - val_loss: 1.1147e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 9.8425e-06 - val_loss: 9.0758e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.5591e-05 - val_loss: 3.1841e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.2385e-05 - val_loss: 9.4892e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.9087e-05 - val_loss: 1.5405e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4720e-05 - val_loss: 8.9328e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.5224e-05 - val_loss: 1.1534e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1665e-05 - val_loss: 8.5314e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.1286e-06 - val_loss: 9.3778e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.2338e-05 - val_loss: 2.4434e-05\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0706e-05 - val_loss: 8.7667e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.1127e-06 - val_loss: 1.6637e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.2872e-05 - val_loss: 1.2274e-05\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.9225e-06 - val_loss: 7.8282e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.4774e-06 - val_loss: 7.5895e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.3068e-06 - val_loss: 7.8462e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.3195e-05 - val_loss: 2.4949e-05\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4227e-05 - val_loss: 7.9392e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.3060e-06 - val_loss: 7.2621e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.8021e-05 - val_loss: 1.5393e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0278e-05 - val_loss: 7.3333e-06\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.9395e-06 - val_loss: 6.9923e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 7.1310e-06 - val_loss: 1.9998e-05\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8086e-05 - val_loss: 7.1171e-06\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1483e-05 - val_loss: 3.8742e-05\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4320e-05 - val_loss: 6.6802e-06\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.3988e-05 - val_loss: 3.0616e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.5107e-05 - val_loss: 8.3002e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.7979e-06 - val_loss: 6.5995e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.3292e-06 - val_loss: 6.4856e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.1508e-06 - val_loss: 1.4487e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.2260e-05 - val_loss: 8.2247e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.9793e-06 - val_loss: 6.2292e-06\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.4989e-05 - val_loss: 3.5293e-05\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4063e-05 - val_loss: 6.5461e-06\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.0788e-06 - val_loss: 6.0522e-06\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.2876e-06 - val_loss: 2.1813e-05\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.4846e-05 - val_loss: 1.0073e-05\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 6.5545e-06 - val_loss: 5.9268e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.9623e-06 - val_loss: 1.0141e-05\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.1604e-05 - val_loss: 8.4221e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.5074e-06 - val_loss: 6.1052e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.0737e-05 - val_loss: 1.1503e-05\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.5689e-06 - val_loss: 5.9701e-06\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.5726e-05 - val_loss: 1.3166e-05\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0483e-05 - val_loss: 5.9398e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8046e-05 - val_loss: 2.6583e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0009e-05 - val_loss: 5.8761e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.6769e-06 - val_loss: 1.2925e-05\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.6037e-05 - val_loss: 6.7024e-06\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.4441e-06 - val_loss: 9.1494e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.5917e-05 - val_loss: 7.8218e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.6917e-06 - val_loss: 5.3277e-06\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.0440e-05 - val_loss: 6.8305e-05\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.2365e-05 - val_loss: 6.7863e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.1523e-06 - val_loss: 3.6738e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1363e-05 - val_loss: 5.4472e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.1620e-05 - val_loss: 1.3009e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4322e-05 - val_loss: 7.3713e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4273e-05 - val_loss: 9.3324e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 7.1718e-06 - val_loss: 1.4412e-05\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.3156e-05 - val_loss: 5.4109e-06\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.0310e-06 - val_loss: 5.2134e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 3.2683e-05 - val_loss: 7.2622e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 6.1758e-06 - val_loss: 4.6545e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1410e-05 - val_loss: 2.8835e-05\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.4227e-05 - val_loss: 5.6372e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.4701e-06 - val_loss: 4.5253e-06\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 2.4843e-05 - val_loss: 5.0588e-05\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.5354e-05 - val_loss: 4.9742e-06\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.3554e-06 - val_loss: 4.3047e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.4507e-05 - val_loss: 5.0081e-05\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 2s 52us/step - loss: 1.1163e-05 - val_loss: 4.9663e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.9426e-06 - val_loss: 1.4194e-05\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.9461e-05 - val_loss: 4.8947e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.7755e-06 - val_loss: 6.0164e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.5252e-05 - val_loss: 4.9744e-06\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.6677e-06 - val_loss: 4.0530e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.7133e-05 - val_loss: 1.6965e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 8.9667e-06 - val_loss: 4.4626e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.0396e-06 - val_loss: 4.1252e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.1299e-05 - val_loss: 1.0313e-05\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.8214e-06 - val_loss: 4.1735e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 1.7832e-05 - val_loss: 5.1579e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 5.6171e-06 - val_loss: 1.3812e-05\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.0465e-05 - val_loss: 8.0845e-06\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 4.5373e-06 - val_loss: 4.5569e-06\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 2s 53us/step - loss: 2.8100e-05 - val_loss: 5.3338e-06\n",
      "Epoch 00211: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_21 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 292, 32)           160       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 146, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 146, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 73, 128)           32896     \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 9344)              0         \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 73, 128)           65664     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_46 (UpSampling (None, 146, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 146, 64)           32832     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_47 (UpSampling (None, 292, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 292, 32)           8224      \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 292, 1)            129       \n",
      "_________________________________________________________________\n",
      "cropping1d_21 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 148,161\n",
      "Trainable params: 148,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 3s 65us/step - loss: 0.0514 - val_loss: 0.0290\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0233 - val_loss: 0.0061\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 0.0010 - val_loss: 9.6390e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.1255e-04 - val_loss: 8.1390e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.0086e-04 - val_loss: 5.3376e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.5198e-04 - val_loss: 3.5192e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.2002e-04 - val_loss: 2.2601e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2498e-04 - val_loss: 1.5449e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.4933e-04 - val_loss: 1.1064e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 9.4182e-05 - val_loss: 8.3076e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.4238e-05 - val_loss: 6.8783e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3841e-04 - val_loss: 6.5621e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.9143e-05 - val_loss: 5.4711e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.1332e-05 - val_loss: 4.9872e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.7217e-05 - val_loss: 4.6204e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.3362e-05 - val_loss: 5.0949e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.3063e-05 - val_loss: 4.1012e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.7926e-05 - val_loss: 4.1574e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.8528e-05 - val_loss: 3.6533e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.1217e-05 - val_loss: 3.7479e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.5285e-05 - val_loss: 3.3632e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.4193e-05 - val_loss: 3.3256e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.5466e-05 - val_loss: 3.6328e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.9576e-05 - val_loss: 5.3556e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.5766e-05 - val_loss: 2.9805e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.8727e-05 - val_loss: 2.3399e-04\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.2285e-05 - val_loss: 3.0843e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.6681e-05 - val_loss: 2.6376e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.8757e-05 - val_loss: 3.3145e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.3822e-05 - val_loss: 2.5910e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.9354e-05 - val_loss: 9.7555e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.1923e-05 - val_loss: 2.4200e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.2840e-05 - val_loss: 2.6818e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.7267e-05 - val_loss: 6.5187e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.7969e-05 - val_loss: 2.7037e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2782e-05 - val_loss: 2.2056e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.2016e-05 - val_loss: 3.7481e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.4652e-05 - val_loss: 2.2477e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.3888e-05 - val_loss: 2.9541e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2772e-05 - val_loss: 2.2014e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.0206e-05 - val_loss: 3.2288e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.1710e-05 - val_loss: 2.0375e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.3800e-05 - val_loss: 2.5149e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.5706e-05 - val_loss: 1.2425e-04\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.4491e-05 - val_loss: 2.0710e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9656e-05 - val_loss: 3.5365e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.5582e-05 - val_loss: 2.3697e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.8846e-05 - val_loss: 1.8865e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.9534e-05 - val_loss: 2.6782e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.9513e-05 - val_loss: 1.8105e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.7074e-05 - val_loss: 2.6478e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0120e-04 - val_loss: 2.4712e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.8110e-05 - val_loss: 1.6788e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.6223e-05 - val_loss: 1.6414e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.9460e-05 - val_loss: 4.8595e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.3153e-05 - val_loss: 1.9389e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.7825e-05 - val_loss: 2.5101e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.1413e-05 - val_loss: 1.9333e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.7205e-05 - val_loss: 8.5633e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.5765e-05 - val_loss: 1.7143e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 4.7858e-05 - val_loss: 1.5754e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.5577e-05 - val_loss: 1.5500e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.7036e-05 - val_loss: 3.1389e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.6701e-05 - val_loss: 1.5648e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.5441e-05 - val_loss: 1.5749e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.2978e-05 - val_loss: 1.4694e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 2.7136e-05 - val_loss: 1.6889e-04\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.4778e-05 - val_loss: 1.4599e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.4102e-05 - val_loss: 4.0215e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.1243e-05 - val_loss: 1.7060e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3997e-05 - val_loss: 1.3331e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.2925e-05 - val_loss: 1.4289e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.1190e-05 - val_loss: 1.4442e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3900e-05 - val_loss: 1.3406e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.6938e-05 - val_loss: 1.4518e-04\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.0449e-05 - val_loss: 1.3964e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.4174e-05 - val_loss: 1.0223e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.3366e-05 - val_loss: 1.3616e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.2281e-05 - val_loss: 2.0772e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.5697e-05 - val_loss: 2.0035e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3067e-05 - val_loss: 1.1840e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.1605e-05 - val_loss: 1.2352e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.0116e-05 - val_loss: 2.0192e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3317e-05 - val_loss: 1.1284e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.8865e-05 - val_loss: 4.6443e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.6497e-05 - val_loss: 1.1288e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0814e-05 - val_loss: 1.0812e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.1321e-05 - val_loss: 6.9518e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.3199e-05 - val_loss: 1.1813e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0547e-05 - val_loss: 1.0563e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0693e-05 - val_loss: 2.0400e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.1505e-05 - val_loss: 1.4102e-05\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0682e-05 - val_loss: 1.0974e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.0180e-05 - val_loss: 1.7305e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.1967e-05 - val_loss: 1.0389e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.1008e-05 - val_loss: 1.5388e-04\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.9486e-05 - val_loss: 1.1276e-05\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.7756e-06 - val_loss: 9.6161e-06\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 6.0076e-05 - val_loss: 1.9051e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.3233e-05 - val_loss: 9.7293e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 9.1174e-06 - val_loss: 9.2572e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.2500e-05 - val_loss: 4.7480e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.6267e-05 - val_loss: 9.8508e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.9457e-06 - val_loss: 9.0404e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.7298e-05 - val_loss: 4.9105e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.7184e-05 - val_loss: 9.4034e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.8209e-05 - val_loss: 1.2870e-04\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.7398e-05 - val_loss: 9.1803e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0537e-05 - val_loss: 5.6212e-05\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 4.6138e-05 - val_loss: 1.0831e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.6213e-06 - val_loss: 8.2874e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.9497e-05 - val_loss: 2.8417e-04\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 5.1548e-05 - val_loss: 1.0533e-05\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 8.5458e-06 - val_loss: 8.1387e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.8892e-06 - val_loss: 8.0127e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.7919e-05 - val_loss: 3.0040e-05\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.0315e-05 - val_loss: 8.1452e-06\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.6682e-05 - val_loss: 2.0081e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 1.2340e-05 - val_loss: 8.1597e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.7222e-06 - val_loss: 1.1609e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 3.9324e-05 - val_loss: 9.3401e-06\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 7.8621e-06 - val_loss: 8.5477e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.3868e-05 - val_loss: 1.6203e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 2s 57us/step - loss: 1.2401e-05 - val_loss: 4.7829e-05\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 2s 56us/step - loss: 2.9064e-05 - val_loss: 8.5742e-06\n",
      "Epoch 00128: early stopping\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_22 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 292, 36)           180       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 146, 36)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 146, 72)           10440     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 73, 72)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 73, 144)           41616     \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 10512)             0         \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 73, 144)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 73, 144)           83088     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_48 (UpSampling (None, 146, 144)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 146, 72)           41544     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_49 (UpSampling (None, 292, 72)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 292, 36)           10404     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 292, 1)            145       \n",
      "_________________________________________________________________\n",
      "cropping1d_22 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 187,417\n",
      "Trainable params: 187,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 114us/step - loss: 0.0521 - val_loss: 0.0282\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 0.0139 - val_loss: 0.0028\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 0.0010 - val_loss: 9.3010e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.2964e-04 - val_loss: 6.9664e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.4664e-04 - val_loss: 5.7157e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.4390e-04 - val_loss: 3.6742e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.5627e-04 - val_loss: 1.7949e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7936e-04 - val_loss: 1.5110e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2392e-04 - val_loss: 1.4490e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0970e-04 - val_loss: 1.1391e-04\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.9747e-05 - val_loss: 7.0960e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0953e-04 - val_loss: 6.7886e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.9216e-05 - val_loss: 5.6331e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.7545e-05 - val_loss: 2.1232e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.2662e-05 - val_loss: 5.0064e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5965e-05 - val_loss: 4.5406e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.3749e-05 - val_loss: 5.2060e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.3648e-05 - val_loss: 4.7549e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.0218e-05 - val_loss: 1.1384e-04\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.6197e-05 - val_loss: 3.6872e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.7082e-05 - val_loss: 1.5626e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4591e-05 - val_loss: 3.3728e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 5.5695e-05 - val_loss: 2.5178e-04\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.7044e-05 - val_loss: 3.1348e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.9830e-05 - val_loss: 2.9780e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.5086e-05 - val_loss: 2.9652e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1833e-05 - val_loss: 2.8012e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.6492e-05 - val_loss: 2.6985e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3311e-04 - val_loss: 3.1855e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8791e-05 - val_loss: 2.5706e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.4374e-05 - val_loss: 2.4554e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.3434e-05 - val_loss: 2.3777e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4833e-05 - val_loss: 3.7181e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.7081e-05 - val_loss: 2.3410e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.6830e-05 - val_loss: 5.2405e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.6536e-05 - val_loss: 2.1881e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.0116e-05 - val_loss: 2.5535e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.8348e-05 - val_loss: 2.1487e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.0489e-05 - val_loss: 2.1830e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.8592e-05 - val_loss: 3.3195e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.2272e-05 - val_loss: 1.9534e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.3334e-05 - val_loss: 8.6940e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1829e-05 - val_loss: 1.9363e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8378e-05 - val_loss: 2.6670e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.6161e-05 - val_loss: 2.5870e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8634e-05 - val_loss: 1.7623e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.3957e-05 - val_loss: 3.5661e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.3135e-05 - val_loss: 1.8495e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6691e-05 - val_loss: 1.6768e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7101e-05 - val_loss: 4.9197e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.4091e-05 - val_loss: 2.0367e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7358e-05 - val_loss: 1.5928e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.6737e-05 - val_loss: 5.9614e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.3080e-05 - val_loss: 1.6606e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.7797e-05 - val_loss: 2.2632e-04\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.2102e-05 - val_loss: 1.5718e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4865e-05 - val_loss: 1.4865e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4354e-05 - val_loss: 1.6043e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.6783e-05 - val_loss: 2.1938e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5161e-05 - val_loss: 1.4962e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 8.5739e-05 - val_loss: 2.6952e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9386e-05 - val_loss: 1.4164e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3338e-05 - val_loss: 1.3810e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.1071e-05 - val_loss: 2.7001e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8864e-05 - val_loss: 1.3352e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.3668e-05 - val_loss: 1.3413e-04\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.0511e-05 - val_loss: 1.3052e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.6775e-05 - val_loss: 2.0716e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.7783e-05 - val_loss: 1.3227e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2309e-05 - val_loss: 1.4830e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.9174e-05 - val_loss: 1.4273e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3097e-05 - val_loss: 1.2191e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.2706e-05 - val_loss: 4.1441e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.2543e-05 - val_loss: 1.3369e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.4155e-05 - val_loss: 2.8195e-05\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.2334e-05 - val_loss: 1.1938e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.7747e-05 - val_loss: 3.8531e-04\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.5732e-05 - val_loss: 1.2187e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.1157e-05 - val_loss: 1.1020e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.7897e-05 - val_loss: 1.2443e-04\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.2739e-05 - val_loss: 1.1404e-05\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.5763e-05 - val_loss: 3.1421e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.8130e-05 - val_loss: 1.1296e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0746e-05 - val_loss: 1.0440e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.7381e-05 - val_loss: 7.9404e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9781e-05 - val_loss: 1.0179e-05\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0077e-05 - val_loss: 1.0779e-05\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5363e-05 - val_loss: 2.2812e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2381e-05 - val_loss: 1.1282e-05\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.1762e-05 - val_loss: 1.7780e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.1764e-05 - val_loss: 9.9509e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.9423e-05 - val_loss: 1.4282e-04\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.7827e-05 - val_loss: 9.8871e-06\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.4986e-06 - val_loss: 2.0581e-05\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.5877e-05 - val_loss: 1.7977e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0114e-05 - val_loss: 8.9628e-06\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4387e-05 - val_loss: 1.1388e-04\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.2390e-05 - val_loss: 9.7590e-06\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.7414e-06 - val_loss: 1.0790e-05\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.4236e-05 - val_loss: 1.4419e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.8142e-06 - val_loss: 8.7083e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.2373e-06 - val_loss: 1.0855e-05\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4190e-05 - val_loss: 1.4827e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.5028e-06 - val_loss: 8.1887e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5484e-05 - val_loss: 2.2695e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.0856e-05 - val_loss: 8.7024e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.8661e-06 - val_loss: 8.0961e-06\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.8374e-05 - val_loss: 2.7982e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4095e-05 - val_loss: 8.4674e-06\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.5822e-06 - val_loss: 7.7246e-06\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.6244e-05 - val_loss: 1.5480e-04\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 3.9471e-05 - val_loss: 9.4406e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.6577e-06 - val_loss: 7.4327e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.6051e-05 - val_loss: 2.8705e-05\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3872e-05 - val_loss: 8.0024e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.1529e-06 - val_loss: 7.2358e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.4322e-05 - val_loss: 3.8121e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5123e-05 - val_loss: 7.3357e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.9085e-06 - val_loss: 7.0556e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.4876e-06 - val_loss: 2.9324e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.2212e-05 - val_loss: 1.3332e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.5137e-06 - val_loss: 6.8457e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 8.5131e-06 - val_loss: 2.4986e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.3717e-05 - val_loss: 7.2577e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.1846e-05 - val_loss: 2.6090e-05\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0052e-05 - val_loss: 6.9531e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.5072e-05 - val_loss: 2.7836e-04\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.8040e-05 - val_loss: 8.1513e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.6376e-06 - val_loss: 6.3543e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.1296e-06 - val_loss: 7.1957e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8791e-05 - val_loss: 6.9060e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5391e-05 - val_loss: 7.3394e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9451e-05 - val_loss: 6.8396e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.6749e-05 - val_loss: 4.2062e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2799e-05 - val_loss: 6.3652e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.5589e-05 - val_loss: 1.6304e-04\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1662e-05 - val_loss: 6.3141e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.7943e-06 - val_loss: 6.0976e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.8195e-05 - val_loss: 1.7584e-05\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.4202e-06 - val_loss: 5.8939e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.3524e-05 - val_loss: 4.5114e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.4670e-05 - val_loss: 6.4495e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.5052e-06 - val_loss: 6.6829e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4007e-05 - val_loss: 1.2311e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.6047e-06 - val_loss: 5.5195e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.2195e-06 - val_loss: 6.9066e-06\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.0315e-05 - val_loss: 8.9520e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.3295e-06 - val_loss: 5.3745e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.9865e-06 - val_loss: 5.1914e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.0944e-05 - val_loss: 1.3011e-04\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.1261e-05 - val_loss: 7.2196e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.3745e-06 - val_loss: 5.1862e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.6979e-05 - val_loss: 1.1458e-05\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2694e-05 - val_loss: 5.3561e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.9339e-06 - val_loss: 6.0745e-06\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.4659e-05 - val_loss: 1.4548e-05\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 6.5699e-06 - val_loss: 5.1824e-06\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.6607e-06 - val_loss: 6.5155e-06\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.5641e-05 - val_loss: 8.3361e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.5797e-06 - val_loss: 4.7851e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5530e-06 - val_loss: 4.7590e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 2.7115e-05 - val_loss: 2.0962e-05\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.3436e-06 - val_loss: 4.6229e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8262e-05 - val_loss: 2.0130e-04\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1247e-05 - val_loss: 5.0985e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5485e-06 - val_loss: 4.4045e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.9474e-06 - val_loss: 2.3459e-05\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.4514e-05 - val_loss: 5.6504e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5703e-06 - val_loss: 4.2937e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.6534e-05 - val_loss: 1.5963e-05\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.3723e-06 - val_loss: 4.5562e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.1162e-06 - val_loss: 4.1666e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.8929e-05 - val_loss: 2.6392e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.2113e-05 - val_loss: 5.0777e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.2668e-06 - val_loss: 4.3290e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.5105e-05 - val_loss: 1.1675e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.2877e-06 - val_loss: 4.1838e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.6098e-05 - val_loss: 3.7519e-05\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.7952e-05 - val_loss: 5.1520e-06\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.1182e-06 - val_loss: 5.7218e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.4486e-05 - val_loss: 4.0633e-06\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 4.7611e-06 - val_loss: 4.1313e-06\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.2505e-05 - val_loss: 7.7589e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.2414e-06 - val_loss: 4.6543e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.7296e-05 - val_loss: 8.8708e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.0155e-06 - val_loss: 3.8450e-06\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.4611e-05 - val_loss: 3.4262e-05\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 9.5636e-06 - val_loss: 4.5315e-06\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.8236e-06 - val_loss: 3.7818e-05\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.9720e-05 - val_loss: 5.1611e-06\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9177e-05 - val_loss: 6.1417e-06\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 7.3053e-06 - val_loss: 4.3169e-06\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3231e-05 - val_loss: 1.1206e-04\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.3322e-05 - val_loss: 3.9466e-06\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.6213e-06 - val_loss: 3.6215e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8038e-05 - val_loss: 5.6143e-05\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.3558e-05 - val_loss: 4.0116e-06\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.2920e-06 - val_loss: 3.3329e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.9683e-06 - val_loss: 1.3760e-05\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4250e-05 - val_loss: 9.0980e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.3179e-06 - val_loss: 3.3497e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.0991e-06 - val_loss: 3.2070e-06\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.2612e-06 - val_loss: 1.8994e-05\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 3s 68us/step - loss: 1.0909e-05 - val_loss: 8.5991e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.1981e-05 - val_loss: 3.5636e-06\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.9301e-05 - val_loss: 5.7653e-06\n",
      "Epoch 210/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.5862e-06 - val_loss: 3.1186e-06\n",
      "Epoch 211/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1959e-05 - val_loss: 1.2426e-05\n",
      "Epoch 212/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.4269e-06 - val_loss: 3.1811e-06\n",
      "Epoch 213/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8497e-06 - val_loss: 2.9590e-06\n",
      "Epoch 214/1000\n",
      "43200/43200 [==============================] - ETA: 0s - loss: 2.5800e-0 - 3s 69us/step - loss: 2.5714e-05 - val_loss: 1.0389e-05\n",
      "Epoch 215/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 4.8927e-06 - val_loss: 3.1953e-06\n",
      "Epoch 216/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.0110e-06 - val_loss: 4.1335e-05\n",
      "Epoch 217/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.0604e-05 - val_loss: 5.3352e-06\n",
      "Epoch 218/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.0631e-06 - val_loss: 3.6532e-06\n",
      "Epoch 219/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 1.8311e-05 - val_loss: 4.1884e-06\n",
      "Epoch 220/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.8400e-06 - val_loss: 3.0226e-06\n",
      "Epoch 221/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 3.1476e-05 - val_loss: 1.5777e-05\n",
      "Epoch 222/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 5.6037e-06 - val_loss: 3.4271e-06\n",
      "Epoch 223/1000\n",
      "43200/43200 [==============================] - 3s 69us/step - loss: 2.8555e-06 - val_loss: 4.0955e-06\n",
      "Epoch 00223: early stopping\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_23 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 292, 40)           200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 146, 40)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 146, 80)           12880     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 73, 80)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 73, 160)           51360     \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 11680)             0         \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 73, 160)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 73, 160)           102560    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_50 (UpSampling (None, 146, 160)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 146, 80)           51280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_51 (UpSampling (None, 292, 80)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 292, 40)           12840     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 292, 1)            161       \n",
      "_________________________________________________________________\n",
      "cropping1d_23 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 231,281\n",
      "Trainable params: 231,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 120us/step - loss: 0.0478 - val_loss: 0.0287\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0202 - val_loss: 0.0050\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 0.0010 - val_loss: 9.7277e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.7311e-04 - val_loss: 8.4624e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.6846e-04 - val_loss: 4.7048e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.7552e-04 - val_loss: 2.6765e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.3944e-04 - val_loss: 2.1004e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.7731e-04 - val_loss: 2.7203e-04\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.4223e-04 - val_loss: 1.0871e-04\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1929e-04 - val_loss: 9.9866e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.3398e-05 - val_loss: 8.5643e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.8315e-05 - val_loss: 1.0754e-04\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.0192e-05 - val_loss: 5.1907e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.6530e-05 - val_loss: 1.9246e-04\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.6787e-05 - val_loss: 4.4562e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.2586e-05 - val_loss: 9.1061e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.5613e-05 - val_loss: 3.9021e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.6767e-05 - val_loss: 3.5531e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.8616e-05 - val_loss: 7.1319e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.9865e-05 - val_loss: 3.2322e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.7667e-05 - val_loss: 1.1731e-04\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.0745e-05 - val_loss: 3.0260e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.0499e-05 - val_loss: 6.8323e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.2948e-05 - val_loss: 3.0456e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.5358e-05 - val_loss: 3.7882e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.3376e-05 - val_loss: 3.8617e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.0762e-05 - val_loss: 3.5895e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.8554e-05 - val_loss: 2.3515e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.3257e-05 - val_loss: 2.5628e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.5929e-05 - val_loss: 2.2221e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.1335e-05 - val_loss: 2.1497e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.9137e-05 - val_loss: 2.2270e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.2955e-05 - val_loss: 2.0184e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.3621e-05 - val_loss: 7.0620e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.6364e-05 - val_loss: 2.0019e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.8906e-05 - val_loss: 1.8662e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.3041e-05 - val_loss: 7.8128e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.7430e-05 - val_loss: 1.8360e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7989e-05 - val_loss: 3.7177e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.5865e-05 - val_loss: 2.7600e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7996e-05 - val_loss: 1.6768e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.7702e-05 - val_loss: 1.0361e-04\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.8973e-05 - val_loss: 1.7221e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.5648e-05 - val_loss: 1.5454e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.1776e-05 - val_loss: 3.7940e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.0552e-05 - val_loss: 1.5678e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.6119e-05 - val_loss: 6.5660e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.4227e-05 - val_loss: 1.5256e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.4528e-05 - val_loss: 1.4060e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 8.2705e-05 - val_loss: 7.9158e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.3904e-05 - val_loss: 1.4077e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.3107e-05 - val_loss: 1.3328e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.3350e-05 - val_loss: 3.5236e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.7329e-05 - val_loss: 1.3025e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.2460e-05 - val_loss: 1.6176e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 9.8931e-05 - val_loss: 2.4373e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.4901e-05 - val_loss: 1.2429e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1857e-05 - val_loss: 1.3580e-05\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.6453e-05 - val_loss: 2.1618e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7644e-05 - val_loss: 9.1084e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.5621e-05 - val_loss: 1.1952e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.2485e-05 - val_loss: 3.8549e-05\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.3833e-05 - val_loss: 1.1910e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1296e-05 - val_loss: 1.0789e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.8976e-05 - val_loss: 3.6138e-05\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.5082e-05 - val_loss: 1.0836e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.4141e-05 - val_loss: 4.5820e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6750e-05 - val_loss: 1.0263e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7982e-05 - val_loss: 1.6371e-04\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.6728e-05 - val_loss: 1.2700e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.0524e-05 - val_loss: 1.1163e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.9963e-05 - val_loss: 2.2454e-05\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1376e-05 - val_loss: 1.0713e-05\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.4028e-05 - val_loss: 1.0811e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.0949e-05 - val_loss: 9.4770e-06\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.8360e-05 - val_loss: 6.2691e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.5617e-05 - val_loss: 9.0666e-06\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.3599e-06 - val_loss: 8.5398e-06\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.8141e-05 - val_loss: 5.0942e-05\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6420e-05 - val_loss: 9.1788e-06\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.1112e-06 - val_loss: 8.4150e-06\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.1187e-05 - val_loss: 1.9031e-05\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.1217e-05 - val_loss: 8.3200e-06\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.2850e-05 - val_loss: 3.0753e-05\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.8278e-05 - val_loss: 8.1576e-06\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.5784e-06 - val_loss: 7.6260e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.0941e-05 - val_loss: 3.3505e-04\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.4620e-05 - val_loss: 8.5984e-06\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.6251e-06 - val_loss: 7.2731e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.3311e-05 - val_loss: 2.3499e-04\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.9579e-05 - val_loss: 1.0659e-05\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.4885e-06 - val_loss: 7.8651e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.1814e-05 - val_loss: 1.2614e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1775e-05 - val_loss: 7.3113e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.9844e-06 - val_loss: 1.4136e-05\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.7777e-05 - val_loss: 1.0320e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 7.9095e-06 - val_loss: 6.5576e-06\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.8913e-05 - val_loss: 2.1313e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.6931e-05 - val_loss: 7.3333e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.4521e-06 - val_loss: 9.8909e-06\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.7384e-05 - val_loss: 9.1681e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.1335e-06 - val_loss: 6.3634e-06\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.4013e-05 - val_loss: 4.2422e-05\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.4578e-05 - val_loss: 6.5784e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.7751e-06 - val_loss: 5.8424e-06\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.5132e-05 - val_loss: 2.0823e-05\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.5356e-05 - val_loss: 6.2778e-06\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.3936e-05 - val_loss: 1.0517e-05\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 1.0213e-05 - val_loss: 7.5612e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 3.9300e-05 - val_loss: 6.4401e-06\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.5039e-06 - val_loss: 5.9773e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.8242e-05 - val_loss: 2.4454e-05\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 8.0844e-06 - val_loss: 5.4363e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.1660e-06 - val_loss: 6.5993e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.8398e-05 - val_loss: 8.1688e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 6.2181e-06 - val_loss: 5.6143e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.1359e-05 - val_loss: 1.2581e-04\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 3.1113e-05 - val_loss: 7.1802e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.2734e-06 - val_loss: 8.0415e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.6920e-05 - val_loss: 1.2237e-05\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.3608e-06 - val_loss: 4.8712e-06\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 9.8046e-06 - val_loss: 8.4657e-05\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.8897e-05 - val_loss: 6.2760e-06\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.0424e-06 - val_loss: 5.9832e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.5230e-05 - val_loss: 6.1154e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 5.7955e-06 - val_loss: 4.6155e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.5462e-06 - val_loss: 9.0034e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 5.5230e-05 - val_loss: 8.4712e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 6.0245e-06 - val_loss: 4.6340e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.3603e-06 - val_loss: 5.6861e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.3048e-05 - val_loss: 9.7914e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.1390e-06 - val_loss: 2.2260e-05\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.9316e-05 - val_loss: 5.6679e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.3638e-06 - val_loss: 4.1520e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 7.7606e-05 - val_loss: 6.2976e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.7246e-05 - val_loss: 5.7765e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.6185e-06 - val_loss: 4.4483e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.1934e-06 - val_loss: 4.6264e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.6581e-05 - val_loss: 7.4368e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 4.9120e-06 - val_loss: 4.4449e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 1.0838e-05 - val_loss: 1.1381e-04\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 2.2813e-05 - val_loss: 4.4181e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 72us/step - loss: 4.1541e-06 - val_loss: 4.6629e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 73us/step - loss: 2.5179e-05 - val_loss: 8.1777e-06\n",
      "Epoch 00147: early stopping\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_24 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 292, 44)           220       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 146, 44)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 146, 88)           15576     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 73, 88)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 73, 176)           62128     \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 12848)             0         \n",
      "_________________________________________________________________\n",
      "reshape_24 (Reshape)         (None, 73, 176)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 73, 176)           124080    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_52 (UpSampling (None, 146, 176)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 146, 88)           62040     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_53 (UpSampling (None, 292, 88)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 292, 44)           15532     \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 292, 1)            177       \n",
      "_________________________________________________________________\n",
      "cropping1d_24 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 279,753\n",
      "Trainable params: 279,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 122us/step - loss: 0.0556 - val_loss: 0.0291\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 0.0269 - val_loss: 0.0118\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 0.0010 - val_loss: 9.3720e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 8.8775e-04 - val_loss: 7.3084e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.2025e-04 - val_loss: 4.4394e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.3265e-04 - val_loss: 2.1825e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.7151e-04 - val_loss: 1.2912e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3305e-04 - val_loss: 9.0644e-05\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 8.6116e-05 - val_loss: 6.9598e-05\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 9.1228e-05 - val_loss: 6.6800e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.5258e-05 - val_loss: 5.2239e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.1176e-04 - val_loss: 5.9517e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.5022e-05 - val_loss: 4.1795e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.8946e-05 - val_loss: 3.7938e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 8.0188e-05 - val_loss: 6.4615e-05\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.8166e-05 - val_loss: 3.3344e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.1664e-05 - val_loss: 3.8790e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.8842e-05 - val_loss: 3.4215e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.9005e-05 - val_loss: 5.3721e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 8.6335e-05 - val_loss: 3.0844e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.5905e-05 - val_loss: 2.5077e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.2707e-05 - val_loss: 7.4554e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.1586e-05 - val_loss: 2.3795e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.7579e-05 - val_loss: 3.7558e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.4316e-05 - val_loss: 2.9321e-05\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.2882e-05 - val_loss: 3.0172e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.7711e-05 - val_loss: 2.2929e-04\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.6561e-05 - val_loss: 2.1708e-05\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 3s 79us/step - loss: 1.9485e-05 - val_loss: 1.9197e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 7.0043e-05 - val_loss: 2.0045e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.0616e-05 - val_loss: 1.8352e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.7329e-05 - val_loss: 2.5627e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.9885e-05 - val_loss: 1.7625e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.2859e-05 - val_loss: 1.2897e-04\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.1943e-05 - val_loss: 1.9335e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.3031e-05 - val_loss: 2.8147e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.7119e-05 - val_loss: 1.6079e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 7.1165e-05 - val_loss: 1.1138e-04\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.1770e-05 - val_loss: 1.6358e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.5036e-05 - val_loss: 1.7324e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.5994e-05 - val_loss: 2.2550e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.5989e-05 - val_loss: 1.8720e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.1277e-05 - val_loss: 1.6367e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.5139e-05 - val_loss: 1.5680e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.9582e-05 - val_loss: 2.5239e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.4764e-05 - val_loss: 1.3954e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 7.1189e-05 - val_loss: 2.7493e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.5934e-05 - val_loss: 1.2876e-05\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.3198e-05 - val_loss: 4.3149e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.0409e-05 - val_loss: 1.3443e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.6021e-05 - val_loss: 1.8801e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.4575e-05 - val_loss: 1.1851e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 7.7232e-05 - val_loss: 6.2391e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.9059e-05 - val_loss: 1.1975e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.1105e-05 - val_loss: 1.1615e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 7.4534e-05 - val_loss: 2.3282e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.4217e-05 - val_loss: 1.1385e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.6576e-05 - val_loss: 1.8765e-04\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.1474e-05 - val_loss: 1.0488e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.0718e-05 - val_loss: 2.2987e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 9.6768e-05 - val_loss: 1.5504e-05\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.1245e-05 - val_loss: 9.9754e-06\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 9.5872e-06 - val_loss: 1.0299e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.0148e-04 - val_loss: 3.9491e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.3325e-05 - val_loss: 9.7005e-06\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 9.1523e-06 - val_loss: 9.2818e-06\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.6200e-05 - val_loss: 3.5043e-05\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3137e-05 - val_loss: 1.0130e-05\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.8249e-05 - val_loss: 3.3098e-05\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3019e-05 - val_loss: 8.7912e-06\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.7478e-05 - val_loss: 1.0924e-04\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.2037e-05 - val_loss: 9.0106e-06\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 8.3107e-06 - val_loss: 8.1854e-06\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.4639e-05 - val_loss: 3.0351e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.6468e-05 - val_loss: 8.0590e-06\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 8.9622e-06 - val_loss: 1.9186e-05\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.6159e-05 - val_loss: 9.8243e-06\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3342e-05 - val_loss: 6.8526e-05\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 5.2294e-05 - val_loss: 8.0424e-06\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 7.9620e-06 - val_loss: 1.7885e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.1596e-05 - val_loss: 9.6281e-06\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 8.1594e-06 - val_loss: 7.1286e-06\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 5.4896e-05 - val_loss: 1.3853e-05\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.1839e-05 - val_loss: 7.9169e-06\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.0613e-05 - val_loss: 2.1363e-04\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.5175e-05 - val_loss: 8.4149e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.9940e-06 - val_loss: 6.7976e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 5.2926e-05 - val_loss: 3.3945e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.0828e-05 - val_loss: 7.1211e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.4264e-05 - val_loss: 4.4855e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.4775e-05 - val_loss: 6.3417e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.0580e-06 - val_loss: 6.3912e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.2010e-05 - val_loss: 4.9561e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.2539e-05 - val_loss: 7.0346e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.8175e-06 - val_loss: 6.6617e-06\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.6828e-05 - val_loss: 1.0372e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 8.9659e-06 - val_loss: 6.0602e-06\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.2470e-05 - val_loss: 1.2469e-04\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.2887e-05 - val_loss: 5.7285e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.4565e-05 - val_loss: 1.9201e-04\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.8093e-05 - val_loss: 6.2560e-06\n",
      "Epoch 105/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.3853e-06 - val_loss: 7.6731e-06\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.0764e-05 - val_loss: 9.1429e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.0713e-06 - val_loss: 5.0783e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.8734e-05 - val_loss: 8.0508e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.6248e-05 - val_loss: 5.3808e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 8.7328e-06 - val_loss: 7.8983e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.5359e-05 - val_loss: 7.3659e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.1213e-06 - val_loss: 4.7344e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.6332e-05 - val_loss: 2.3427e-05\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.1996e-05 - val_loss: 5.3305e-06\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.5529e-06 - val_loss: 4.5233e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.5815e-05 - val_loss: 5.0170e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 7.9485e-06 - val_loss: 5.0216e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.0857e-05 - val_loss: 9.2282e-06\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.4281e-05 - val_loss: 5.3123e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.3469e-05 - val_loss: 6.0105e-05\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3777e-05 - val_loss: 4.4714e-06\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.6082e-05 - val_loss: 1.8530e-05\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.0048e-05 - val_loss: 4.9071e-06\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.4108e-05 - val_loss: 2.8297e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 7.7529e-06 - val_loss: 4.1071e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.7611e-05 - val_loss: 1.2191e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 6.9719e-06 - val_loss: 4.3548e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 1.3710e-05 - val_loss: 1.9405e-04\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.0672e-05 - val_loss: 5.5328e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.9428e-06 - val_loss: 3.7793e-06\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.3665e-05 - val_loss: 1.4133e-04\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.6758e-05 - val_loss: 4.5554e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.8917e-06 - val_loss: 3.6254e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.3031e-05 - val_loss: 1.9143e-05\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.1944e-05 - val_loss: 4.3150e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.7068e-06 - val_loss: 3.6121e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 4.4912e-06 - val_loss: 3.3621e-05\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.8896e-05 - val_loss: 4.0593e-06\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.9447e-06 - val_loss: 3.5109e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.2793e-06 - val_loss: 3.3239e-06\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 3s 77us/step - loss: 1.1065e-05 - val_loss: 1.7624e-04\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.7176e-05 - val_loss: 3.9037e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.4730e-06 - val_loss: 3.3194e-06\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 5.8173e-06 - val_loss: 6.0998e-05\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.3066e-05 - val_loss: 5.1240e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.5384e-06 - val_loss: 3.1092e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.6443e-05 - val_loss: 1.7423e-05\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.3091e-05 - val_loss: 4.0692e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.3139e-06 - val_loss: 3.1106e-06\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.8549e-06 - val_loss: 1.6716e-05\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 2.3860e-05 - val_loss: 6.1714e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 4.6912e-06 - val_loss: 1.7976e-05\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 2.1411e-05 - val_loss: 4.0627e-06\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 6.6349e-06 - val_loss: 7.2523e-05\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 3s 77us/step - loss: 3.9812e-05 - val_loss: 7.3379e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 3s 78us/step - loss: 3.9116e-06 - val_loss: 3.1565e-06\n",
      "Epoch 00156: early stopping\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_25 (ZeroPaddi (None, 292, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 292, 48)           240       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 146, 48)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_180 (Conv1D)          (None, 146, 96)           18528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 73, 96)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 73, 192)           73920     \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 14016)             0         \n",
      "_________________________________________________________________\n",
      "reshape_25 (Reshape)         (None, 73, 192)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_182 (Conv1D)          (None, 73, 192)           147648    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_54 (UpSampling (None, 146, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          (None, 146, 96)           73824     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_55 (UpSampling (None, 292, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 292, 48)           18480     \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 292, 1)            193       \n",
      "_________________________________________________________________\n",
      "cropping1d_25 (Cropping1D)   (None, 288, 1)            0         \n",
      "=================================================================\n",
      "Total params: 332,833\n",
      "Trainable params: 332,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/1000\n",
      "43200/43200 [==============================] - 5s 126us/step - loss: 0.0499 - val_loss: 0.0287\n",
      "Epoch 2/1000\n",
      "43200/43200 [==============================] - 3s 80us/step - loss: 0.0188 - val_loss: 0.0039\n",
      "Epoch 3/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 0.0011 - val_loss: 9.2888e-04\n",
      "Epoch 6/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.5868e-04 - val_loss: 7.0397e-04\n",
      "Epoch 7/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.6663e-04 - val_loss: 4.1767e-04\n",
      "Epoch 8/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.2869e-04 - val_loss: 2.1189e-04\n",
      "Epoch 9/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7226e-04 - val_loss: 1.0609e-04\n",
      "Epoch 10/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 9.2713e-05 - val_loss: 2.0617e-04\n",
      "Epoch 11/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.3511e-04 - val_loss: 6.1274e-05\n",
      "Epoch 12/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.5853e-05 - val_loss: 5.1500e-05\n",
      "Epoch 13/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.7158e-05 - val_loss: 4.9091e-05\n",
      "Epoch 14/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.2632e-04 - val_loss: 5.1568e-05\n",
      "Epoch 15/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.0021e-05 - val_loss: 3.7001e-05\n",
      "Epoch 16/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.5719e-05 - val_loss: 5.4651e-05\n",
      "Epoch 17/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3060e-05 - val_loss: 3.5585e-05\n",
      "Epoch 18/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 7.8464e-05 - val_loss: 1.6139e-04\n",
      "Epoch 19/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.6408e-05 - val_loss: 2.8184e-05\n",
      "Epoch 20/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.7187e-05 - val_loss: 3.2678e-05\n",
      "Epoch 21/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.2761e-05 - val_loss: 2.8735e-05\n",
      "Epoch 22/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.2144e-05 - val_loss: 2.4481e-05\n",
      "Epoch 23/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 7.0843e-05 - val_loss: 8.1537e-05\n",
      "Epoch 24/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.5935e-05 - val_loss: 2.3279e-05\n",
      "Epoch 25/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.1896e-05 - val_loss: 2.1317e-05\n",
      "Epoch 26/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.9026e-05 - val_loss: 2.5834e-05\n",
      "Epoch 27/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.3807e-05 - val_loss: 2.0304e-05\n",
      "Epoch 28/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.6645e-05 - val_loss: 1.0062e-04\n",
      "Epoch 29/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.0346e-05 - val_loss: 2.8815e-05\n",
      "Epoch 30/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 6.3094e-05 - val_loss: 1.9340e-05\n",
      "Epoch 31/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.5598e-05 - val_loss: 1.3374e-04\n",
      "Epoch 32/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.1099e-05 - val_loss: 1.9393e-05\n",
      "Epoch 33/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.6311e-05 - val_loss: 3.2626e-05\n",
      "Epoch 34/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.5392e-05 - val_loss: 3.3500e-05\n",
      "Epoch 35/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 6.6148e-05 - val_loss: 2.2397e-05\n",
      "Epoch 36/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.6550e-05 - val_loss: 1.7589e-05\n",
      "Epoch 37/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 1.0024e-04 - val_loss: 2.9179e-05\n",
      "Epoch 38/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7627e-05 - val_loss: 1.4865e-05\n",
      "Epoch 39/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.4833e-05 - val_loss: 2.6720e-05\n",
      "Epoch 40/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 9.0133e-05 - val_loss: 2.6700e-05\n",
      "Epoch 41/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.5593e-05 - val_loss: 1.3902e-05\n",
      "Epoch 42/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.5443e-05 - val_loss: 8.6193e-05\n",
      "Epoch 43/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 8.4962e-05 - val_loss: 1.5226e-05\n",
      "Epoch 44/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.3625e-05 - val_loss: 1.3052e-05\n",
      "Epoch 45/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 5.2946e-05 - val_loss: 4.8534e-05\n",
      "Epoch 46/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.8994e-05 - val_loss: 1.4416e-05\n",
      "Epoch 47/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.2881e-05 - val_loss: 2.5933e-05\n",
      "Epoch 48/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7934e-05 - val_loss: 8.1811e-05\n",
      "Epoch 49/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.1112e-05 - val_loss: 1.7979e-05\n",
      "Epoch 50/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.2205e-05 - val_loss: 1.1645e-05\n",
      "Epoch 51/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.4186e-05 - val_loss: 2.5726e-04\n",
      "Epoch 52/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.3532e-05 - val_loss: 1.2027e-05\n",
      "Epoch 53/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.1420e-05 - val_loss: 1.1037e-05\n",
      "Epoch 54/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0470e-05 - val_loss: 1.0889e-05\n",
      "Epoch 55/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 7.8581e-05 - val_loss: 4.2159e-05\n",
      "Epoch 56/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.4675e-05 - val_loss: 1.0511e-05\n",
      "Epoch 57/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0759e-05 - val_loss: 2.0470e-05\n",
      "Epoch 58/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.5782e-05 - val_loss: 1.0368e-05\n",
      "Epoch 59/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.3095e-05 - val_loss: 6.5408e-05\n",
      "Epoch 60/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 7.8963e-05 - val_loss: 1.5980e-05\n",
      "Epoch 61/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0723e-05 - val_loss: 9.5161e-06\n",
      "Epoch 62/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.5789e-05 - val_loss: 4.3131e-05\n",
      "Epoch 63/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.1295e-05 - val_loss: 1.0693e-05\n",
      "Epoch 64/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.0350e-05 - val_loss: 2.0904e-04\n",
      "Epoch 65/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.6831e-05 - val_loss: 9.7976e-06\n",
      "Epoch 66/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 9.3376e-06 - val_loss: 1.1734e-05\n",
      "Epoch 67/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.2738e-05 - val_loss: 2.1204e-05\n",
      "Epoch 68/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0181e-05 - val_loss: 8.8334e-06\n",
      "Epoch 69/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 4.3752e-05 - val_loss: 4.3274e-05\n",
      "Epoch 70/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.8172e-05 - val_loss: 8.1960e-06\n",
      "Epoch 71/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.4030e-05 - val_loss: 1.1106e-04\n",
      "Epoch 72/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.6612e-05 - val_loss: 8.6689e-06\n",
      "Epoch 73/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.2122e-06 - val_loss: 1.2009e-05\n",
      "Epoch 74/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.2847e-05 - val_loss: 1.6281e-05\n",
      "Epoch 75/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.6965e-06 - val_loss: 7.5885e-06\n",
      "Epoch 76/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 7.2145e-06 - val_loss: 9.9600e-06\n",
      "Epoch 77/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.4310e-05 - val_loss: 1.6346e-05\n",
      "Epoch 78/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.8765e-06 - val_loss: 7.6974e-06\n",
      "Epoch 79/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 7.0151e-06 - val_loss: 7.0956e-06\n",
      "Epoch 80/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.5956e-05 - val_loss: 4.3652e-05\n",
      "Epoch 81/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.2260e-05 - val_loss: 8.0345e-06\n",
      "Epoch 82/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.7680e-06 - val_loss: 8.0735e-06\n",
      "Epoch 83/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.8690e-05 - val_loss: 1.4953e-05\n",
      "Epoch 84/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.7497e-06 - val_loss: 6.6619e-06\n",
      "Epoch 85/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.7288e-05 - val_loss: 1.4053e-04\n",
      "Epoch 86/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.8434e-05 - val_loss: 6.9631e-06\n",
      "Epoch 87/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 6.5966e-06 - val_loss: 6.4512e-06\n",
      "Epoch 88/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.3015e-05 - val_loss: 5.7866e-05\n",
      "Epoch 89/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.2575e-05 - val_loss: 6.8816e-06\n",
      "Epoch 90/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.9534e-06 - val_loss: 6.1052e-06\n",
      "Epoch 91/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.8687e-05 - val_loss: 1.8917e-05\n",
      "Epoch 92/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 8.2585e-06 - val_loss: 6.1362e-06\n",
      "Epoch 93/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 6.0283e-06 - val_loss: 1.3683e-05\n",
      "Epoch 94/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.3844e-05 - val_loss: 6.8999e-06\n",
      "Epoch 95/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3178e-06 - val_loss: 5.9578e-06\n",
      "Epoch 96/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.1976e-05 - val_loss: 1.1083e-05\n",
      "Epoch 97/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.0003e-05 - val_loss: 6.0269e-06\n",
      "Epoch 98/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.3610e-06 - val_loss: 7.9521e-06\n",
      "Epoch 99/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.4791e-05 - val_loss: 1.0801e-05\n",
      "Epoch 100/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3803e-06 - val_loss: 5.3092e-06\n",
      "Epoch 101/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.8518e-06 - val_loss: 1.5929e-05\n",
      "Epoch 102/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.1482e-05 - val_loss: 7.0557e-06\n",
      "Epoch 103/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.4823e-06 - val_loss: 4.2788e-05\n",
      "Epoch 104/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.0645e-05 - val_loss: 6.8326e-06\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.0007e-05 - val_loss: 1.1324e-04\n",
      "Epoch 106/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.9508e-05 - val_loss: 5.2937e-06\n",
      "Epoch 107/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 5.2691e-06 - val_loss: 6.9844e-06\n",
      "Epoch 108/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 4.4245e-05 - val_loss: 1.2324e-05\n",
      "Epoch 109/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3254e-06 - val_loss: 4.7319e-06\n",
      "Epoch 110/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.4686e-06 - val_loss: 2.7722e-05\n",
      "Epoch 111/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.6073e-05 - val_loss: 8.5285e-06\n",
      "Epoch 112/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.2305e-06 - val_loss: 4.5877e-06\n",
      "Epoch 113/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.2898e-06 - val_loss: 4.4398e-06\n",
      "Epoch 114/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.0251e-05 - val_loss: 1.1883e-04\n",
      "Epoch 115/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.2764e-05 - val_loss: 6.2389e-06\n",
      "Epoch 116/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.0691e-06 - val_loss: 4.6493e-06\n",
      "Epoch 117/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.2834e-06 - val_loss: 4.4259e-06\n",
      "Epoch 118/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.6974e-05 - val_loss: 4.6549e-05\n",
      "Epoch 119/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 9.4835e-06 - val_loss: 4.3321e-06\n",
      "Epoch 120/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.0428e-06 - val_loss: 4.1400e-06\n",
      "Epoch 121/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.4792e-05 - val_loss: 2.4987e-05\n",
      "Epoch 122/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.8846e-06 - val_loss: 4.1079e-06\n",
      "Epoch 123/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.8889e-06 - val_loss: 3.9169e-06\n",
      "Epoch 124/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.8492e-05 - val_loss: 1.1855e-05\n",
      "Epoch 125/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.8180e-06 - val_loss: 3.9104e-06\n",
      "Epoch 126/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.5892e-05 - val_loss: 6.8034e-05\n",
      "Epoch 127/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.3720e-05 - val_loss: 4.0293e-06\n",
      "Epoch 128/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.7067e-06 - val_loss: 3.6711e-06\n",
      "Epoch 129/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.4692e-06 - val_loss: 3.6699e-06\n",
      "Epoch 130/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.4767e-05 - val_loss: 1.2108e-05\n",
      "Epoch 131/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.7227e-06 - val_loss: 3.7664e-06\n",
      "Epoch 132/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.4471e-06 - val_loss: 3.5016e-06\n",
      "Epoch 133/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.5715e-05 - val_loss: 7.3173e-06\n",
      "Epoch 134/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3739e-06 - val_loss: 3.8080e-06\n",
      "Epoch 135/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.3167e-06 - val_loss: 3.4903e-06\n",
      "Epoch 136/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.1142e-05 - val_loss: 6.7600e-06\n",
      "Epoch 137/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.7270e-06 - val_loss: 3.4132e-06\n",
      "Epoch 138/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.1038e-05 - val_loss: 2.9996e-05\n",
      "Epoch 139/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.1828e-05 - val_loss: 4.0008e-06\n",
      "Epoch 140/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.2819e-06 - val_loss: 3.7137e-06\n",
      "Epoch 141/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.4387e-05 - val_loss: 5.3911e-06\n",
      "Epoch 142/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.9268e-06 - val_loss: 3.1369e-06\n",
      "Epoch 143/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.4279e-05 - val_loss: 6.6454e-05\n",
      "Epoch 144/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.3369e-05 - val_loss: 3.7528e-06\n",
      "Epoch 145/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.1495e-06 - val_loss: 3.0477e-06\n",
      "Epoch 146/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.1087e-06 - val_loss: 9.9602e-06\n",
      "Epoch 147/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.6504e-05 - val_loss: 4.6428e-06\n",
      "Epoch 148/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.1265e-06 - val_loss: 3.0039e-06\n",
      "Epoch 149/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.2839e-05 - val_loss: 5.2408e-05\n",
      "Epoch 150/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 9.4788e-06 - val_loss: 2.9136e-06\n",
      "Epoch 151/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.4908e-06 - val_loss: 9.7283e-06\n",
      "Epoch 152/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.0231e-05 - val_loss: 3.7098e-06\n",
      "Epoch 153/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.1761e-05 - val_loss: 7.8304e-05\n",
      "Epoch 154/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.2157e-05 - val_loss: 3.5655e-06\n",
      "Epoch 155/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.8341e-06 - val_loss: 3.7907e-06\n",
      "Epoch 156/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.5039e-05 - val_loss: 4.8617e-06\n",
      "Epoch 157/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.3205e-06 - val_loss: 2.6268e-06\n",
      "Epoch 158/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.5391e-05 - val_loss: 4.1077e-06\n",
      "Epoch 159/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 4.2754e-06 - val_loss: 2.5302e-06\n",
      "Epoch 160/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.7354e-05 - val_loss: 2.2345e-05\n",
      "Epoch 161/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.6549e-06 - val_loss: 2.9849e-06\n",
      "Epoch 162/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.7384e-06 - val_loss: 6.7944e-06\n",
      "Epoch 163/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.4040e-05 - val_loss: 4.3320e-06\n",
      "Epoch 164/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.6813e-06 - val_loss: 2.4384e-06\n",
      "Epoch 165/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.3608e-06 - val_loss: 4.8345e-06\n",
      "Epoch 166/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.8155e-05 - val_loss: 4.7655e-06\n",
      "Epoch 167/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.0482e-06 - val_loss: 2.4252e-06\n",
      "Epoch 168/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.2407e-06 - val_loss: 2.3410e-06\n",
      "Epoch 169/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.2309e-05 - val_loss: 3.8600e-06\n",
      "Epoch 170/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 3.5022e-06 - val_loss: 2.3473e-06\n",
      "Epoch 171/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.2668e-06 - val_loss: 5.9053e-06\n",
      "Epoch 172/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.6234e-05 - val_loss: 3.9354e-06\n",
      "Epoch 173/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.6307e-06 - val_loss: 2.6768e-06\n",
      "Epoch 174/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.4961e-05 - val_loss: 6.8959e-06\n",
      "Epoch 175/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 3.2880e-06 - val_loss: 2.5309e-06\n",
      "Epoch 176/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.3895e-05 - val_loss: 4.0538e-05\n",
      "Epoch 177/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0907e-05 - val_loss: 2.7242e-06\n",
      "Epoch 178/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 2.1247e-06 - val_loss: 2.1652e-06\n",
      "Epoch 179/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.0054e-05 - val_loss: 1.2118e-05\n",
      "Epoch 180/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.9944e-06 - val_loss: 2.3816e-06\n",
      "Epoch 181/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.1048e-06 - val_loss: 2.0848e-06\n",
      "Epoch 182/1000\n",
      "43200/43200 [==============================] - 3s 81us/step - loss: 1.6664e-05 - val_loss: 1.4270e-05\n",
      "Epoch 183/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.1821e-06 - val_loss: 2.0936e-06\n",
      "Epoch 184/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 9.7486e-06 - val_loss: 1.1404e-04\n",
      "Epoch 185/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.9709e-05 - val_loss: 3.0750e-06\n",
      "Epoch 186/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.1829e-06 - val_loss: 2.0426e-06\n",
      "Epoch 187/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.4156e-05 - val_loss: 3.2904e-06\n",
      "Epoch 188/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.2527e-06 - val_loss: 2.2484e-06\n",
      "Epoch 189/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.8862e-06 - val_loss: 3.9218e-06\n",
      "Epoch 190/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 3.1138e-05 - val_loss: 6.7102e-06\n",
      "Epoch 191/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 4.1296e-06 - val_loss: 1.9170e-06\n",
      "Epoch 192/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7755e-06 - val_loss: 1.8080e-06\n",
      "Epoch 193/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 7.2105e-06 - val_loss: 2.8026e-06\n",
      "Epoch 194/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.5290e-05 - val_loss: 2.5412e-05\n",
      "Epoch 195/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.0573e-05 - val_loss: 1.9737e-06\n",
      "Epoch 196/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7810e-06 - val_loss: 1.7540e-06\n",
      "Epoch 197/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7454e-06 - val_loss: 3.2139e-06\n",
      "Epoch 198/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 1.8062e-05 - val_loss: 3.9856e-06\n",
      "Epoch 199/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.4244e-06 - val_loss: 1.7140e-06\n",
      "Epoch 200/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.6463e-05 - val_loss: 2.1888e-05\n",
      "Epoch 201/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 6.3945e-06 - val_loss: 2.0422e-06\n",
      "Epoch 202/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 1.7018e-06 - val_loss: 1.8864e-06\n",
      "Epoch 203/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 8.3461e-06 - val_loss: 5.4033e-06\n",
      "Epoch 204/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 7.7218e-06 - val_loss: 4.1352e-06\n",
      "Epoch 205/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 5.6460e-06 - val_loss: 1.0466e-05\n",
      "Epoch 206/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.7367e-06 - val_loss: 2.8542e-06\n",
      "Epoch 207/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 5.6282e-06 - val_loss: 4.3363e-06\n",
      "Epoch 208/1000\n",
      "43200/43200 [==============================] - 4s 82us/step - loss: 2.2390e-05 - val_loss: 6.7710e-06\n",
      "Epoch 209/1000\n",
      "43200/43200 [==============================] - 4s 81us/step - loss: 2.8728e-06 - val_loss: 1.7391e-06\n",
      "Epoch 00209: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in [4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48]: \n",
    "    numOfLayers = depthParam\n",
    "    filtersCountInFirstLayer = i\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, i, filterSize = filterParam)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.749173644493567e-05, 1.3900788530918362e-05, 1.4584769587600022e-05, 1.519950141452379e-05, 3.940822125514387e-06, 6.06398733301224e-06, 4.0530157813615615e-06, 8.012689439359141e-06, 2.9589559839375093e-06, 4.152041223430085e-06, 3.1091566180900068e-06, 1.7140224078578588e-06]\n",
      "[367, 329, 189, 160, 290, 208, 211, 128, 223, 147, 156, 209]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.749173644493567e-05, 1.3900788530918362e-05, 1.4584769587600022e-05, 1.519950141452379e-05, 3.940822125514387e-06, 6.06398733301224e-06, 4.0530157813615615e-06, 8.012689439359141e-06, 2.9589559839375093e-06, 4.152041223430085e-06, 3.1091566180900068e-06, 1.7140224078578588e-06]\n"
     ]
    }
   ],
   "source": [
    "print(modelsLoss)\n",
    "print(modelsEpochs)\n",
    "\n",
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. first layer filter count')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('first layer filter count')\n",
    "plt.xticks(np.arange(13), [4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48])\n",
    "plt.show()\n",
    "print(modelsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
