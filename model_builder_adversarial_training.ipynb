{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Flatten, Reshape, ZeroPadding1D, Conv1D, MaxPooling1D, UpSampling1D, Cropping1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load config\n",
    "config = loadData(\"config\")\n",
    "dataSetSize = config[\"dataSetSize\"]\n",
    "testSetBenignSize = config[\"testSetBenignSize\"]\n",
    "validationSetSize = config[\"validationSetSize\"]\n",
    "trainingSetSize = config[\"trainingSetSize\"]\n",
    "sequenceLen = config[\"sequenceLen\"]\n",
    "dimensionsCount = config[\"dimensionsCount\"]\n",
    "attackSamplesCount = config[\"attackSamplesCount\"]\n",
    "testSetSize = testSetBenignSize + attackSamplesCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = loadData(\"normalized_data_set\")\n",
    "advDataSet = loadData(\"adversarial_data_set_lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPCA(codeSize, trainingSetAdv, trainingSetLabels, validationSet, printSummary = 1, vrbs = 1, return_best = 0, learningRate = 0.001):\n",
    "    inputSize = sequenceLen * dimensionsCount\n",
    "    model = Sequential()\n",
    "    model.add(Dense(inputSize, input_shape=(inputSize,), activation='linear'))\n",
    "    model.add(Dense(int(codeSize), activation=\"linear\"))\n",
    "    model.add(Dense(inputSize, activation=\"linear\"))\n",
    "    if(printSummary == True):\n",
    "            model.summary()\n",
    "    adamOptimizer = Adam(learning_rate=learningRate) # , beta_1=0.9, beta_2=0.999, amsgrad=False        \n",
    "    model.compile(optimizer=adamOptimizer,\n",
    "        loss='mean_squared_error',\n",
    "    )\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_pca.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "    \n",
    "    trainingSet, testSet, validationSet = getReshapedDataSet(dataSet, \"PCA\")\n",
    "    history=model.fit(trainingSet, trainingSet,\n",
    "                            batch_size=5000,\n",
    "                            shuffle=True,\n",
    "                            epochs=10000,                             \n",
    "                            validation_data=(validationSet, validationSet),\n",
    "                            callbacks=callbacksArray,\n",
    "                            verbose = vrbs,\n",
    "                        )\n",
    "    \n",
    "    if(return_best):\n",
    "        best_model = load_model('best_pca.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1800)              3241800   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                90050     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1800)              91800     \n",
      "=================================================================\n",
      "Total params: 3,423,650\n",
      "Trainable params: 3,423,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11060 samples, validate on 1382 samples\n",
      "Epoch 1/10000\n",
      "11060/11060 [==============================] - 1s 67us/sample - loss: 0.1090 - val_loss: 0.0240\n",
      "Epoch 2/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0758 - val_loss: 0.0238\n",
      "Epoch 3/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0630 - val_loss: 0.0229\n",
      "Epoch 4/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0509 - val_loss: 0.0231\n",
      "Epoch 5/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0423 - val_loss: 0.0219\n",
      "Epoch 6/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0277 - val_loss: 0.0214\n",
      "Epoch 7/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 0.0209 - val_loss: 0.0205\n",
      "Epoch 8/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 9/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0143 - val_loss: 0.0188\n",
      "Epoch 10/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0124 - val_loss: 0.0179\n",
      "Epoch 11/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0110 - val_loss: 0.0167\n",
      "Epoch 12/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0095 - val_loss: 0.0156\n",
      "Epoch 13/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0082 - val_loss: 0.0145\n",
      "Epoch 14/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 0.0071 - val_loss: 0.0136\n",
      "Epoch 15/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 0.0062 - val_loss: 0.0128\n",
      "Epoch 16/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0056 - val_loss: 0.0121\n",
      "Epoch 17/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0051 - val_loss: 0.0116\n",
      "Epoch 18/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0047 - val_loss: 0.0111\n",
      "Epoch 19/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0044 - val_loss: 0.0106\n",
      "Epoch 20/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0041 - val_loss: 0.0101\n",
      "Epoch 21/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0038 - val_loss: 0.0097\n",
      "Epoch 22/10000\n",
      "11060/11060 [==============================] - 0s 16us/sample - loss: 0.0037 - val_loss: 0.0093\n",
      "Epoch 23/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0040 - val_loss: 0.0089\n",
      "Epoch 24/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0034 - val_loss: 0.0086\n",
      "Epoch 25/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0033 - val_loss: 0.0083\n",
      "Epoch 26/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0031 - val_loss: 0.0080\n",
      "Epoch 27/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0029 - val_loss: 0.0078\n",
      "Epoch 28/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0028 - val_loss: 0.0076\n",
      "Epoch 29/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 30/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 0.0025 - val_loss: 0.0073\n",
      "Epoch 31/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 32/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0023 - val_loss: 0.0071\n",
      "Epoch 33/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0023 - val_loss: 0.0070\n",
      "Epoch 34/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 35/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 36/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 37/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 38/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 39/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 40/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 41/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 42/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 43/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 44/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0015 - val_loss: 0.0058\n",
      "Epoch 45/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 46/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 47/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 48/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0013 - val_loss: 0.0052\n",
      "Epoch 49/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0013 - val_loss: 0.0051\n",
      "Epoch 50/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 51/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 52/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 53/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 54/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 55/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 56/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 57/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 58/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 59/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 60/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 61/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0010 - val_loss: 0.0035\n",
      "Epoch 62/10000\n",
      "11060/11060 [==============================] - 0s 16us/sample - loss: 9.6002e-04 - val_loss: 0.0033\n",
      "Epoch 63/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 9.2501e-04 - val_loss: 0.0032\n",
      "Epoch 64/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 9.1878e-04 - val_loss: 0.0031\n",
      "Epoch 65/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 8.9706e-04 - val_loss: 0.0030\n",
      "Epoch 66/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 8.3072e-04 - val_loss: 0.0029\n",
      "Epoch 67/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 11us/sample - loss: 8.1005e-04 - val_loss: 0.0028\n",
      "Epoch 68/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.9182e-04 - val_loss: 0.0028\n",
      "Epoch 69/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 7.6420e-04 - val_loss: 0.0027\n",
      "Epoch 70/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 7.6099e-04 - val_loss: 0.0026\n",
      "Epoch 71/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.5997e-04 - val_loss: 0.0025\n",
      "Epoch 72/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.7235e-04 - val_loss: 0.0025\n",
      "Epoch 73/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 8.3968e-04 - val_loss: 0.0024\n",
      "Epoch 74/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 9.0133e-04 - val_loss: 0.0023\n",
      "Epoch 75/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.4779e-04 - val_loss: 0.0023\n",
      "Epoch 76/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.3796e-04 - val_loss: 0.0022\n",
      "Epoch 77/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 7.0517e-04 - val_loss: 0.0022\n",
      "Epoch 78/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 8.7449e-04 - val_loss: 0.0021\n",
      "Epoch 79/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 80/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.8724e-04 - val_loss: 0.0020\n",
      "Epoch 81/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 8.0383e-04 - val_loss: 0.0020\n",
      "Epoch 82/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.8617e-04 - val_loss: 0.0019\n",
      "Epoch 83/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.4601e-04 - val_loss: 0.0019\n",
      "Epoch 84/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.2228e-04 - val_loss: 0.0018\n",
      "Epoch 85/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 6.0351e-04 - val_loss: 0.0018\n",
      "Epoch 86/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.9683e-04 - val_loss: 0.0018\n",
      "Epoch 87/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.8548e-04 - val_loss: 0.0017\n",
      "Epoch 88/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.7352e-04 - val_loss: 0.0017\n",
      "Epoch 89/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.6952e-04 - val_loss: 0.0017\n",
      "Epoch 90/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.6323e-04 - val_loss: 0.0017\n",
      "Epoch 91/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.5265e-04 - val_loss: 0.0016\n",
      "Epoch 92/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 5.4503e-04 - val_loss: 0.0016\n",
      "Epoch 93/10000\n",
      "11060/11060 [==============================] - 0s 16us/sample - loss: 5.3901e-04 - val_loss: 0.0016\n",
      "Epoch 94/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.3332e-04 - val_loss: 0.0016\n",
      "Epoch 95/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.2907e-04 - val_loss: 0.0015\n",
      "Epoch 96/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 5.3044e-04 - val_loss: 0.0015\n",
      "Epoch 97/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.5280e-04 - val_loss: 0.0015\n",
      "Epoch 98/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.2782e-04 - val_loss: 0.0015\n",
      "Epoch 99/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 8.5626e-04 - val_loss: 0.0015\n",
      "Epoch 100/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 9.3585e-04 - val_loss: 0.0015\n",
      "Epoch 101/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.8521e-04 - val_loss: 0.0014\n",
      "Epoch 102/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 9.7725e-04 - val_loss: 0.0014\n",
      "Epoch 103/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.4136e-04 - val_loss: 0.0014\n",
      "Epoch 104/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.9619e-04 - val_loss: 0.0014\n",
      "Epoch 105/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 5.9570e-04 - val_loss: 0.0014\n",
      "Epoch 106/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.6328e-04 - val_loss: 0.0014\n",
      "Epoch 107/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 5.2286e-04 - val_loss: 0.0013\n",
      "Epoch 108/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.0491e-04 - val_loss: 0.0013\n",
      "Epoch 109/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9832e-04 - val_loss: 0.0013\n",
      "Epoch 110/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.8226e-04 - val_loss: 0.0013\n",
      "Epoch 111/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.7785e-04 - val_loss: 0.0013\n",
      "Epoch 112/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.7326e-04 - val_loss: 0.0013\n",
      "Epoch 113/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.7576e-04 - val_loss: 0.0013\n",
      "Epoch 114/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9970e-04 - val_loss: 0.0013\n",
      "Epoch 115/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 5.6964e-04 - val_loss: 0.0013\n",
      "Epoch 116/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.8239e-04 - val_loss: 0.0012\n",
      "Epoch 117/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.6097e-04 - val_loss: 0.0012\n",
      "Epoch 118/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.6840e-04 - val_loss: 0.0012\n",
      "Epoch 119/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.3728e-04 - val_loss: 0.0012\n",
      "Epoch 120/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4151e-04 - val_loss: 0.0012\n",
      "Epoch 121/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.2563e-04 - val_loss: 0.0012\n",
      "Epoch 122/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.2685e-04 - val_loss: 0.0012\n",
      "Epoch 123/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 4.2585e-04 - val_loss: 0.0012\n",
      "Epoch 124/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 4.1933e-04 - val_loss: 0.0012\n",
      "Epoch 125/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.2029e-04 - val_loss: 0.0012\n",
      "Epoch 126/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.3053e-04 - val_loss: 0.0012\n",
      "Epoch 127/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4778e-04 - val_loss: 0.0012\n",
      "Epoch 128/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.1225e-04 - val_loss: 0.0011\n",
      "Epoch 129/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9314e-04 - val_loss: 0.0011\n",
      "Epoch 130/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.0324e-04 - val_loss: 0.0011\n",
      "Epoch 131/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 4.4257e-04 - val_loss: 0.0011\n",
      "Epoch 132/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.2983e-04 - val_loss: 0.0011\n",
      "Epoch 133/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.8860e-04 - val_loss: 0.0011\n",
      "Epoch 134/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.2731e-04 - val_loss: 0.0011\n",
      "Epoch 135/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.8955e-04 - val_loss: 0.0011\n",
      "Epoch 136/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9711e-04 - val_loss: 0.0011\n",
      "Epoch 137/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.8853e-04 - val_loss: 0.0011\n",
      "Epoch 138/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4049e-04 - val_loss: 0.0011\n",
      "Epoch 139/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.5561e-04 - val_loss: 0.0011\n",
      "Epoch 140/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 7.4092e-04 - val_loss: 0.0011\n",
      "Epoch 141/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.1088e-04 - val_loss: 0.0011\n",
      "Epoch 142/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.6715e-04 - val_loss: 0.0011\n",
      "Epoch 143/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.6354e-04 - val_loss: 0.0011\n",
      "Epoch 144/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.1863e-04 - val_loss: 0.0011\n",
      "Epoch 145/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.9693e-04 - val_loss: 0.0010\n",
      "Epoch 146/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.9250e-04 - val_loss: 0.0010\n",
      "Epoch 147/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 3.6936e-04 - val_loss: 0.0010\n",
      "Epoch 148/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.6829e-04 - val_loss: 0.0010\n",
      "Epoch 149/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5945e-04 - val_loss: 0.0010\n",
      "Epoch 150/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5316e-04 - val_loss: 0.0010\n",
      "Epoch 151/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4985e-04 - val_loss: 0.0010\n",
      "Epoch 152/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 3.4638e-04 - val_loss: 0.0010\n",
      "Epoch 153/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4259e-04 - val_loss: 0.0010\n",
      "Epoch 154/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.4103e-04 - val_loss: 0.0010\n",
      "Epoch 155/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 3.3809e-04 - val_loss: 0.0010\n",
      "Epoch 156/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3582e-04 - val_loss: 9.9808e-04\n",
      "Epoch 157/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3416e-04 - val_loss: 9.9378e-04\n",
      "Epoch 158/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3210e-04 - val_loss: 9.9023e-04\n",
      "Epoch 159/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3055e-04 - val_loss: 9.8751e-04\n",
      "Epoch 160/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2963e-04 - val_loss: 9.8512e-04\n",
      "Epoch 161/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2959e-04 - val_loss: 9.8233e-04\n",
      "Epoch 162/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.3655e-04 - val_loss: 9.8075e-04\n",
      "Epoch 163/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 3.7816e-04 - val_loss: 9.8485e-04\n",
      "Epoch 164/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.1979e-04 - val_loss: 0.0010\n",
      "Epoch 165/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 0.0011 - val_loss: 9.8065e-04\n",
      "Epoch 166/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9504e-04 - val_loss: 9.7515e-04\n",
      "Epoch 167/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.3009e-04 - val_loss: 9.8390e-04\n",
      "Epoch 168/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.7992e-04 - val_loss: 9.7425e-04\n",
      "Epoch 169/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.3088e-04 - val_loss: 9.6793e-04\n",
      "Epoch 170/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 4.3735e-04 - val_loss: 9.6424e-04\n",
      "Epoch 171/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.7418e-04 - val_loss: 9.6122e-04\n",
      "Epoch 172/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.6397e-04 - val_loss: 9.5721e-04\n",
      "Epoch 173/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5578e-04 - val_loss: 9.5612e-04\n",
      "Epoch 174/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5550e-04 - val_loss: 9.5208e-04\n",
      "Epoch 175/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5072e-04 - val_loss: 9.4740e-04\n",
      "Epoch 176/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4495e-04 - val_loss: 9.4405e-04\n",
      "Epoch 177/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2830e-04 - val_loss: 9.4085e-04\n",
      "Epoch 178/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 3.1486e-04 - val_loss: 9.3663e-04\n",
      "Epoch 179/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.1378e-04 - val_loss: 9.3308e-04\n",
      "Epoch 180/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1469e-04 - val_loss: 9.2929e-04\n",
      "Epoch 181/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0981e-04 - val_loss: 9.2670e-04\n",
      "Epoch 182/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 3.0524e-04 - val_loss: 9.2485e-04\n",
      "Epoch 183/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0579e-04 - val_loss: 9.2223e-04\n",
      "Epoch 184/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0545e-04 - val_loss: 9.2031e-04\n",
      "Epoch 185/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0455e-04 - val_loss: 9.1831e-04\n",
      "Epoch 186/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 3.0685e-04 - val_loss: 9.1517e-04\n",
      "Epoch 187/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.2196e-04 - val_loss: 9.1677e-04\n",
      "Epoch 188/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7299e-04 - val_loss: 9.1458e-04\n",
      "Epoch 189/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.7036e-04 - val_loss: 9.2482e-04\n",
      "Epoch 190/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.6608e-04 - val_loss: 9.1913e-04\n",
      "Epoch 191/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.3790e-04 - val_loss: 9.2644e-04\n",
      "Epoch 192/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 6.2407e-04 - val_loss: 9.1998e-04\n",
      "Epoch 193/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4428e-04 - val_loss: 9.1103e-04\n",
      "Epoch 194/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 4.0188e-04 - val_loss: 9.0005e-04\n",
      "Epoch 195/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7414e-04 - val_loss: 9.0090e-04\n",
      "Epoch 196/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7365e-04 - val_loss: 9.0069e-04\n",
      "Epoch 197/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5444e-04 - val_loss: 8.9740e-04\n",
      "Epoch 198/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2954e-04 - val_loss: 8.9248e-04\n",
      "Epoch 199/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0638e-04 - val_loss: 8.9083e-04\n",
      "Epoch 200/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.0506e-04 - val_loss: 8.8802e-04\n",
      "Epoch 201/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9716e-04 - val_loss: 8.8727e-04\n",
      "Epoch 202/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.9202e-04 - val_loss: 8.8675e-04\n",
      "Epoch 203/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.8933e-04 - val_loss: 8.8300e-04\n",
      "Epoch 204/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8429e-04 - val_loss: 8.8091e-04\n",
      "Epoch 205/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8491e-04 - val_loss: 8.7801e-04\n",
      "Epoch 206/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8268e-04 - val_loss: 8.7451e-04\n",
      "Epoch 207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8170e-04 - val_loss: 8.7297e-04\n",
      "Epoch 208/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8001e-04 - val_loss: 8.7127e-04\n",
      "Epoch 209/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.7978e-04 - val_loss: 8.6881e-04\n",
      "Epoch 210/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.8293e-04 - val_loss: 8.6585e-04\n",
      "Epoch 211/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9220e-04 - val_loss: 8.6540e-04\n",
      "Epoch 212/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2473e-04 - val_loss: 8.6319e-04\n",
      "Epoch 213/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.8452e-04 - val_loss: 8.7407e-04\n",
      "Epoch 214/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.8192e-04 - val_loss: 8.6251e-04\n",
      "Epoch 215/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8709e-04 - val_loss: 8.6666e-04\n",
      "Epoch 216/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2254e-04 - val_loss: 8.5628e-04\n",
      "Epoch 217/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.9389e-04 - val_loss: 8.5379e-04\n",
      "Epoch 218/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 3.2326e-04 - val_loss: 8.5818e-04\n",
      "Epoch 219/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4973e-04 - val_loss: 8.6272e-04\n",
      "Epoch 220/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7930e-04 - val_loss: 8.5512e-04\n",
      "Epoch 221/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5642e-04 - val_loss: 8.5207e-04\n",
      "Epoch 222/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5177e-04 - val_loss: 8.6178e-04\n",
      "Epoch 223/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7791e-04 - val_loss: 8.4968e-04\n",
      "Epoch 224/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7427e-04 - val_loss: 8.5751e-04\n",
      "Epoch 225/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 4.1369e-04 - val_loss: 8.6655e-04\n",
      "Epoch 226/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.1339e-04 - val_loss: 8.6467e-04\n",
      "Epoch 227/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.9618e-04 - val_loss: 8.4840e-04\n",
      "Epoch 228/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.5197e-04 - val_loss: 8.3742e-04\n",
      "Epoch 229/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4468e-04 - val_loss: 8.5126e-04\n",
      "Epoch 230/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5404e-04 - val_loss: 8.4033e-04\n",
      "Epoch 231/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 3.6800e-04 - val_loss: 8.3938e-04\n",
      "Epoch 232/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 4.8118e-04 - val_loss: 8.4822e-04\n",
      "Epoch 233/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 5.4559e-04 - val_loss: 8.4688e-04\n",
      "Epoch 234/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.1871e-04 - val_loss: 8.4460e-04\n",
      "Epoch 235/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 5.0567e-04 - val_loss: 8.3546e-04\n",
      "Epoch 236/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.9604e-04 - val_loss: 8.2760e-04\n",
      "Epoch 237/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2839e-04 - val_loss: 8.2881e-04\n",
      "Epoch 238/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1950e-04 - val_loss: 8.2600e-04\n",
      "Epoch 239/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0608e-04 - val_loss: 8.2258e-04\n",
      "Epoch 240/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8350e-04 - val_loss: 8.1746e-04\n",
      "Epoch 241/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.8009e-04 - val_loss: 8.1418e-04\n",
      "Epoch 242/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7062e-04 - val_loss: 8.1290e-04\n",
      "Epoch 243/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6630e-04 - val_loss: 8.1146e-04\n",
      "Epoch 244/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6367e-04 - val_loss: 8.0871e-04\n",
      "Epoch 245/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6134e-04 - val_loss: 8.0592e-04\n",
      "Epoch 246/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5976e-04 - val_loss: 8.0324e-04\n",
      "Epoch 247/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5776e-04 - val_loss: 8.0188e-04\n",
      "Epoch 248/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.5836e-04 - val_loss: 7.9928e-04\n",
      "Epoch 249/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.6042e-04 - val_loss: 7.9696e-04\n",
      "Epoch 250/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6337e-04 - val_loss: 7.9524e-04\n",
      "Epoch 251/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6862e-04 - val_loss: 7.9416e-04\n",
      "Epoch 252/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7757e-04 - val_loss: 8.0030e-04\n",
      "Epoch 253/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8844e-04 - val_loss: 7.9585e-04\n",
      "Epoch 254/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9829e-04 - val_loss: 7.9374e-04\n",
      "Epoch 255/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9067e-04 - val_loss: 7.9083e-04\n",
      "Epoch 256/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.7257e-04 - val_loss: 7.9101e-04\n",
      "Epoch 257/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2715e-04 - val_loss: 7.8710e-04\n",
      "Epoch 258/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7786e-04 - val_loss: 7.9394e-04\n",
      "Epoch 259/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4163e-04 - val_loss: 7.8055e-04\n",
      "Epoch 260/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6750e-04 - val_loss: 7.7689e-04\n",
      "Epoch 261/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8370e-04 - val_loss: 7.7909e-04\n",
      "Epoch 262/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8028e-04 - val_loss: 7.7629e-04\n",
      "Epoch 263/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 3.4512e-04 - val_loss: 7.8251e-04\n",
      "Epoch 264/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 4.2927e-04 - val_loss: 7.7969e-04\n",
      "Epoch 265/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.1264e-04 - val_loss: 7.8404e-04\n",
      "Epoch 266/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4724e-04 - val_loss: 7.8831e-04\n",
      "Epoch 267/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.3034e-04 - val_loss: 7.7197e-04\n",
      "Epoch 268/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0965e-04 - val_loss: 7.7114e-04\n",
      "Epoch 269/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9292e-04 - val_loss: 7.6596e-04\n",
      "Epoch 270/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9013e-04 - val_loss: 7.6388e-04\n",
      "Epoch 271/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0472e-04 - val_loss: 7.6242e-04\n",
      "Epoch 272/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 3.2552e-04 - val_loss: 7.6446e-04\n",
      "Epoch 273/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1440e-04 - val_loss: 7.5731e-04\n",
      "Epoch 274/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7007e-04 - val_loss: 7.5229e-04\n",
      "Epoch 275/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 10us/sample - loss: 2.6223e-04 - val_loss: 7.5221e-04\n",
      "Epoch 276/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5043e-04 - val_loss: 7.5014e-04\n",
      "Epoch 277/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5026e-04 - val_loss: 7.4781e-04\n",
      "Epoch 278/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4350e-04 - val_loss: 7.4725e-04\n",
      "Epoch 279/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4200e-04 - val_loss: 7.4413e-04\n",
      "Epoch 280/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.3960e-04 - val_loss: 7.4218e-04\n",
      "Epoch 281/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3876e-04 - val_loss: 7.3876e-04\n",
      "Epoch 282/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3636e-04 - val_loss: 7.3691e-04\n",
      "Epoch 283/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.3677e-04 - val_loss: 7.3505e-04\n",
      "Epoch 284/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3762e-04 - val_loss: 7.3323e-04\n",
      "Epoch 285/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4150e-04 - val_loss: 7.3017e-04\n",
      "Epoch 286/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4740e-04 - val_loss: 7.2896e-04\n",
      "Epoch 287/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.5129e-04 - val_loss: 7.2580e-04\n",
      "Epoch 288/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.4658e-04 - val_loss: 7.2222e-04\n",
      "Epoch 289/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3985e-04 - val_loss: 7.1491e-04\n",
      "Epoch 290/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4225e-04 - val_loss: 7.1678e-04\n",
      "Epoch 291/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6661e-04 - val_loss: 7.1190e-04\n",
      "Epoch 292/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0538e-04 - val_loss: 7.2260e-04\n",
      "Epoch 293/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2381e-04 - val_loss: 7.0923e-04\n",
      "Epoch 294/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6514e-04 - val_loss: 7.1355e-04\n",
      "Epoch 295/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.8516e-04 - val_loss: 7.1602e-04\n",
      "Epoch 296/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.7575e-04 - val_loss: 7.2757e-04\n",
      "Epoch 297/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.8427e-04 - val_loss: 7.1074e-04\n",
      "Epoch 298/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3457e-04 - val_loss: 7.2860e-04\n",
      "Epoch 299/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.5822e-04 - val_loss: 7.0765e-04\n",
      "Epoch 300/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7870e-04 - val_loss: 7.1168e-04\n",
      "Epoch 301/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.3963e-04 - val_loss: 7.0889e-04\n",
      "Epoch 302/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3453e-04 - val_loss: 6.9866e-04\n",
      "Epoch 303/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 3.5575e-04 - val_loss: 7.0914e-04\n",
      "Epoch 304/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3466e-04 - val_loss: 6.9096e-04\n",
      "Epoch 305/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1092e-04 - val_loss: 6.9471e-04\n",
      "Epoch 306/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.7325e-04 - val_loss: 6.8598e-04\n",
      "Epoch 307/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.6122e-04 - val_loss: 6.8924e-04\n",
      "Epoch 308/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.4004e-04 - val_loss: 6.8684e-04\n",
      "Epoch 309/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3465e-04 - val_loss: 6.8111e-04\n",
      "Epoch 310/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.3487e-04 - val_loss: 6.7851e-04\n",
      "Epoch 311/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.2397e-04 - val_loss: 6.7569e-04\n",
      "Epoch 312/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2280e-04 - val_loss: 6.7344e-04\n",
      "Epoch 313/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1918e-04 - val_loss: 6.7082e-04\n",
      "Epoch 314/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1895e-04 - val_loss: 6.6852e-04\n",
      "Epoch 315/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1595e-04 - val_loss: 6.6640e-04\n",
      "Epoch 316/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1512e-04 - val_loss: 6.6371e-04\n",
      "Epoch 317/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.1346e-04 - val_loss: 6.6184e-04\n",
      "Epoch 318/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.1261e-04 - val_loss: 6.6042e-04\n",
      "Epoch 319/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1233e-04 - val_loss: 6.5937e-04\n",
      "Epoch 320/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1270e-04 - val_loss: 6.5733e-04\n",
      "Epoch 321/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1582e-04 - val_loss: 6.5622e-04\n",
      "Epoch 322/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2961e-04 - val_loss: 6.5424e-04\n",
      "Epoch 323/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6529e-04 - val_loss: 6.5884e-04\n",
      "Epoch 324/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2329e-04 - val_loss: 6.5179e-04\n",
      "Epoch 325/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3562e-04 - val_loss: 6.5253e-04\n",
      "Epoch 326/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.7863e-04 - val_loss: 6.5432e-04\n",
      "Epoch 327/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.2672e-04 - val_loss: 6.4406e-04\n",
      "Epoch 328/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 2.7618e-04 - val_loss: 6.4934e-04\n",
      "Epoch 329/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.2796e-04 - val_loss: 6.6051e-04\n",
      "Epoch 330/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.4272e-04 - val_loss: 6.4236e-04\n",
      "Epoch 331/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.5585e-04 - val_loss: 6.4441e-04\n",
      "Epoch 332/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7765e-04 - val_loss: 6.4525e-04\n",
      "Epoch 333/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.7742e-04 - val_loss: 6.3627e-04\n",
      "Epoch 334/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.1521e-04 - val_loss: 6.4667e-04\n",
      "Epoch 335/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.3902e-04 - val_loss: 6.3833e-04\n",
      "Epoch 336/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.9760e-04 - val_loss: 6.3295e-04\n",
      "Epoch 337/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3717e-04 - val_loss: 6.2818e-04\n",
      "Epoch 338/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9976e-04 - val_loss: 6.3124e-04\n",
      "Epoch 339/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.3713e-04 - val_loss: 6.2535e-04\n",
      "Epoch 340/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.4164e-04 - val_loss: 6.2225e-04\n",
      "Epoch 341/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.3080e-04 - val_loss: 6.1813e-04\n",
      "Epoch 342/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3002e-04 - val_loss: 6.1937e-04\n",
      "Epoch 343/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3705e-04 - val_loss: 6.1542e-04\n",
      "Epoch 344/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5354e-04 - val_loss: 6.1154e-04\n",
      "Epoch 345/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7380e-04 - val_loss: 6.1621e-04\n",
      "Epoch 346/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8329e-04 - val_loss: 6.1233e-04\n",
      "Epoch 347/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4833e-04 - val_loss: 6.1740e-04\n",
      "Epoch 348/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.2073e-04 - val_loss: 6.0231e-04\n",
      "Epoch 349/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.8363e-04 - val_loss: 6.0706e-04\n",
      "Epoch 350/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2901e-04 - val_loss: 5.9945e-04\n",
      "Epoch 351/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2300e-04 - val_loss: 5.9612e-04\n",
      "Epoch 352/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1154e-04 - val_loss: 5.9401e-04\n",
      "Epoch 353/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.0622e-04 - val_loss: 5.9111e-04\n",
      "Epoch 354/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9905e-04 - val_loss: 5.8754e-04\n",
      "Epoch 355/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9729e-04 - val_loss: 5.8468e-04\n",
      "Epoch 356/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.9370e-04 - val_loss: 5.8219e-04\n",
      "Epoch 357/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.9172e-04 - val_loss: 5.7987e-04\n",
      "Epoch 358/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9215e-04 - val_loss: 5.7873e-04\n",
      "Epoch 359/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8999e-04 - val_loss: 5.7803e-04\n",
      "Epoch 360/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 1.8922e-04 - val_loss: 5.7635e-04\n",
      "Epoch 361/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8774e-04 - val_loss: 5.7420e-04\n",
      "Epoch 362/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8677e-04 - val_loss: 5.7253e-04\n",
      "Epoch 363/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.8645e-04 - val_loss: 5.7042e-04\n",
      "Epoch 364/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.8609e-04 - val_loss: 5.6756e-04\n",
      "Epoch 365/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8645e-04 - val_loss: 5.6585e-04\n",
      "Epoch 366/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8778e-04 - val_loss: 5.6420e-04\n",
      "Epoch 367/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9184e-04 - val_loss: 5.6302e-04\n",
      "Epoch 368/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.0165e-04 - val_loss: 5.6312e-04\n",
      "Epoch 369/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3766e-04 - val_loss: 5.6775e-04\n",
      "Epoch 370/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.2390e-04 - val_loss: 5.7214e-04\n",
      "Epoch 371/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.9675e-04 - val_loss: 5.5999e-04\n",
      "Epoch 372/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.5861e-04 - val_loss: 5.6132e-04\n",
      "Epoch 373/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9753e-04 - val_loss: 5.6431e-04\n",
      "Epoch 374/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9547e-04 - val_loss: 5.6102e-04\n",
      "Epoch 375/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7648e-04 - val_loss: 5.5645e-04\n",
      "Epoch 376/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.7901e-04 - val_loss: 5.6160e-04\n",
      "Epoch 377/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.5919e-04 - val_loss: 5.5225e-04\n",
      "Epoch 378/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3678e-04 - val_loss: 5.6128e-04\n",
      "Epoch 379/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 3.4573e-04 - val_loss: 5.5164e-04\n",
      "Epoch 380/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.8023e-04 - val_loss: 5.4602e-04\n",
      "Epoch 381/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.5890e-04 - val_loss: 5.4085e-04\n",
      "Epoch 382/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3246e-04 - val_loss: 5.3785e-04\n",
      "Epoch 383/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1440e-04 - val_loss: 5.4050e-04\n",
      "Epoch 384/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2012e-04 - val_loss: 5.3853e-04\n",
      "Epoch 385/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8346e-04 - val_loss: 5.4326e-04\n",
      "Epoch 386/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 4.4069e-04 - val_loss: 5.3958e-04\n",
      "Epoch 387/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 3.1590e-04 - val_loss: 5.4068e-04\n",
      "Epoch 388/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 3.9479e-04 - val_loss: 5.4198e-04\n",
      "Epoch 389/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4752e-04 - val_loss: 5.3766e-04\n",
      "Epoch 390/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.0072e-04 - val_loss: 5.3771e-04\n",
      "Epoch 391/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8312e-04 - val_loss: 5.2991e-04\n",
      "Epoch 392/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.4104e-04 - val_loss: 5.2422e-04\n",
      "Epoch 393/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.5506e-04 - val_loss: 5.2514e-04\n",
      "Epoch 394/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.3913e-04 - val_loss: 5.2677e-04\n",
      "Epoch 395/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.2649e-04 - val_loss: 5.2097e-04\n",
      "Epoch 396/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3256e-04 - val_loss: 5.1601e-04\n",
      "Epoch 397/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9833e-04 - val_loss: 5.1357e-04\n",
      "Epoch 398/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8256e-04 - val_loss: 5.1258e-04\n",
      "Epoch 399/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8236e-04 - val_loss: 5.1028e-04\n",
      "Epoch 400/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7628e-04 - val_loss: 5.0795e-04\n",
      "Epoch 401/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7468e-04 - val_loss: 5.0557e-04\n",
      "Epoch 402/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 1.7094e-04 - val_loss: 5.0401e-04\n",
      "Epoch 403/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.7034e-04 - val_loss: 5.0148e-04\n",
      "Epoch 404/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6859e-04 - val_loss: 4.9956e-04\n",
      "Epoch 405/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6783e-04 - val_loss: 4.9776e-04\n",
      "Epoch 406/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6853e-04 - val_loss: 4.9604e-04\n",
      "Epoch 407/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7280e-04 - val_loss: 4.9678e-04\n",
      "Epoch 408/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.8961e-04 - val_loss: 4.9900e-04\n",
      "Epoch 409/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3453e-04 - val_loss: 4.9373e-04\n",
      "Epoch 410/10000\n",
      "11060/11060 [==============================] - 0s 16us/sample - loss: 2.5374e-04 - val_loss: 4.9529e-04\n",
      "Epoch 411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7282e-04 - val_loss: 4.9186e-04\n",
      "Epoch 412/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.9524e-04 - val_loss: 4.9141e-04\n",
      "Epoch 413/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7148e-04 - val_loss: 4.9087e-04\n",
      "Epoch 414/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6901e-04 - val_loss: 4.8679e-04\n",
      "Epoch 415/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.7121e-04 - val_loss: 4.8614e-04\n",
      "Epoch 416/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.7632e-04 - val_loss: 4.8467e-04\n",
      "Epoch 417/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.8828e-04 - val_loss: 4.8873e-04\n",
      "Epoch 418/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.2684e-04 - val_loss: 4.8637e-04\n",
      "Epoch 419/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.5744e-04 - val_loss: 4.8382e-04\n",
      "Epoch 420/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.8413e-04 - val_loss: 4.8345e-04\n",
      "Epoch 421/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.8405e-04 - val_loss: 4.8047e-04\n",
      "Epoch 422/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6949e-04 - val_loss: 4.7633e-04\n",
      "Epoch 423/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6888e-04 - val_loss: 4.7614e-04\n",
      "Epoch 424/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6552e-04 - val_loss: 4.7382e-04\n",
      "Epoch 425/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.6212e-04 - val_loss: 4.7260e-04\n",
      "Epoch 426/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6078e-04 - val_loss: 4.7143e-04\n",
      "Epoch 427/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6264e-04 - val_loss: 4.7023e-04\n",
      "Epoch 428/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7408e-04 - val_loss: 4.6921e-04\n",
      "Epoch 429/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.0906e-04 - val_loss: 4.7162e-04\n",
      "Epoch 430/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.9909e-04 - val_loss: 4.8515e-04\n",
      "Epoch 431/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.4219e-04 - val_loss: 4.7319e-04\n",
      "Epoch 432/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.4564e-04 - val_loss: 4.7107e-04\n",
      "Epoch 433/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.8247e-04 - val_loss: 4.7279e-04\n",
      "Epoch 434/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1936e-04 - val_loss: 4.6735e-04\n",
      "Epoch 435/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6409e-04 - val_loss: 4.7312e-04\n",
      "Epoch 436/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7970e-04 - val_loss: 4.6675e-04\n",
      "Epoch 437/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1126e-04 - val_loss: 4.7149e-04\n",
      "Epoch 438/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1612e-04 - val_loss: 4.6565e-04\n",
      "Epoch 439/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.6342e-04 - val_loss: 4.6373e-04\n",
      "Epoch 440/10000\n",
      "11060/11060 [==============================] - 0s 13us/sample - loss: 2.4318e-04 - val_loss: 4.7129e-04\n",
      "Epoch 441/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 2.6823e-04 - val_loss: 4.6015e-04\n",
      "Epoch 442/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1260e-04 - val_loss: 4.5729e-04\n",
      "Epoch 443/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.7591e-04 - val_loss: 4.7459e-04\n",
      "Epoch 444/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.7804e-04 - val_loss: 4.5745e-04\n",
      "Epoch 445/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2552e-04 - val_loss: 4.6115e-04\n",
      "Epoch 446/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5055e-04 - val_loss: 4.5457e-04\n",
      "Epoch 447/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.9216e-04 - val_loss: 4.5002e-04\n",
      "Epoch 448/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.7962e-04 - val_loss: 4.4830e-04\n",
      "Epoch 449/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6834e-04 - val_loss: 4.4372e-04\n",
      "Epoch 450/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6290e-04 - val_loss: 4.4298e-04\n",
      "Epoch 451/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.5501e-04 - val_loss: 4.4192e-04\n",
      "Epoch 452/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5424e-04 - val_loss: 4.3994e-04\n",
      "Epoch 453/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5355e-04 - val_loss: 4.3964e-04\n",
      "Epoch 454/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5151e-04 - val_loss: 4.3787e-04\n",
      "Epoch 455/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5319e-04 - val_loss: 4.3585e-04\n",
      "Epoch 456/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.5899e-04 - val_loss: 4.3449e-04\n",
      "Epoch 457/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6265e-04 - val_loss: 4.3361e-04\n",
      "Epoch 458/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5639e-04 - val_loss: 4.3090e-04\n",
      "Epoch 459/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4569e-04 - val_loss: 4.3037e-04\n",
      "Epoch 460/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4681e-04 - val_loss: 4.2945e-04\n",
      "Epoch 461/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.5271e-04 - val_loss: 4.3048e-04\n",
      "Epoch 462/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6543e-04 - val_loss: 4.2769e-04\n",
      "Epoch 463/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.0713e-04 - val_loss: 4.2962e-04\n",
      "Epoch 464/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 2.1673e-04 - val_loss: 4.2789e-04\n",
      "Epoch 465/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4877e-04 - val_loss: 4.2652e-04\n",
      "Epoch 466/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6478e-04 - val_loss: 4.2365e-04\n",
      "Epoch 467/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4433e-04 - val_loss: 4.2307e-04\n",
      "Epoch 468/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4764e-04 - val_loss: 4.2143e-04\n",
      "Epoch 469/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.4751e-04 - val_loss: 4.1969e-04\n",
      "Epoch 470/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.4354e-04 - val_loss: 4.1890e-04\n",
      "Epoch 471/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.4559e-04 - val_loss: 4.1983e-04\n",
      "Epoch 472/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6835e-04 - val_loss: 4.2390e-04\n",
      "Epoch 473/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.5724e-04 - val_loss: 4.2690e-04\n",
      "Epoch 474/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.3586e-04 - val_loss: 4.1911e-04\n",
      "Epoch 475/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.1868e-04 - val_loss: 4.2551e-04\n",
      "Epoch 476/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3554e-04 - val_loss: 4.1353e-04\n",
      "Epoch 477/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6387e-04 - val_loss: 4.1439e-04\n",
      "Epoch 478/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7839e-04 - val_loss: 4.1256e-04\n",
      "Epoch 479/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.6746e-04 - val_loss: 4.1561e-04\n",
      "Epoch 480/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.0657e-04 - val_loss: 4.1101e-04\n",
      "Epoch 481/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3659e-04 - val_loss: 4.1628e-04\n",
      "Epoch 482/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6562e-04 - val_loss: 4.1013e-04\n",
      "Epoch 483/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8109e-04 - val_loss: 4.0789e-04\n",
      "Epoch 484/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9177e-04 - val_loss: 4.1069e-04\n",
      "Epoch 485/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.9932e-04 - val_loss: 4.0697e-04\n",
      "Epoch 486/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 1.6191e-04 - val_loss: 4.0650e-04\n",
      "Epoch 487/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.6766e-04 - val_loss: 4.0352e-04\n",
      "Epoch 488/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.4642e-04 - val_loss: 4.0327e-04\n",
      "Epoch 489/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.4548e-04 - val_loss: 4.0196e-04\n",
      "Epoch 490/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.4259e-04 - val_loss: 4.0071e-04\n",
      "Epoch 491/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.4775e-04 - val_loss: 3.9948e-04\n",
      "Epoch 492/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.5388e-04 - val_loss: 3.9736e-04\n",
      "Epoch 493/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.5030e-04 - val_loss: 4.0086e-04\n",
      "Epoch 494/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.4137e-04 - val_loss: 3.9811e-04\n",
      "Epoch 495/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.3950e-04 - val_loss: 3.9548e-04\n",
      "Epoch 496/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.3482e-04 - val_loss: 3.9432e-04\n",
      "Epoch 497/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.3108e-04 - val_loss: 3.9310e-04\n",
      "Epoch 498/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.2937e-04 - val_loss: 3.9332e-04\n",
      "Epoch 499/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.2939e-04 - val_loss: 3.9222e-04\n",
      "Epoch 500/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.3184e-04 - val_loss: 3.9145e-04\n",
      "Epoch 501/10000\n",
      "11060/11060 [==============================] - 0s 16us/sample - loss: 1.3878e-04 - val_loss: 3.9182e-04\n",
      "Epoch 502/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7011e-04 - val_loss: 3.9362e-04\n",
      "Epoch 503/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5163e-04 - val_loss: 3.9145e-04\n",
      "Epoch 504/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2675e-04 - val_loss: 3.8921e-04\n",
      "Epoch 505/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.5233e-04 - val_loss: 3.8957e-04\n",
      "Epoch 506/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6306e-04 - val_loss: 3.8807e-04\n",
      "Epoch 507/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.6778e-04 - val_loss: 3.8755e-04\n",
      "Epoch 508/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.6479e-04 - val_loss: 3.8836e-04\n",
      "Epoch 509/10000\n",
      "11060/11060 [==============================] - 0s 15us/sample - loss: 1.7090e-04 - val_loss: 3.8797e-04\n",
      "Epoch 510/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.8706e-04 - val_loss: 3.8709e-04\n",
      "Epoch 511/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.8099e-04 - val_loss: 3.8666e-04\n",
      "Epoch 512/10000\n",
      "11060/11060 [==============================] - 0s 10us/sample - loss: 1.4099e-04 - val_loss: 3.8442e-04\n",
      "Epoch 513/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 1.5907e-04 - val_loss: 3.8311e-04\n",
      "Epoch 514/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 1.7716e-04 - val_loss: 3.8839e-04\n",
      "Epoch 515/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8085e-04 - val_loss: 4.0133e-04\n",
      "Epoch 516/10000\n",
      "11060/11060 [==============================] - 0s 14us/sample - loss: 3.6158e-04 - val_loss: 3.8636e-04\n",
      "Epoch 517/10000\n",
      "11060/11060 [==============================] - 0s 12us/sample - loss: 2.7688e-04 - val_loss: 3.9434e-04\n",
      "Epoch 518/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.3802e-04 - val_loss: 3.9331e-04\n",
      "Epoch 519/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 3.1212e-04 - val_loss: 4.0313e-04\n",
      "Epoch 520/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8038e-04 - val_loss: 3.9533e-04\n",
      "Epoch 521/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.8129e-04 - val_loss: 3.9456e-04\n",
      "Epoch 522/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.5496e-04 - val_loss: 3.9037e-04\n",
      "Epoch 523/10000\n",
      "11060/11060 [==============================] - 0s 11us/sample - loss: 2.2394e-04 - val_loss: 3.9231e-04\n",
      "Epoch 00523: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelType = \"PCA\"\n",
    "trainingSetAdv, trainingSetLabels, testSet, validationSet = getReshapedAdversarialDataSet(dataSet, advDataSet, modelType)\n",
    "codeLayerSize = 50\n",
    "[model, validatoinLoss, numOfEpochs,_] = trainPCA(codeLayerSize, trainingSetAdv, trainingSetLabels, validationSet)\n",
    "model.save('Trained_Model/pca_adv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAutoencoder(numOfHiddenLayersInEncoder, codeLayerSize, trainingSet, labels, validationSet, printSummary = 1, vrbs = 1, return_best = 1, learningRate = 0.001):\n",
    "    inputSize = sequenceLen * dimensionsCount\n",
    "    layerSizeDifference = (inputSize - codeLayerSize) // (numOfHiddenLayersInEncoder + 1)\n",
    "    model = Sequential()\n",
    "    \n",
    "    print(layerSizeDifference)\n",
    "    \n",
    "    \n",
    "    #NeuronsCountInFirstLayer = 64\n",
    "    model.add(Dense(inputSize, input_shape=(inputSize,), activation='relu'))\n",
    "    for i in range(1,numOfHiddenLayersInEncoder + 1):\n",
    "        model.add(Dense(int(inputSize - (layerSizeDifference * i)), activation=\"relu\"))\n",
    "        \n",
    "    model.add(Dense(int(codeLayerSize), activation=\"relu\"))\n",
    "        \n",
    "    for j in range(1,numOfHiddenLayersInEncoder + 1):    \n",
    "        model.add(Dense(int(inputSize - (layerSizeDifference * (numOfHiddenLayersInEncoder - j + 1))), activation=\"relu\"))\n",
    "        \n",
    "    model.add(Dense(inputSize, activation=\"linear\"))\n",
    "\n",
    "    if(printSummary == True):\n",
    "            model.summary()\n",
    "\n",
    "    adamOptimizer = Adam(learning_rate=learningRate) # , beta_1=0.9, beta_2=0.999, amsgrad=False        \n",
    "            \n",
    "    model.compile(optimizer=adamOptimizer,\n",
    "        loss='mean_squared_error',\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_Autoencoder.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "    \n",
    "    history=model.fit(trainingSet, labels,\n",
    "                            batch_size=5000,\n",
    "                            shuffle=True,\n",
    "                            epochs=10000,                             \n",
    "                            validation_data=(validationSet, validationSet),\n",
    "                            callbacks=callbacksArray,\n",
    "                            verbose = vrbs,\n",
    "                        )\n",
    "    \n",
    "    if(return_best):\n",
    "        best_model = load_model('best_Autoencoder.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1800)              3241800   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 920)               1656920   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 40)                36840     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 920)               37720     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1800)              1657800   \n",
      "=================================================================\n",
      "Total params: 6,631,080\n",
      "Trainable params: 6,631,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11310 samples, validate on 1382 samples\n",
      "Epoch 1/10000\n",
      "11310/11310 [==============================] - 1s 66us/sample - loss: 0.0614 - val_loss: 0.0230\n",
      "Epoch 2/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 0.0295 - val_loss: 0.0226\n",
      "Epoch 3/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 0.0169 - val_loss: 0.0225\n",
      "Epoch 4/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 0.0143 - val_loss: 0.0222\n",
      "Epoch 5/10000\n",
      "11310/11310 [==============================] - 1s 49us/sample - loss: 0.0109 - val_loss: 0.0218\n",
      "Epoch 6/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 0.0085 - val_loss: 0.0211\n",
      "Epoch 7/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 0.0069 - val_loss: 0.0203\n",
      "Epoch 8/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 0.0058 - val_loss: 0.0192\n",
      "Epoch 9/10000\n",
      "11310/11310 [==============================] - 0s 43us/sample - loss: 0.0049 - val_loss: 0.0180\n",
      "Epoch 10/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 0.0040 - val_loss: 0.0168\n",
      "Epoch 11/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 0.0032 - val_loss: 0.0153\n",
      "Epoch 12/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 0.0027 - val_loss: 0.0136\n",
      "Epoch 13/10000\n",
      "11310/11310 [==============================] - 0s 41us/sample - loss: 0.0023 - val_loss: 0.0117\n",
      "Epoch 14/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 15/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 16/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 17/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 0.0015 - val_loss: 0.0059\n",
      "Epoch 18/10000\n",
      "11310/11310 [==============================] - 0s 41us/sample - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 19/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 20/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 21/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 22/10000\n",
      "11310/11310 [==============================] - 0s 43us/sample - loss: 8.8877e-04 - val_loss: 0.0022\n",
      "Epoch 23/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 8.1717e-04 - val_loss: 0.0020\n",
      "Epoch 24/10000\n",
      "11310/11310 [==============================] - 0s 43us/sample - loss: 7.2126e-04 - val_loss: 0.0018\n",
      "Epoch 25/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 6.4470e-04 - val_loss: 0.0017\n",
      "Epoch 26/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 5.8918e-04 - val_loss: 0.0016\n",
      "Epoch 27/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 5.4820e-04 - val_loss: 0.0015\n",
      "Epoch 28/10000\n",
      "11310/11310 [==============================] - 1s 45us/sample - loss: 5.1244e-04 - val_loss: 0.0014\n",
      "Epoch 29/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 4.9813e-04 - val_loss: 0.0014\n",
      "Epoch 30/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 6.4635e-04 - val_loss: 0.0014\n",
      "Epoch 31/10000\n",
      "11310/11310 [==============================] - 0s 42us/sample - loss: 6.5015e-04 - val_loss: 0.0014\n",
      "Epoch 32/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 5.4550e-04 - val_loss: 0.0013\n",
      "Epoch 33/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 4.9632e-04 - val_loss: 0.0013\n",
      "Epoch 34/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 4.7163e-04 - val_loss: 0.0012\n",
      "Epoch 35/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 4.4753e-04 - val_loss: 0.0012\n",
      "Epoch 36/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 4.2010e-04 - val_loss: 0.0012\n",
      "Epoch 37/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 4.0635e-04 - val_loss: 0.0011\n",
      "Epoch 38/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 3.9117e-04 - val_loss: 0.0011\n",
      "Epoch 39/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 3.7614e-04 - val_loss: 0.0011\n",
      "Epoch 40/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 3.6707e-04 - val_loss: 0.0010\n",
      "Epoch 41/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 3.5490e-04 - val_loss: 9.8576e-04\n",
      "Epoch 42/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 3.4505e-04 - val_loss: 9.5743e-04\n",
      "Epoch 43/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 3.3689e-04 - val_loss: 9.3364e-04\n",
      "Epoch 44/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 3.2801e-04 - val_loss: 9.0737e-04\n",
      "Epoch 45/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 3.2054e-04 - val_loss: 8.7801e-04\n",
      "Epoch 46/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 3.1747e-04 - val_loss: 8.5734e-04\n",
      "Epoch 47/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 3.5667e-04 - val_loss: 8.4606e-04\n",
      "Epoch 48/10000\n",
      "11310/11310 [==============================] - 0s 41us/sample - loss: 5.8591e-04 - val_loss: 8.3700e-04\n",
      "Epoch 49/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 3.5317e-04 - val_loss: 8.0452e-04\n",
      "Epoch 50/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 3.7885e-04 - val_loss: 7.8472e-04\n",
      "Epoch 51/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 3.6465e-04 - val_loss: 7.8034e-04\n",
      "Epoch 52/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 3.4094e-04 - val_loss: 7.5108e-04\n",
      "Epoch 53/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 3.2076e-04 - val_loss: 7.3889e-04\n",
      "Epoch 54/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 3.0296e-04 - val_loss: 7.2685e-04\n",
      "Epoch 55/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.9087e-04 - val_loss: 7.1076e-04\n",
      "Epoch 56/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.7786e-04 - val_loss: 6.9977e-04\n",
      "Epoch 57/10000\n",
      "11310/11310 [==============================] - 1s 48us/sample - loss: 2.6950e-04 - val_loss: 6.9070e-04\n",
      "Epoch 58/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.6102e-04 - val_loss: 6.8139e-04\n",
      "Epoch 59/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.5463e-04 - val_loss: 6.7406e-04\n",
      "Epoch 60/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 2.5000e-04 - val_loss: 6.6735e-04\n",
      "Epoch 61/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 2.4645e-04 - val_loss: 6.5838e-04\n",
      "Epoch 62/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.4365e-04 - val_loss: 6.5175e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 2.4161e-04 - val_loss: 6.4596e-04\n",
      "Epoch 64/10000\n",
      "11310/11310 [==============================] - 1s 49us/sample - loss: 2.3914e-04 - val_loss: 6.4198e-04\n",
      "Epoch 65/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 2.3643e-04 - val_loss: 6.3664e-04\n",
      "Epoch 66/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.3355e-04 - val_loss: 6.2842e-04\n",
      "Epoch 67/10000\n",
      "11310/11310 [==============================] - 1s 45us/sample - loss: 2.3111e-04 - val_loss: 6.2808e-04\n",
      "Epoch 68/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.2922e-04 - val_loss: 6.2030e-04\n",
      "Epoch 69/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.2761e-04 - val_loss: 6.1745e-04\n",
      "Epoch 70/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 2.2530e-04 - val_loss: 6.1282e-04\n",
      "Epoch 71/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.2330e-04 - val_loss: 6.0654e-04\n",
      "Epoch 72/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.2467e-04 - val_loss: 6.1105e-04\n",
      "Epoch 73/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 2.5999e-04 - val_loss: 0.0010\n",
      "Epoch 74/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 5.2319e-04 - val_loss: 7.1533e-04\n",
      "Epoch 75/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 3.0767e-04 - val_loss: 6.8026e-04\n",
      "Epoch 76/10000\n",
      "11310/11310 [==============================] - 1s 48us/sample - loss: 2.9962e-04 - val_loss: 6.5878e-04\n",
      "Epoch 77/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.6781e-04 - val_loss: 6.4895e-04\n",
      "Epoch 78/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.5304e-04 - val_loss: 6.3536e-04\n",
      "Epoch 79/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.4233e-04 - val_loss: 6.3906e-04\n",
      "Epoch 80/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 2.3726e-04 - val_loss: 6.2984e-04\n",
      "Epoch 81/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 2.2775e-04 - val_loss: 6.0312e-04\n",
      "Epoch 82/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 2.1928e-04 - val_loss: 5.8601e-04\n",
      "Epoch 83/10000\n",
      "11310/11310 [==============================] - 0s 41us/sample - loss: 2.1459e-04 - val_loss: 5.8129e-04\n",
      "Epoch 84/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.1202e-04 - val_loss: 5.9136e-04\n",
      "Epoch 85/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.0853e-04 - val_loss: 5.7235e-04\n",
      "Epoch 86/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 2.0452e-04 - val_loss: 5.7239e-04\n",
      "Epoch 87/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.0098e-04 - val_loss: 5.6002e-04\n",
      "Epoch 88/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.9831e-04 - val_loss: 5.5593e-04\n",
      "Epoch 89/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.9602e-04 - val_loss: 5.5139e-04\n",
      "Epoch 90/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.9346e-04 - val_loss: 5.4536e-04\n",
      "Epoch 91/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 1.9112e-04 - val_loss: 5.3925e-04\n",
      "Epoch 92/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.8876e-04 - val_loss: 5.3634e-04\n",
      "Epoch 93/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 1.8662e-04 - val_loss: 5.3163e-04\n",
      "Epoch 94/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.8453e-04 - val_loss: 5.2678e-04\n",
      "Epoch 95/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.8283e-04 - val_loss: 5.2181e-04\n",
      "Epoch 96/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 1.8492e-04 - val_loss: 5.1731e-04\n",
      "Epoch 97/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 2.1570e-04 - val_loss: 5.1640e-04\n",
      "Epoch 98/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 4.0170e-04 - val_loss: 5.1724e-04\n",
      "Epoch 99/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 3.9492e-04 - val_loss: 5.0835e-04\n",
      "Epoch 100/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.8106e-04 - val_loss: 5.0404e-04\n",
      "Epoch 101/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.1142e-04 - val_loss: 5.0298e-04\n",
      "Epoch 102/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.1028e-04 - val_loss: 4.9754e-04\n",
      "Epoch 103/10000\n",
      "11310/11310 [==============================] - 0s 42us/sample - loss: 2.1270e-04 - val_loss: 4.9154e-04\n",
      "Epoch 104/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 2.0790e-04 - val_loss: 4.8819e-04\n",
      "Epoch 105/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.9450e-04 - val_loss: 4.8309e-04\n",
      "Epoch 106/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.8057e-04 - val_loss: 4.8062e-04\n",
      "Epoch 107/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.6891e-04 - val_loss: 4.7562e-04\n",
      "Epoch 108/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.6176e-04 - val_loss: 4.7169e-04\n",
      "Epoch 109/10000\n",
      "11310/11310 [==============================] - 1s 49us/sample - loss: 1.5785e-04 - val_loss: 4.6779e-04\n",
      "Epoch 110/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.5573e-04 - val_loss: 4.6326e-04\n",
      "Epoch 111/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.5374e-04 - val_loss: 4.6009e-04\n",
      "Epoch 112/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.5180e-04 - val_loss: 4.5598e-04\n",
      "Epoch 113/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.4971e-04 - val_loss: 4.5296e-04\n",
      "Epoch 114/10000\n",
      "11310/11310 [==============================] - 0s 42us/sample - loss: 1.4697e-04 - val_loss: 4.4899e-04\n",
      "Epoch 115/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 1.4477e-04 - val_loss: 4.4616e-04\n",
      "Epoch 116/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 1.4278e-04 - val_loss: 4.4291e-04\n",
      "Epoch 117/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.4160e-04 - val_loss: 4.4029e-04\n",
      "Epoch 118/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.4253e-04 - val_loss: 4.4086e-04\n",
      "Epoch 119/10000\n",
      "11310/11310 [==============================] - 1s 47us/sample - loss: 1.5180e-04 - val_loss: 5.2876e-04\n",
      "Epoch 120/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.7000e-04 - val_loss: 5.0479e-04\n",
      "Epoch 121/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.5255e-04 - val_loss: 4.2885e-04\n",
      "Epoch 122/10000\n",
      "11310/11310 [==============================] - 0s 41us/sample - loss: 1.3832e-04 - val_loss: 4.2182e-04\n",
      "Epoch 123/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.3563e-04 - val_loss: 4.2763e-04\n",
      "Epoch 124/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.3563e-04 - val_loss: 4.0895e-04\n",
      "Epoch 125/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.2982e-04 - val_loss: 4.1871e-04\n",
      "Epoch 126/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 1.3124e-04 - val_loss: 4.0471e-04\n",
      "Epoch 127/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.2759e-04 - val_loss: 4.0361e-04\n",
      "Epoch 128/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.2562e-04 - val_loss: 3.9615e-04\n",
      "Epoch 129/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 1.2489e-04 - val_loss: 3.9117e-04\n",
      "Epoch 130/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.2221e-04 - val_loss: 3.8973e-04\n",
      "Epoch 131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.2156e-04 - val_loss: 3.8630e-04\n",
      "Epoch 132/10000\n",
      "11310/11310 [==============================] - 0s 42us/sample - loss: 1.2067e-04 - val_loss: 3.8613e-04\n",
      "Epoch 133/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.2064e-04 - val_loss: 3.8259e-04\n",
      "Epoch 134/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.1849e-04 - val_loss: 3.7832e-04\n",
      "Epoch 135/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.1749e-04 - val_loss: 3.7680e-04\n",
      "Epoch 136/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 1.1648e-04 - val_loss: 3.7332e-04\n",
      "Epoch 137/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.1655e-04 - val_loss: 3.7472e-04\n",
      "Epoch 138/10000\n",
      "11310/11310 [==============================] - 1s 48us/sample - loss: 1.2070e-04 - val_loss: 3.8560e-04\n",
      "Epoch 139/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.3801e-04 - val_loss: 4.2804e-04\n",
      "Epoch 140/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.7952e-04 - val_loss: 3.9883e-04\n",
      "Epoch 141/10000\n",
      "11310/11310 [==============================] - 1s 49us/sample - loss: 1.5208e-04 - val_loss: 3.7710e-04\n",
      "Epoch 142/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.2476e-04 - val_loss: 3.8122e-04\n",
      "Epoch 143/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.2040e-04 - val_loss: 3.8247e-04\n",
      "Epoch 144/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.2179e-04 - val_loss: 3.6394e-04\n",
      "Epoch 145/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.1225e-04 - val_loss: 3.6091e-04\n",
      "Epoch 146/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.1240e-04 - val_loss: 3.6159e-04\n",
      "Epoch 147/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.1191e-04 - val_loss: 3.6002e-04\n",
      "Epoch 148/10000\n",
      "11310/11310 [==============================] - 1s 48us/sample - loss: 1.0888e-04 - val_loss: 3.5548e-04\n",
      "Epoch 149/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 1.0853e-04 - val_loss: 3.5181e-04\n",
      "Epoch 150/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.0511e-04 - val_loss: 3.5335e-04\n",
      "Epoch 151/10000\n",
      "11310/11310 [==============================] - 0s 40us/sample - loss: 1.0609e-04 - val_loss: 3.4712e-04\n",
      "Epoch 152/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.0411e-04 - val_loss: 3.4776e-04\n",
      "Epoch 153/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.0398e-04 - val_loss: 3.4587e-04\n",
      "Epoch 154/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.0323e-04 - val_loss: 3.4236e-04\n",
      "Epoch 155/10000\n",
      "11310/11310 [==============================] - 0s 39us/sample - loss: 1.0358e-04 - val_loss: 3.4645e-04\n",
      "Epoch 156/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.0853e-04 - val_loss: 3.7073e-04\n",
      "Epoch 157/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.2667e-04 - val_loss: 3.9170e-04\n",
      "Epoch 158/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.3467e-04 - val_loss: 3.5305e-04\n",
      "Epoch 159/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.0785e-04 - val_loss: 3.6687e-04\n",
      "Epoch 160/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.4075e-04 - val_loss: 3.4358e-04\n",
      "Epoch 161/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.9736e-04 - val_loss: 3.5029e-04\n",
      "Epoch 162/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.7307e-04 - val_loss: 3.5691e-04\n",
      "Epoch 163/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.3371e-04 - val_loss: 3.4312e-04\n",
      "Epoch 164/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.5506e-04 - val_loss: 3.3549e-04\n",
      "Epoch 165/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.0713e-04 - val_loss: 3.3507e-04\n",
      "Epoch 166/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 1.2958e-04 - val_loss: 3.3377e-04\n",
      "Epoch 167/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.0399e-04 - val_loss: 3.3049e-04\n",
      "Epoch 168/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.0892e-04 - val_loss: 3.2346e-04\n",
      "Epoch 169/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.0214e-04 - val_loss: 3.1942e-04\n",
      "Epoch 170/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 9.8478e-05 - val_loss: 3.2007e-04\n",
      "Epoch 171/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 9.8937e-05 - val_loss: 3.1488e-04\n",
      "Epoch 172/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 9.3093e-05 - val_loss: 3.1320e-04\n",
      "Epoch 173/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 9.4539e-05 - val_loss: 3.1300e-04\n",
      "Epoch 174/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 9.1549e-05 - val_loss: 3.0991e-04\n",
      "Epoch 175/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 9.2450e-05 - val_loss: 3.1173e-04\n",
      "Epoch 176/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.0055e-04 - val_loss: 3.3501e-04\n",
      "Epoch 177/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 1.6394e-04 - val_loss: 5.3816e-04\n",
      "Epoch 178/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 2.9970e-04 - val_loss: 3.3082e-04\n",
      "Epoch 179/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 1.2880e-04 - val_loss: 3.6768e-04\n",
      "Epoch 180/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 1.4067e-04 - val_loss: 3.9546e-04\n",
      "Epoch 181/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.3526e-04 - val_loss: 3.4247e-04\n",
      "Epoch 182/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 1.2419e-04 - val_loss: 3.5897e-04\n",
      "Epoch 183/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.1519e-04 - val_loss: 3.5624e-04\n",
      "Epoch 184/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 1.1027e-04 - val_loss: 3.1693e-04\n",
      "Epoch 00184: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelType = \"fullyConnected\"\n",
    "trainingSetAdv, trainingSetLabels, testSet, validationSet = getReshapedAdversarialDataSet(dataSet, advDataSet, modelType)\n",
    "numOfHiddenLayers = 1\n",
    "codeLayerSize = 40 # 64\n",
    "[model, validatoinLoss, numOfEpochs, history] = trainAutoencoder(numOfHiddenLayers, codeLayerSize, trainingSetAdv, trainingSetLabels, validationSet, return_best = 1)\n",
    "model.save('Trained_Model/autoencoder_adv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1DConv(numOfHiddenLayersInEncoder, trainingSet, labels, validationSet, FiltersCountInFirstLayer = 32, printSummary = 1, vrbs = 1, return_best = 1, filterSize = 3, learningRate = 0.001):\n",
    "    numOfHiddenLayersInEncoder = numOfHiddenLayersInEncoder + 1\n",
    "    model = Sequential()    \n",
    "    poolingSize = 2\n",
    "    numOfFiltersInEncoder = [FiltersCountInFirstLayer]\n",
    "    paddingSize = (filterSize // 2)\n",
    "    inputLen = (sequenceLen * dimensionsCount)\n",
    "    paddedInputLength = inputLen + (paddingSize*2)\n",
    "    encoderLayersFilterSizes = [paddedInputLength]\n",
    "    model.add(ZeroPadding1D(paddingSize,input_shape=(sequenceLen * dimensionsCount,1)))\n",
    "    model.add(Conv1D(int(FiltersCountInFirstLayer), filterSize, activation='relu', padding = 'same'))\n",
    "    for i in range(1,numOfHiddenLayersInEncoder):\n",
    "        model.add(MaxPooling1D(poolingSize, padding='same'))\n",
    "        model.add(Conv1D(int(FiltersCountInFirstLayer*np.power(2,i)), filterSize, activation='relu', padding = 'same'))\n",
    "        \n",
    "        encoderLayersFilterSizes.append(int(np.ceil(paddedInputLength/np.power(2,i))))\n",
    "        numOfFiltersInEncoder.append(int(FiltersCountInFirstLayer*np.power(2,i)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((encoderLayersFilterSizes[-1], numOfFiltersInEncoder[-1])))\n",
    "    for j in range(1,numOfHiddenLayersInEncoder):    \n",
    "        model.add(Conv1D(numOfFiltersInEncoder[-j], filterSize, activation='relu', padding = 'same'))\n",
    "        model.add(UpSampling1D(poolingSize))\n",
    "\n",
    "    model.add(Conv1D(numOfFiltersInEncoder[0], filterSize, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(1, filterSize, activation='linear', padding='same'))\n",
    "    \n",
    "    toCrop = (model.layers[-1].output_shape[1] - inputLen) // 2\n",
    "    \n",
    "    model.add(Cropping1D(toCrop))\n",
    "    model.summary()\n",
    "\n",
    "    adamOptimizer = Adam(learning_rate=learningRate) # , beta_1=0.9, beta_2=0.999, amsgrad=False            \n",
    "    model.compile(optimizer=adamOptimizer,\n",
    "        loss='mean_squared_error',\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_1DConv.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "   \n",
    "    history=model.fit(trainingSet, labels,\n",
    "                            batch_size=1000,\n",
    "                            shuffle=True,\n",
    "                            epochs=10000,                             \n",
    "                            validation_data=(validationSet, validationSet),\n",
    "                            callbacks=callbacksArray,\n",
    "                            verbose = vrbs,\n",
    "                        )\n",
    "    \n",
    "    if(return_best):\n",
    "        best_model = load_model('best_1DConv.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d (ZeroPadding1 (None, 1804, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1804, 48)          240       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 902, 48)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 902, 96)           18528     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 451, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 451, 192)          73920     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 86592)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 451, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 451, 192)          147648    \n",
      "_________________________________________________________________\n",
      "up_sampling1d (UpSampling1D) (None, 902, 192)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 902, 96)           73824     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 1804, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1804, 48)          18480     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1804, 1)           193       \n",
      "_________________________________________________________________\n",
      "cropping1d (Cropping1D)      (None, 1800, 1)           0         \n",
      "=================================================================\n",
      "Total params: 332,833\n",
      "Trainable params: 332,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11310 samples, validate on 1382 samples\n",
      "Epoch 1/10000\n",
      "11310/11310 [==============================] - 11s 975us/sample - loss: 0.0419 - val_loss: 0.0212\n",
      "Epoch 2/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 0.0211 - val_loss: 0.0192\n",
      "Epoch 3/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 0.0139 - val_loss: 0.0192\n",
      "Epoch 4/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 0.0099 - val_loss: 0.0187\n",
      "Epoch 5/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 0.0073 - val_loss: 0.0167\n",
      "Epoch 6/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 0.0057 - val_loss: 0.0126\n",
      "Epoch 7/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 0.0041 - val_loss: 0.0088\n",
      "Epoch 8/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 9/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 10/10000\n",
      "11310/11310 [==============================] - 4s 360us/sample - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 11/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 12/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 13/10000\n",
      "11310/11310 [==============================] - 4s 378us/sample - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 14/10000\n",
      "11310/11310 [==============================] - 4s 390us/sample - loss: 9.1256e-04 - val_loss: 0.0020\n",
      "Epoch 15/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 7.6252e-04 - val_loss: 0.0017\n",
      "Epoch 16/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 6.7122e-04 - val_loss: 0.0014\n",
      "Epoch 17/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 5.9918e-04 - val_loss: 0.0013\n",
      "Epoch 18/10000\n",
      "11310/11310 [==============================] - 4s 360us/sample - loss: 5.3292e-04 - val_loss: 0.0011\n",
      "Epoch 19/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 4.8112e-04 - val_loss: 0.0010\n",
      "Epoch 20/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 4.5925e-04 - val_loss: 0.0010\n",
      "Epoch 21/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 4.2904e-04 - val_loss: 8.2837e-04\n",
      "Epoch 22/10000\n",
      "11310/11310 [==============================] - 4s 360us/sample - loss: 3.6561e-04 - val_loss: 7.6929e-04\n",
      "Epoch 23/10000\n",
      "11310/11310 [==============================] - 4s 360us/sample - loss: 3.2160e-04 - val_loss: 7.0015e-04\n",
      "Epoch 24/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 3.0109e-04 - val_loss: 6.9904e-04\n",
      "Epoch 25/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 3.0127e-04 - val_loss: 6.1135e-04\n",
      "Epoch 26/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 2.4730e-04 - val_loss: 5.6749e-04\n",
      "Epoch 27/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 2.3043e-04 - val_loss: 5.4693e-04\n",
      "Epoch 28/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.2782e-04 - val_loss: 5.7037e-04\n",
      "Epoch 29/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 2.4792e-04 - val_loss: 4.9677e-04\n",
      "Epoch 30/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 1.9583e-04 - val_loss: 4.6321e-04\n",
      "Epoch 31/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.8077e-04 - val_loss: 4.4651e-04\n",
      "Epoch 32/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.7384e-04 - val_loss: 4.0320e-04\n",
      "Epoch 33/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 1.9984e-04 - val_loss: 4.9179e-04\n",
      "Epoch 34/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.9759e-04 - val_loss: 3.7817e-04\n",
      "Epoch 35/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.5328e-04 - val_loss: 3.6303e-04\n",
      "Epoch 36/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.3789e-04 - val_loss: 3.4572e-04\n",
      "Epoch 37/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.4539e-04 - val_loss: 3.7024e-04\n",
      "Epoch 38/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.6153e-04 - val_loss: 3.4301e-04\n",
      "Epoch 39/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.2181e-04 - val_loss: 3.1497e-04\n",
      "Epoch 40/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 1.1735e-04 - val_loss: 3.2653e-04\n",
      "Epoch 41/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.2758e-04 - val_loss: 3.3054e-04\n",
      "Epoch 42/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.4355e-04 - val_loss: 2.9246e-04\n",
      "Epoch 43/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.0931e-04 - val_loss: 2.9835e-04\n",
      "Epoch 44/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.0139e-04 - val_loss: 2.6931e-04\n",
      "Epoch 45/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 9.2313e-05 - val_loss: 2.6455e-04\n",
      "Epoch 46/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.4355e-04 - val_loss: 2.7595e-04\n",
      "Epoch 47/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.1165e-04 - val_loss: 2.7290e-04\n",
      "Epoch 48/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 9.2270e-05 - val_loss: 2.4760e-04\n",
      "Epoch 49/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 8.1368e-05 - val_loss: 2.3779e-04\n",
      "Epoch 50/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 4s 371us/sample - loss: 7.9412e-05 - val_loss: 2.5618e-04\n",
      "Epoch 51/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 1.1246e-04 - val_loss: 2.4358e-04\n",
      "Epoch 52/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 8.7322e-05 - val_loss: 2.2384e-04\n",
      "Epoch 53/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 7.4016e-05 - val_loss: 2.2100e-04\n",
      "Epoch 54/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 6.9202e-05 - val_loss: 2.1535e-04\n",
      "Epoch 55/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 8.9803e-05 - val_loss: 2.2264e-04\n",
      "Epoch 56/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 9.0424e-05 - val_loss: 2.2752e-04\n",
      "Epoch 57/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 6.6243e-05 - val_loss: 2.1840e-04\n",
      "Epoch 58/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.1418e-04 - val_loss: 2.0333e-04\n",
      "Epoch 59/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 7.8193e-05 - val_loss: 2.1489e-04\n",
      "Epoch 60/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 6.2200e-05 - val_loss: 1.9286e-04\n",
      "Epoch 61/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 6.1126e-05 - val_loss: 1.8949e-04\n",
      "Epoch 62/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 5.7496e-05 - val_loss: 1.9128e-04\n",
      "Epoch 63/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.1717e-04 - val_loss: 2.0355e-04\n",
      "Epoch 64/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 7.8509e-05 - val_loss: 1.9268e-04\n",
      "Epoch 65/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 6.1233e-05 - val_loss: 1.8037e-04\n",
      "Epoch 66/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 5.5861e-05 - val_loss: 1.7693e-04\n",
      "Epoch 67/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 6.0644e-05 - val_loss: 1.6876e-04\n",
      "Epoch 68/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 4.8223e-05 - val_loss: 1.6770e-04\n",
      "Epoch 69/10000\n",
      "11310/11310 [==============================] - 4s 361us/sample - loss: 7.6929e-05 - val_loss: 2.3111e-04\n",
      "Epoch 70/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.1615e-04 - val_loss: 1.6917e-04\n",
      "Epoch 71/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 5.8191e-05 - val_loss: 1.5974e-04\n",
      "Epoch 72/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 4.6524e-05 - val_loss: 1.5385e-04\n",
      "Epoch 73/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 4.2793e-05 - val_loss: 1.5271e-04\n",
      "Epoch 74/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 4.1416e-05 - val_loss: 1.5955e-04\n",
      "Epoch 75/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 6.6338e-05 - val_loss: 1.6567e-04\n",
      "Epoch 76/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 5.5172e-05 - val_loss: 1.6197e-04\n",
      "Epoch 77/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 4.0768e-05 - val_loss: 1.4540e-04\n",
      "Epoch 78/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 5.2695e-05 - val_loss: 1.6630e-04\n",
      "Epoch 79/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 8.4556e-05 - val_loss: 1.5712e-04\n",
      "Epoch 80/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 4.6636e-05 - val_loss: 1.4232e-04\n",
      "Epoch 81/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 3.6281e-05 - val_loss: 1.3343e-04\n",
      "Epoch 82/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 3.7219e-05 - val_loss: 1.3349e-04\n",
      "Epoch 83/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 4.3342e-05 - val_loss: 1.3243e-04\n",
      "Epoch 84/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 4.0084e-05 - val_loss: 1.3696e-04\n",
      "Epoch 85/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.2423e-04 - val_loss: 1.5532e-04\n",
      "Epoch 86/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 7.5504e-05 - val_loss: 1.6368e-04\n",
      "Epoch 87/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 5.9586e-05 - val_loss: 1.4498e-04\n",
      "Epoch 88/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 4.4309e-05 - val_loss: 1.4103e-04\n",
      "Epoch 89/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 3.6222e-05 - val_loss: 1.2741e-04\n",
      "Epoch 90/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 3.6428e-05 - val_loss: 1.3004e-04\n",
      "Epoch 91/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 3.3938e-05 - val_loss: 1.2200e-04\n",
      "Epoch 92/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 3.9912e-05 - val_loss: 1.8809e-04\n",
      "Epoch 93/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 6.7740e-05 - val_loss: 1.5620e-04\n",
      "Epoch 94/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 3.7754e-05 - val_loss: 1.2403e-04\n",
      "Epoch 95/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.9305e-05 - val_loss: 1.2487e-04\n",
      "Epoch 96/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.0163e-04 - val_loss: 1.3363e-04\n",
      "Epoch 97/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 5.5635e-05 - val_loss: 1.1591e-04\n",
      "Epoch 98/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 3.4237e-05 - val_loss: 1.1836e-04\n",
      "Epoch 99/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.8046e-05 - val_loss: 1.1117e-04\n",
      "Epoch 100/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.5742e-05 - val_loss: 1.1021e-04\n",
      "Epoch 101/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.4187e-05 - val_loss: 1.0830e-04\n",
      "Epoch 102/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 4.2770e-05 - val_loss: 1.9549e-04\n",
      "Epoch 103/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.3842e-04 - val_loss: 1.3806e-04\n",
      "Epoch 104/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 4.6834e-05 - val_loss: 1.1128e-04\n",
      "Epoch 105/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 2.9929e-05 - val_loss: 1.0665e-04\n",
      "Epoch 106/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.5112e-05 - val_loss: 1.0446e-04\n",
      "Epoch 107/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.3219e-05 - val_loss: 1.0228e-04\n",
      "Epoch 108/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.4618e-05 - val_loss: 1.0288e-04\n",
      "Epoch 109/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 3.0723e-05 - val_loss: 1.0311e-04\n",
      "Epoch 110/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.4628e-05 - val_loss: 1.0056e-04\n",
      "Epoch 111/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.6692e-05 - val_loss: 1.0785e-04\n",
      "Epoch 112/10000\n",
      "11310/11310 [==============================] - 4s 346us/sample - loss: 2.6984e-05 - val_loss: 1.0022e-04\n",
      "Epoch 113/10000\n",
      "11310/11310 [==============================] - 4s 345us/sample - loss: 4.5980e-05 - val_loss: 1.3119e-04\n",
      "Epoch 114/10000\n",
      "11310/11310 [==============================] - 4s 352us/sample - loss: 1.0634e-04 - val_loss: 1.2050e-04\n",
      "Epoch 115/10000\n",
      "11310/11310 [==============================] - 4s 345us/sample - loss: 4.5242e-05 - val_loss: 1.0915e-04\n",
      "Epoch 116/10000\n",
      "11310/11310 [==============================] - 4s 348us/sample - loss: 2.7969e-05 - val_loss: 9.8170e-05\n",
      "Epoch 117/10000\n",
      "11310/11310 [==============================] - 4s 345us/sample - loss: 2.2401e-05 - val_loss: 9.4631e-05\n",
      "Epoch 118/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 4s 354us/sample - loss: 1.9968e-05 - val_loss: 9.2965e-05\n",
      "Epoch 119/10000\n",
      "11310/11310 [==============================] - 4s 345us/sample - loss: 1.9154e-05 - val_loss: 9.5369e-05\n",
      "Epoch 120/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 4.7388e-05 - val_loss: 2.0921e-04\n",
      "Epoch 121/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.4395e-04 - val_loss: 1.2889e-04\n",
      "Epoch 122/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 4.4619e-05 - val_loss: 9.9691e-05\n",
      "Epoch 123/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.7127e-05 - val_loss: 9.2398e-05\n",
      "Epoch 124/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.1321e-05 - val_loss: 8.9324e-05\n",
      "Epoch 125/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.8814e-05 - val_loss: 9.2320e-05\n",
      "Epoch 126/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.1140e-05 - val_loss: 8.7992e-05\n",
      "Epoch 127/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.8881e-05 - val_loss: 8.6599e-05\n",
      "Epoch 128/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.7963e-05 - val_loss: 8.5771e-05\n",
      "Epoch 129/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.7474e-05 - val_loss: 8.7257e-05\n",
      "Epoch 130/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.3712e-05 - val_loss: 9.0393e-05\n",
      "Epoch 131/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 2.0889e-05 - val_loss: 8.5091e-05\n",
      "Epoch 132/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 2.3013e-05 - val_loss: 9.0991e-05\n",
      "Epoch 133/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 8.1646e-05 - val_loss: 9.7014e-05\n",
      "Epoch 134/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 3.3049e-05 - val_loss: 8.6928e-05\n",
      "Epoch 135/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 2.1764e-05 - val_loss: 8.1678e-05\n",
      "Epoch 136/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.8901e-05 - val_loss: 8.4588e-05\n",
      "Epoch 137/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 2.1900e-05 - val_loss: 8.9926e-05\n",
      "Epoch 138/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 6.2738e-05 - val_loss: 9.1356e-05\n",
      "Epoch 139/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 2.7937e-05 - val_loss: 7.9148e-05\n",
      "Epoch 140/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.8208e-05 - val_loss: 8.1269e-05\n",
      "Epoch 141/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.7001e-05 - val_loss: 7.6577e-05\n",
      "Epoch 142/10000\n",
      "11310/11310 [==============================] - 4s 379us/sample - loss: 1.6035e-05 - val_loss: 7.7119e-05\n",
      "Epoch 143/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.9873e-05 - val_loss: 9.2145e-05\n",
      "Epoch 144/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.1288e-04 - val_loss: 1.0838e-04\n",
      "Epoch 145/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 5.5204e-05 - val_loss: 8.5122e-05\n",
      "Epoch 146/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 2.7134e-05 - val_loss: 7.6233e-05\n",
      "Epoch 147/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.9572e-05 - val_loss: 7.4891e-05\n",
      "Epoch 148/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.5850e-05 - val_loss: 7.2591e-05\n",
      "Epoch 149/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 1.4826e-05 - val_loss: 7.2679e-05\n",
      "Epoch 150/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.1507e-05 - val_loss: 7.6232e-05\n",
      "Epoch 151/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 2.7606e-05 - val_loss: 7.2339e-05\n",
      "Epoch 152/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 1.8825e-05 - val_loss: 7.1833e-05\n",
      "Epoch 153/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.8156e-05 - val_loss: 7.4951e-05\n",
      "Epoch 154/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 5.1380e-05 - val_loss: 8.8915e-05\n",
      "Epoch 155/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 3.1066e-05 - val_loss: 7.9655e-05\n",
      "Epoch 156/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 2.1568e-05 - val_loss: 6.9906e-05\n",
      "Epoch 157/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.6303e-05 - val_loss: 6.9321e-05\n",
      "Epoch 158/10000\n",
      "11310/11310 [==============================] - 4s 378us/sample - loss: 1.5230e-05 - val_loss: 6.7657e-05\n",
      "Epoch 159/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 1.8093e-05 - val_loss: 8.6297e-05\n",
      "Epoch 160/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 1.6186e-04 - val_loss: 1.3527e-04\n",
      "Epoch 161/10000\n",
      "11310/11310 [==============================] - 4s 363us/sample - loss: 5.3086e-05 - val_loss: 7.8906e-05\n",
      "Epoch 162/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 2.4386e-05 - val_loss: 6.8099e-05\n",
      "Epoch 163/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.6763e-05 - val_loss: 6.8266e-05\n",
      "Epoch 164/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.4208e-05 - val_loss: 6.4910e-05\n",
      "Epoch 165/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.2962e-05 - val_loss: 6.4381e-05\n",
      "Epoch 166/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.2527e-05 - val_loss: 6.4213e-05\n",
      "Epoch 167/10000\n",
      "11310/11310 [==============================] - 4s 364us/sample - loss: 1.2744e-05 - val_loss: 6.2262e-05\n",
      "Epoch 168/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 1.5683e-05 - val_loss: 6.4743e-05\n",
      "Epoch 169/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 1.9411e-05 - val_loss: 6.8229e-05\n",
      "Epoch 170/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 1.8425e-05 - val_loss: 6.3326e-05\n",
      "Epoch 171/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 5.4462e-05 - val_loss: 6.5868e-05\n",
      "Epoch 172/10000\n",
      "11310/11310 [==============================] - 4s 351us/sample - loss: 3.3963e-05 - val_loss: 6.5719e-05\n",
      "Epoch 173/10000\n",
      "11310/11310 [==============================] - 4s 346us/sample - loss: 1.8538e-05 - val_loss: 6.0508e-05\n",
      "Epoch 174/10000\n",
      "11310/11310 [==============================] - 4s 348us/sample - loss: 1.3396e-05 - val_loss: 5.8995e-05\n",
      "Epoch 175/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.1861e-05 - val_loss: 5.7987e-05\n",
      "Epoch 176/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 1.5893e-05 - val_loss: 6.8233e-05\n",
      "Epoch 177/10000\n",
      "11310/11310 [==============================] - 4s 375us/sample - loss: 6.2818e-05 - val_loss: 6.8107e-05\n",
      "Epoch 178/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 3.3107e-05 - val_loss: 7.1941e-05\n",
      "Epoch 179/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.8586e-05 - val_loss: 5.8470e-05\n",
      "Epoch 180/10000\n",
      "11310/11310 [==============================] - 4s 380us/sample - loss: 1.8692e-05 - val_loss: 5.5716e-05\n",
      "Epoch 181/10000\n",
      "11310/11310 [==============================] - 4s 349us/sample - loss: 1.2335e-05 - val_loss: 5.6974e-05\n",
      "Epoch 182/10000\n",
      "11310/11310 [==============================] - 4s 346us/sample - loss: 1.5317e-05 - val_loss: 6.1551e-05\n",
      "Epoch 183/10000\n",
      "11310/11310 [==============================] - 4s 347us/sample - loss: 7.4670e-05 - val_loss: 6.5041e-05\n",
      "Epoch 184/10000\n",
      "11310/11310 [==============================] - 4s 348us/sample - loss: 3.1864e-05 - val_loss: 6.8897e-05\n",
      "Epoch 185/10000\n",
      "11310/11310 [==============================] - 4s 348us/sample - loss: 2.2994e-05 - val_loss: 5.6552e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/10000\n",
      "11310/11310 [==============================] - 4s 345us/sample - loss: 1.3371e-05 - val_loss: 5.2862e-05\n",
      "Epoch 187/10000\n",
      "11310/11310 [==============================] - 4s 344us/sample - loss: 1.1595e-05 - val_loss: 5.2183e-05\n",
      "Epoch 188/10000\n",
      "11310/11310 [==============================] - 4s 351us/sample - loss: 1.1107e-05 - val_loss: 5.2143e-05\n",
      "Epoch 189/10000\n",
      "11310/11310 [==============================] - 4s 350us/sample - loss: 1.3617e-05 - val_loss: 5.2076e-05\n",
      "Epoch 190/10000\n",
      "11310/11310 [==============================] - 4s 347us/sample - loss: 1.5693e-05 - val_loss: 5.2383e-05\n",
      "Epoch 191/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 4.8739e-05 - val_loss: 8.5897e-05\n",
      "Epoch 192/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 3.4915e-05 - val_loss: 5.6685e-05\n",
      "Epoch 193/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.8803e-05 - val_loss: 5.1356e-05\n",
      "Epoch 194/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 1.2560e-05 - val_loss: 4.8965e-05\n",
      "Epoch 195/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.7678e-05 - val_loss: 5.4678e-05\n",
      "Epoch 196/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 6.6478e-05 - val_loss: 6.1504e-05\n",
      "Epoch 197/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 2.5655e-05 - val_loss: 4.9447e-05\n",
      "Epoch 198/10000\n",
      "11310/11310 [==============================] - 4s 388us/sample - loss: 1.3858e-05 - val_loss: 4.8132e-05\n",
      "Epoch 199/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 1.4172e-05 - val_loss: 5.0638e-05\n",
      "Epoch 200/10000\n",
      "11310/11310 [==============================] - 4s 349us/sample - loss: 1.3418e-05 - val_loss: 4.7686e-05\n",
      "Epoch 201/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 4.2049e-05 - val_loss: 5.1608e-05\n",
      "Epoch 202/10000\n",
      "11310/11310 [==============================] - 4s 392us/sample - loss: 2.7791e-05 - val_loss: 4.8578e-05\n",
      "Epoch 203/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 1.8946e-05 - val_loss: 4.7265e-05\n",
      "Epoch 204/10000\n",
      "11310/11310 [==============================] - 4s 396us/sample - loss: 1.2300e-05 - val_loss: 4.5595e-05\n",
      "Epoch 205/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.1547e-05 - val_loss: 4.4520e-05\n",
      "Epoch 206/10000\n",
      "11310/11310 [==============================] - 4s 353us/sample - loss: 9.3977e-06 - val_loss: 4.4128e-05\n",
      "Epoch 207/10000\n",
      "11310/11310 [==============================] - 5s 408us/sample - loss: 1.5521e-05 - val_loss: 5.0724e-05\n",
      "Epoch 208/10000\n",
      "11310/11310 [==============================] - 4s 381us/sample - loss: 7.8759e-05 - val_loss: 6.8103e-05\n",
      "Epoch 209/10000\n",
      "11310/11310 [==============================] - 4s 386us/sample - loss: 3.2769e-05 - val_loss: 4.6239e-05\n",
      "Epoch 210/10000\n",
      "11310/11310 [==============================] - 4s 384us/sample - loss: 1.7380e-05 - val_loss: 4.4168e-05\n",
      "Epoch 211/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 1.1657e-05 - val_loss: 4.3846e-05\n",
      "Epoch 212/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 9.7284e-06 - val_loss: 4.1834e-05\n",
      "Epoch 213/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 9.6153e-06 - val_loss: 4.1588e-05\n",
      "Epoch 214/10000\n",
      "11310/11310 [==============================] - 4s 365us/sample - loss: 3.1364e-05 - val_loss: 5.9003e-05\n",
      "Epoch 215/10000\n",
      "11310/11310 [==============================] - 4s 375us/sample - loss: 7.3183e-05 - val_loss: 5.0574e-05\n",
      "Epoch 216/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 2.9387e-05 - val_loss: 4.5101e-05\n",
      "Epoch 217/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.6156e-05 - val_loss: 4.3741e-05\n",
      "Epoch 218/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.0818e-05 - val_loss: 4.1443e-05\n",
      "Epoch 219/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 9.7774e-06 - val_loss: 4.1895e-05\n",
      "Epoch 220/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.3980e-05 - val_loss: 4.6016e-05\n",
      "Epoch 221/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 6.4628e-05 - val_loss: 4.2142e-05\n",
      "Epoch 222/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.6277e-05 - val_loss: 4.7447e-05\n",
      "Epoch 223/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.5006e-05 - val_loss: 3.9026e-05\n",
      "Epoch 224/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 9.8580e-06 - val_loss: 4.3701e-05\n",
      "Epoch 225/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.7534e-05 - val_loss: 4.4091e-05\n",
      "Epoch 226/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.1541e-05 - val_loss: 4.0238e-05\n",
      "Epoch 227/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 2.0929e-05 - val_loss: 7.2843e-05\n",
      "Epoch 228/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 6.3477e-05 - val_loss: 4.4325e-05\n",
      "Epoch 229/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 1.5748e-05 - val_loss: 3.8966e-05\n",
      "Epoch 230/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 9.8591e-06 - val_loss: 3.7452e-05\n",
      "Epoch 231/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 8.3604e-06 - val_loss: 3.7609e-05\n",
      "Epoch 232/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 3.5207e-05 - val_loss: 6.8242e-05\n",
      "Epoch 233/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 4.2269e-05 - val_loss: 5.5473e-05\n",
      "Epoch 234/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 2.4479e-05 - val_loss: 4.4157e-05\n",
      "Epoch 235/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.2440e-05 - val_loss: 3.8881e-05\n",
      "Epoch 236/10000\n",
      "11310/11310 [==============================] - 4s 396us/sample - loss: 9.3020e-06 - val_loss: 3.7127e-05\n",
      "Epoch 237/10000\n",
      "11310/11310 [==============================] - 4s 353us/sample - loss: 8.1733e-06 - val_loss: 3.4726e-05\n",
      "Epoch 238/10000\n",
      "11310/11310 [==============================] - 4s 352us/sample - loss: 8.6150e-06 - val_loss: 3.4978e-05\n",
      "Epoch 239/10000\n",
      "11310/11310 [==============================] - 4s 346us/sample - loss: 3.4980e-05 - val_loss: 6.6920e-05\n",
      "Epoch 240/10000\n",
      "11310/11310 [==============================] - 4s 362us/sample - loss: 3.2417e-05 - val_loss: 4.7436e-05\n",
      "Epoch 241/10000\n",
      "11310/11310 [==============================] - 4s 354us/sample - loss: 1.6308e-05 - val_loss: 3.4516e-05\n",
      "Epoch 242/10000\n",
      "11310/11310 [==============================] - 4s 356us/sample - loss: 1.0396e-05 - val_loss: 3.4025e-05\n",
      "Epoch 243/10000\n",
      "11310/11310 [==============================] - 4s 346us/sample - loss: 9.1105e-06 - val_loss: 3.4716e-05\n",
      "Epoch 244/10000\n",
      "11310/11310 [==============================] - 4s 359us/sample - loss: 2.0820e-05 - val_loss: 4.1730e-05\n",
      "Epoch 245/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 2.3924e-05 - val_loss: 3.4754e-05\n",
      "Epoch 246/10000\n",
      "11310/11310 [==============================] - 4s 350us/sample - loss: 2.4971e-05 - val_loss: 4.6809e-05\n",
      "Epoch 247/10000\n",
      "11310/11310 [==============================] - 4s 355us/sample - loss: 3.1746e-05 - val_loss: 3.4583e-05\n",
      "Epoch 248/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 9.9575e-06 - val_loss: 3.3287e-05\n",
      "Epoch 249/10000\n",
      "11310/11310 [==============================] - 4s 384us/sample - loss: 8.9434e-06 - val_loss: 3.2948e-05\n",
      "Epoch 250/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 2.3403e-05 - val_loss: 6.9580e-05\n",
      "Epoch 251/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 7.5279e-05 - val_loss: 4.6032e-05\n",
      "Epoch 252/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 2.1715e-05 - val_loss: 3.6948e-05\n",
      "Epoch 253/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.3070e-05 - val_loss: 3.2258e-05\n",
      "Epoch 254/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.0039e-05 - val_loss: 3.2411e-05\n",
      "Epoch 255/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.0211e-05 - val_loss: 3.8677e-05\n",
      "Epoch 256/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 2.9214e-05 - val_loss: 3.3522e-05\n",
      "Epoch 257/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 1.3447e-05 - val_loss: 3.3036e-05\n",
      "Epoch 258/10000\n",
      "11310/11310 [==============================] - 4s 375us/sample - loss: 1.1349e-05 - val_loss: 3.1616e-05\n",
      "Epoch 259/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 8.8834e-06 - val_loss: 3.5058e-05\n",
      "Epoch 260/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.5335e-05 - val_loss: 3.9949e-05\n",
      "Epoch 261/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 5.7035e-05 - val_loss: 3.5782e-05\n",
      "Epoch 262/10000\n",
      "11310/11310 [==============================] - 4s 366us/sample - loss: 2.1032e-05 - val_loss: 3.5344e-05\n",
      "Epoch 263/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.3128e-05 - val_loss: 3.3161e-05\n",
      "Epoch 264/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 8.2377e-06 - val_loss: 3.0347e-05\n",
      "Epoch 265/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 7.1534e-06 - val_loss: 2.9586e-05\n",
      "Epoch 266/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 8.8468e-06 - val_loss: 3.5622e-05\n",
      "Epoch 267/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 5.1785e-05 - val_loss: 3.1802e-05\n",
      "Epoch 268/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.6018e-05 - val_loss: 4.1549e-05\n",
      "Epoch 269/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 6.1721e-05 - val_loss: 3.6073e-05\n",
      "Epoch 270/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 2.2185e-05 - val_loss: 3.1408e-05\n",
      "Epoch 271/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.1865e-05 - val_loss: 2.9840e-05\n",
      "Epoch 272/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 8.2097e-06 - val_loss: 2.8964e-05\n",
      "Epoch 273/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 6.9522e-06 - val_loss: 2.8462e-05\n",
      "Epoch 274/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 6.3895e-06 - val_loss: 2.8068e-05\n",
      "Epoch 275/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 6.5316e-06 - val_loss: 2.9067e-05\n",
      "Epoch 276/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 6.0240e-05 - val_loss: 4.3750e-05\n",
      "Epoch 277/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 6.6618e-05 - val_loss: 5.1703e-05\n",
      "Epoch 278/10000\n",
      "11310/11310 [==============================] - 4s 377us/sample - loss: 2.6506e-05 - val_loss: 3.9778e-05\n",
      "Epoch 279/10000\n",
      "11310/11310 [==============================] - 4s 395us/sample - loss: 1.4523e-05 - val_loss: 3.4799e-05\n",
      "Epoch 280/10000\n",
      "11310/11310 [==============================] - 4s 383us/sample - loss: 8.9551e-06 - val_loss: 2.9577e-05\n",
      "Epoch 281/10000\n",
      "11310/11310 [==============================] - 5s 398us/sample - loss: 7.0398e-06 - val_loss: 2.8002e-05\n",
      "Epoch 282/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 6.6281e-06 - val_loss: 2.7594e-05\n",
      "Epoch 283/10000\n",
      "11310/11310 [==============================] - 4s 379us/sample - loss: 7.6844e-06 - val_loss: 2.8151e-05\n",
      "Epoch 284/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 8.1151e-06 - val_loss: 2.9055e-05\n",
      "Epoch 285/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 3.5905e-05 - val_loss: 3.9885e-05\n",
      "Epoch 286/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 2.4653e-05 - val_loss: 3.1127e-05\n",
      "Epoch 287/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 9.7222e-06 - val_loss: 2.7407e-05\n",
      "Epoch 288/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 7.8146e-06 - val_loss: 2.6833e-05\n",
      "Epoch 289/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.7684e-05 - val_loss: 3.1087e-05\n",
      "Epoch 290/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.7915e-05 - val_loss: 2.8992e-05\n",
      "Epoch 291/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 3.4564e-05 - val_loss: 3.5164e-05\n",
      "Epoch 292/10000\n",
      "11310/11310 [==============================] - 4s 391us/sample - loss: 3.5651e-05 - val_loss: 2.7609e-05\n",
      "Epoch 293/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.2891e-05 - val_loss: 2.6876e-05\n",
      "Epoch 294/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 8.0028e-06 - val_loss: 2.7159e-05\n",
      "Epoch 295/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 7.7423e-06 - val_loss: 2.6766e-05\n",
      "Epoch 296/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 9.9641e-06 - val_loss: 3.2679e-05\n",
      "Epoch 297/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 6.1199e-05 - val_loss: 7.9811e-05\n",
      "Epoch 298/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 4.1878e-05 - val_loss: 4.6707e-05\n",
      "Epoch 299/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 2.6629e-05 - val_loss: 3.7430e-05\n",
      "Epoch 300/10000\n",
      "11310/11310 [==============================] - 4s 380us/sample - loss: 1.5145e-05 - val_loss: 2.8483e-05\n",
      "Epoch 301/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.0108e-05 - val_loss: 2.9556e-05\n",
      "Epoch 302/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 7.2714e-06 - val_loss: 2.5390e-05\n",
      "Epoch 303/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.3402e-05 - val_loss: 4.1371e-05\n",
      "Epoch 304/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 4.3680e-05 - val_loss: 2.5925e-05\n",
      "Epoch 305/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.6475e-05 - val_loss: 2.8818e-05\n",
      "Epoch 306/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.3798e-05 - val_loss: 2.6953e-05\n",
      "Epoch 307/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 7.0435e-06 - val_loss: 2.5487e-05\n",
      "Epoch 308/10000\n",
      "11310/11310 [==============================] - 4s 375us/sample - loss: 6.3607e-06 - val_loss: 2.4831e-05\n",
      "Epoch 309/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 1.1122e-05 - val_loss: 2.7020e-05\n",
      "Epoch 310/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.4341e-05 - val_loss: 2.5617e-05\n",
      "Epoch 311/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 3.3965e-05 - val_loss: 1.0312e-04\n",
      "Epoch 312/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 4.2816e-05 - val_loss: 2.8256e-05\n",
      "Epoch 313/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 1.7839e-05 - val_loss: 2.5782e-05\n",
      "Epoch 314/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 8.9952e-06 - val_loss: 2.4235e-05\n",
      "Epoch 315/10000\n",
      "11310/11310 [==============================] - 4s 375us/sample - loss: 7.4572e-06 - val_loss: 2.4228e-05\n",
      "Epoch 316/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 7.1564e-06 - val_loss: 2.4153e-05\n",
      "Epoch 317/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 2.1467e-05 - val_loss: 3.8853e-05\n",
      "Epoch 318/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 7.8815e-05 - val_loss: 3.5192e-05\n",
      "Epoch 319/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.8137e-05 - val_loss: 2.4749e-05\n",
      "Epoch 320/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 1.1714e-05 - val_loss: 2.4764e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 7.2762e-06 - val_loss: 2.5779e-05\n",
      "Epoch 322/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.2672e-05 - val_loss: 4.5353e-05\n",
      "Epoch 323/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 3.7008e-05 - val_loss: 2.8532e-05\n",
      "Epoch 324/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.2092e-05 - val_loss: 2.3751e-05\n",
      "Epoch 325/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 7.2297e-06 - val_loss: 2.3455e-05\n",
      "Epoch 326/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 6.0876e-06 - val_loss: 2.2878e-05\n",
      "Epoch 327/10000\n",
      "11310/11310 [==============================] - 4s 385us/sample - loss: 5.6109e-06 - val_loss: 2.2620e-05\n",
      "Epoch 328/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 6.5238e-06 - val_loss: 2.8948e-05\n",
      "Epoch 329/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 6.2772e-05 - val_loss: 2.6630e-05\n",
      "Epoch 330/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.3187e-05 - val_loss: 2.4676e-05\n",
      "Epoch 331/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.1335e-05 - val_loss: 2.3305e-05\n",
      "Epoch 332/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 6.9194e-06 - val_loss: 2.3147e-05\n",
      "Epoch 333/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 5.6395e-06 - val_loss: 2.2373e-05\n",
      "Epoch 334/10000\n",
      "11310/11310 [==============================] - 4s 374us/sample - loss: 5.9050e-06 - val_loss: 2.2257e-05\n",
      "Epoch 335/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.2424e-05 - val_loss: 3.0350e-05\n",
      "Epoch 336/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 3.1601e-05 - val_loss: 3.4837e-05\n",
      "Epoch 337/10000\n",
      "11310/11310 [==============================] - 4s 373us/sample - loss: 4.0168e-05 - val_loss: 2.7924e-05\n",
      "Epoch 338/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 1.2441e-05 - val_loss: 2.3203e-05\n",
      "Epoch 339/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 7.8031e-06 - val_loss: 2.1940e-05\n",
      "Epoch 340/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 6.0563e-06 - val_loss: 2.2187e-05\n",
      "Epoch 341/10000\n",
      "11310/11310 [==============================] - 4s 376us/sample - loss: 1.4398e-05 - val_loss: 4.0571e-05\n",
      "Epoch 342/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 9.1551e-05 - val_loss: 3.2463e-05\n",
      "Epoch 343/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 2.7225e-05 - val_loss: 2.4261e-05\n",
      "Epoch 344/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 1.0889e-05 - val_loss: 2.2150e-05\n",
      "Epoch 345/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 6.5248e-06 - val_loss: 2.2263e-05\n",
      "Epoch 346/10000\n",
      "11310/11310 [==============================] - 4s 367us/sample - loss: 5.4747e-06 - val_loss: 2.1931e-05\n",
      "Epoch 347/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 4.9192e-06 - val_loss: 2.1047e-05\n",
      "Epoch 348/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 5.2202e-06 - val_loss: 2.1309e-05\n",
      "Epoch 349/10000\n",
      "11310/11310 [==============================] - 4s 371us/sample - loss: 1.2575e-05 - val_loss: 3.3170e-05\n",
      "Epoch 350/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 4.2950e-05 - val_loss: 3.0719e-05\n",
      "Epoch 351/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 1.2330e-05 - val_loss: 2.3031e-05\n",
      "Epoch 352/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 7.5837e-06 - val_loss: 2.2144e-05\n",
      "Epoch 353/10000\n",
      "11310/11310 [==============================] - 4s 378us/sample - loss: 5.5390e-06 - val_loss: 2.2504e-05\n",
      "Epoch 354/10000\n",
      "11310/11310 [==============================] - 4s 368us/sample - loss: 2.3148e-05 - val_loss: 4.4111e-05\n",
      "Epoch 355/10000\n",
      "11310/11310 [==============================] - 4s 372us/sample - loss: 3.4135e-05 - val_loss: 2.7904e-05\n",
      "Epoch 356/10000\n",
      "11310/11310 [==============================] - 4s 370us/sample - loss: 1.4702e-05 - val_loss: 2.3886e-05\n",
      "Epoch 357/10000\n",
      "11310/11310 [==============================] - 4s 369us/sample - loss: 9.4910e-06 - val_loss: 2.1617e-05\n",
      "Epoch 00357: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelType = \"1DConv\"\n",
    "trainingSetAdv, trainingSetLabels, testSet, validationSet = getReshapedAdversarialDataSet(dataSet, advDataSet, modelType)\n",
    "numOfLayers = 2\n",
    "filtersCountInFirstLayer = 48\n",
    "[model, validatoinLoss, numOfEpochs, history] = train1DConv(numOfLayers, trainingSetAdv, trainingSetLabels, validationSet, filtersCountInFirstLayer, filterSize = 4)\n",
    "model.save('Trained_Model/conv_adv.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function changed\n",
    "def trainLSTMAdv(numOfLayers, numOfNeurons, trainingSet, labels, validationSet, printSummary = 1, vrbs = 1, return_best = 1, learningRate = 0.001):\n",
    "        sequenceLen = dataSet.shape[1]\n",
    "        dimensionsCount = dataSet.shape[2]\n",
    "        \n",
    "        print('Training model.')\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(numOfNeurons, input_shape=(sequenceLen, dimensionsCount), return_sequences=True))\n",
    "        for j in range(0, numOfLayers - 1):\n",
    "            model.add(LSTM(numOfNeurons, return_sequences=True))\n",
    "\n",
    "        model.add(Dense(dimensionsCount))\n",
    "        model.add(Activation(\"linear\"))\n",
    "\n",
    "        if(printSummary == True):\n",
    "            model.summary()\n",
    "\n",
    "        adamOptimizer = Adam(learning_rate=learningRate) # , beta_1=0.9, beta_2=0.999, amsgrad=False            \n",
    "        model.compile(optimizer=adamOptimizer,\n",
    "            loss='mean_squared_error',\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "        callbacksArray = [es]\n",
    "        if(return_best):\n",
    "            mc = ModelCheckpoint('best_lstm.h5', monitor='val_loss', mode='min')\n",
    "            callbacksArray = [es, mc]\n",
    "\n",
    "        history=model.fit(trainingSet, labels,\n",
    "                            batch_size=5000,\n",
    "                            shuffle=True,\n",
    "                            epochs=10000, \n",
    "                            #validation_split=0.1,\n",
    "                            validation_data=(validationSet, validationSet),\n",
    "                            callbacks=callbacksArray,\n",
    "                            verbose = vrbs,\n",
    "                        )\n",
    "\n",
    "        if(return_best):\n",
    "            best_model = load_model('best_lstm.h5')\n",
    "        returnModel = model\n",
    "        if(return_best):\n",
    "            returnModel = best_model\n",
    "        return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 20)           2400      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200, 9)            189       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 200, 9)            0         \n",
      "=================================================================\n",
      "Total params: 2,589\n",
      "Trainable params: 2,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 11310 samples, validate on 1382 samples\n",
      "Epoch 1/10000\n",
      "11310/11310 [==============================] - 1s 120us/sample - loss: 0.0702 - val_loss: 0.0299\n",
      "Epoch 2/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0589 - val_loss: 0.0291\n",
      "Epoch 3/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0491 - val_loss: 0.0284\n",
      "Epoch 4/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0408 - val_loss: 0.0277\n",
      "Epoch 5/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0337 - val_loss: 0.0272\n",
      "Epoch 6/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 0.0277 - val_loss: 0.0267\n",
      "Epoch 7/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0227 - val_loss: 0.0262\n",
      "Epoch 8/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0189 - val_loss: 0.0258\n",
      "Epoch 9/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0162 - val_loss: 0.0253\n",
      "Epoch 10/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 0.0143 - val_loss: 0.0249\n",
      "Epoch 11/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0129 - val_loss: 0.0244\n",
      "Epoch 12/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0119 - val_loss: 0.0237\n",
      "Epoch 13/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0111 - val_loss: 0.0230\n",
      "Epoch 14/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0105 - val_loss: 0.0223\n",
      "Epoch 15/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0099 - val_loss: 0.0215\n",
      "Epoch 16/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 0.0093 - val_loss: 0.0207\n",
      "Epoch 17/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 0.0087 - val_loss: 0.0200\n",
      "Epoch 18/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0081 - val_loss: 0.0192\n",
      "Epoch 19/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0076 - val_loss: 0.0185\n",
      "Epoch 20/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0070 - val_loss: 0.0178\n",
      "Epoch 21/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 0.0065 - val_loss: 0.0171\n",
      "Epoch 22/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0060 - val_loss: 0.0165\n",
      "Epoch 23/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 0.0056 - val_loss: 0.0158\n",
      "Epoch 24/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0052 - val_loss: 0.0151\n",
      "Epoch 25/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0048 - val_loss: 0.0145\n",
      "Epoch 26/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0045 - val_loss: 0.0139\n",
      "Epoch 27/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 0.0042 - val_loss: 0.0133\n",
      "Epoch 28/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0039 - val_loss: 0.0127\n",
      "Epoch 29/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0037 - val_loss: 0.0121\n",
      "Epoch 30/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0035 - val_loss: 0.0116\n",
      "Epoch 31/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0034 - val_loss: 0.0111\n",
      "Epoch 32/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0032 - val_loss: 0.0107\n",
      "Epoch 33/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 0.0031 - val_loss: 0.0103\n",
      "Epoch 34/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0031 - val_loss: 0.0099\n",
      "Epoch 35/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0030 - val_loss: 0.0096\n",
      "Epoch 36/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0029 - val_loss: 0.0093\n",
      "Epoch 37/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0028 - val_loss: 0.0091\n",
      "Epoch 38/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0027 - val_loss: 0.0088\n",
      "Epoch 39/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 40/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 0.0026 - val_loss: 0.0084\n",
      "Epoch 41/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0025 - val_loss: 0.0081\n",
      "Epoch 42/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 43/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0024 - val_loss: 0.0077\n",
      "Epoch 44/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0024 - val_loss: 0.0075\n",
      "Epoch 45/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0023 - val_loss: 0.0073\n",
      "Epoch 46/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0023 - val_loss: 0.0072\n",
      "Epoch 47/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0022 - val_loss: 0.0070\n",
      "Epoch 48/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0022 - val_loss: 0.0068\n",
      "Epoch 49/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 50/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0021 - val_loss: 0.0065\n",
      "Epoch 51/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 52/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 0.0020 - val_loss: 0.0062\n",
      "Epoch 53/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 54/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 55/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 56/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 57/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 58/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 59/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 60/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 61/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 62/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 63/10000\n",
      "11310/11310 [==============================] - 0s 37us/sample - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 64/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 65/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 66/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 67/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 28us/sample - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 68/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 69/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 70/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 71/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 72/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 73/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 74/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 75/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 76/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 77/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 78/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 79/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 80/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 81/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 82/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 83/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 84/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 85/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 86/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 87/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 88/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 89/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 90/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 91/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 92/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 93/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 94/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 95/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 96/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 97/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 98/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 99/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 100/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 101/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 102/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 103/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 104/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 105/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 106/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 107/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 108/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 109/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 110/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 111/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 112/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 113/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 114/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 115/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 116/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 117/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 118/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 119/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 120/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 121/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 122/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 123/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.9943e-04 - val_loss: 0.0017\n",
      "Epoch 124/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.9260e-04 - val_loss: 0.0017\n",
      "Epoch 125/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.8582e-04 - val_loss: 0.0017\n",
      "Epoch 126/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.7914e-04 - val_loss: 0.0016\n",
      "Epoch 127/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.7258e-04 - val_loss: 0.0016\n",
      "Epoch 128/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.6608e-04 - val_loss: 0.0016\n",
      "Epoch 129/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 9.5968e-04 - val_loss: 0.0016\n",
      "Epoch 130/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.5337e-04 - val_loss: 0.0015\n",
      "Epoch 131/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.4716e-04 - val_loss: 0.0015\n",
      "Epoch 132/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 9.4106e-04 - val_loss: 0.0015\n",
      "Epoch 133/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.3500e-04 - val_loss: 0.0015\n",
      "Epoch 134/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 9.2905e-04 - val_loss: 0.0015\n",
      "Epoch 135/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.2321e-04 - val_loss: 0.0014\n",
      "Epoch 136/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 9.1743e-04 - val_loss: 0.0014\n",
      "Epoch 137/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.1171e-04 - val_loss: 0.0014\n",
      "Epoch 138/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 9.0608e-04 - val_loss: 0.0014\n",
      "Epoch 139/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.0051e-04 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.9509e-04 - val_loss: 0.0013\n",
      "Epoch 141/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.8966e-04 - val_loss: 0.0013\n",
      "Epoch 142/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 8.8437e-04 - val_loss: 0.0013\n",
      "Epoch 143/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.7914e-04 - val_loss: 0.0013\n",
      "Epoch 144/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.7398e-04 - val_loss: 0.0013\n",
      "Epoch 145/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.6890e-04 - val_loss: 0.0012\n",
      "Epoch 146/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 8.6392e-04 - val_loss: 0.0012\n",
      "Epoch 147/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 8.5901e-04 - val_loss: 0.0012\n",
      "Epoch 148/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.5412e-04 - val_loss: 0.0012\n",
      "Epoch 149/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.4935e-04 - val_loss: 0.0012\n",
      "Epoch 150/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.4463e-04 - val_loss: 0.0012\n",
      "Epoch 151/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 8.3997e-04 - val_loss: 0.0012\n",
      "Epoch 152/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.3536e-04 - val_loss: 0.0011\n",
      "Epoch 153/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 8.3084e-04 - val_loss: 0.0011\n",
      "Epoch 154/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.2640e-04 - val_loss: 0.0011\n",
      "Epoch 155/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.2201e-04 - val_loss: 0.0011\n",
      "Epoch 156/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.1767e-04 - val_loss: 0.0011\n",
      "Epoch 157/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.1340e-04 - val_loss: 0.0011\n",
      "Epoch 158/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.0919e-04 - val_loss: 0.0011\n",
      "Epoch 159/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 8.0504e-04 - val_loss: 0.0010\n",
      "Epoch 160/10000\n",
      "11310/11310 [==============================] - 0s 38us/sample - loss: 8.0095e-04 - val_loss: 0.0010\n",
      "Epoch 161/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.9692e-04 - val_loss: 0.0010\n",
      "Epoch 162/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.9295e-04 - val_loss: 0.0010\n",
      "Epoch 163/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.8900e-04 - val_loss: 0.0010\n",
      "Epoch 164/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.8517e-04 - val_loss: 9.9461e-04\n",
      "Epoch 165/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.8131e-04 - val_loss: 9.8436e-04\n",
      "Epoch 166/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.7752e-04 - val_loss: 9.7467e-04\n",
      "Epoch 167/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.7379e-04 - val_loss: 9.6542e-04\n",
      "Epoch 168/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.7009e-04 - val_loss: 9.5635e-04\n",
      "Epoch 169/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.6648e-04 - val_loss: 9.4744e-04\n",
      "Epoch 170/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.6287e-04 - val_loss: 9.3798e-04\n",
      "Epoch 171/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.5935e-04 - val_loss: 9.2861e-04\n",
      "Epoch 172/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.5585e-04 - val_loss: 9.1976e-04\n",
      "Epoch 173/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.5243e-04 - val_loss: 9.1161e-04\n",
      "Epoch 174/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 7.4903e-04 - val_loss: 9.0323e-04\n",
      "Epoch 175/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.4569e-04 - val_loss: 8.9575e-04\n",
      "Epoch 176/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.4240e-04 - val_loss: 8.8899e-04\n",
      "Epoch 177/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.3915e-04 - val_loss: 8.8238e-04\n",
      "Epoch 178/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.3596e-04 - val_loss: 8.7563e-04\n",
      "Epoch 179/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.3279e-04 - val_loss: 8.6879e-04\n",
      "Epoch 180/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.2967e-04 - val_loss: 8.6236e-04\n",
      "Epoch 181/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.2657e-04 - val_loss: 8.5596e-04\n",
      "Epoch 182/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2351e-04 - val_loss: 8.5008e-04\n",
      "Epoch 183/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2049e-04 - val_loss: 8.4384e-04\n",
      "Epoch 184/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.1749e-04 - val_loss: 8.3829e-04\n",
      "Epoch 185/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.1455e-04 - val_loss: 8.3295e-04\n",
      "Epoch 186/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.1164e-04 - val_loss: 8.2741e-04\n",
      "Epoch 187/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.0875e-04 - val_loss: 8.2169e-04\n",
      "Epoch 188/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.0590e-04 - val_loss: 8.1700e-04\n",
      "Epoch 189/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 7.0309e-04 - val_loss: 8.1260e-04\n",
      "Epoch 190/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.0030e-04 - val_loss: 8.0867e-04\n",
      "Epoch 191/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.9754e-04 - val_loss: 8.0531e-04\n",
      "Epoch 192/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.9483e-04 - val_loss: 8.0186e-04\n",
      "Epoch 193/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.9213e-04 - val_loss: 7.9837e-04\n",
      "Epoch 194/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 6.8947e-04 - val_loss: 7.9449e-04\n",
      "Epoch 195/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.8683e-04 - val_loss: 7.9025e-04\n",
      "Epoch 196/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 6.8425e-04 - val_loss: 7.8610e-04\n",
      "Epoch 197/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.8165e-04 - val_loss: 7.8150e-04\n",
      "Epoch 198/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.7910e-04 - val_loss: 7.7762e-04\n",
      "Epoch 199/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.7658e-04 - val_loss: 7.7439e-04\n",
      "Epoch 200/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.7408e-04 - val_loss: 7.7098e-04\n",
      "Epoch 201/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.7161e-04 - val_loss: 7.6780e-04\n",
      "Epoch 202/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.6915e-04 - val_loss: 7.6534e-04\n",
      "Epoch 203/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.6670e-04 - val_loss: 7.6203e-04\n",
      "Epoch 204/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.6429e-04 - val_loss: 7.5921e-04\n",
      "Epoch 205/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.6190e-04 - val_loss: 7.5583e-04\n",
      "Epoch 206/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.5952e-04 - val_loss: 7.5226e-04\n",
      "Epoch 207/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.5717e-04 - val_loss: 7.4921e-04\n",
      "Epoch 208/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.5485e-04 - val_loss: 7.4634e-04\n",
      "Epoch 209/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.5256e-04 - val_loss: 7.4391e-04\n",
      "Epoch 210/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.5026e-04 - val_loss: 7.4174e-04\n",
      "Epoch 211/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.4800e-04 - val_loss: 7.3946e-04\n",
      "Epoch 212/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 6.4577e-04 - val_loss: 7.3787e-04\n",
      "Epoch 213/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4354e-04 - val_loss: 7.3602e-04\n",
      "Epoch 214/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 6.4135e-04 - val_loss: 7.3445e-04\n",
      "Epoch 215/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.3918e-04 - val_loss: 7.3289e-04\n",
      "Epoch 216/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.3702e-04 - val_loss: 7.3047e-04\n",
      "Epoch 217/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.3487e-04 - val_loss: 7.2839e-04\n",
      "Epoch 218/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.3274e-04 - val_loss: 7.2634e-04\n",
      "Epoch 219/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 6.3063e-04 - val_loss: 7.2450e-04\n",
      "Epoch 220/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.2851e-04 - val_loss: 7.2280e-04\n",
      "Epoch 221/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.2642e-04 - val_loss: 7.2111e-04\n",
      "Epoch 222/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.2436e-04 - val_loss: 7.1968e-04\n",
      "Epoch 223/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.2229e-04 - val_loss: 7.1832e-04\n",
      "Epoch 224/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.2025e-04 - val_loss: 7.1679e-04\n",
      "Epoch 225/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.1821e-04 - val_loss: 7.1592e-04\n",
      "Epoch 226/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.1619e-04 - val_loss: 7.1481e-04\n",
      "Epoch 227/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.1417e-04 - val_loss: 7.1340e-04\n",
      "Epoch 228/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.1217e-04 - val_loss: 7.1260e-04\n",
      "Epoch 229/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 6.1021e-04 - val_loss: 7.1183e-04\n",
      "Epoch 230/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.0825e-04 - val_loss: 7.1040e-04\n",
      "Epoch 231/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.0629e-04 - val_loss: 7.0901e-04\n",
      "Epoch 232/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 6.0434e-04 - val_loss: 7.0781e-04\n",
      "Epoch 233/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.0240e-04 - val_loss: 7.0705e-04\n",
      "Epoch 234/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 6.0049e-04 - val_loss: 7.0593e-04\n",
      "Epoch 235/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.9858e-04 - val_loss: 7.0406e-04\n",
      "Epoch 236/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.9668e-04 - val_loss: 7.0247e-04\n",
      "Epoch 237/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.9483e-04 - val_loss: 7.0125e-04\n",
      "Epoch 238/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.9294e-04 - val_loss: 6.9955e-04\n",
      "Epoch 239/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.9109e-04 - val_loss: 6.9852e-04\n",
      "Epoch 240/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.8924e-04 - val_loss: 6.9723e-04\n",
      "Epoch 241/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.8742e-04 - val_loss: 6.9619e-04\n",
      "Epoch 242/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.8559e-04 - val_loss: 6.9523e-04\n",
      "Epoch 243/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.8379e-04 - val_loss: 6.9482e-04\n",
      "Epoch 244/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.8198e-04 - val_loss: 6.9387e-04\n",
      "Epoch 245/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 5.8021e-04 - val_loss: 6.9248e-04\n",
      "Epoch 246/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.7843e-04 - val_loss: 6.9062e-04\n",
      "Epoch 247/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.7667e-04 - val_loss: 6.8819e-04\n",
      "Epoch 248/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.7491e-04 - val_loss: 6.8582e-04\n",
      "Epoch 249/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.7318e-04 - val_loss: 6.8378e-04\n",
      "Epoch 250/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.7148e-04 - val_loss: 6.8201e-04\n",
      "Epoch 251/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.6975e-04 - val_loss: 6.8064e-04\n",
      "Epoch 252/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.6803e-04 - val_loss: 6.7984e-04\n",
      "Epoch 253/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.6634e-04 - val_loss: 6.7861e-04\n",
      "Epoch 254/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.6463e-04 - val_loss: 6.7785e-04\n",
      "Epoch 255/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.6294e-04 - val_loss: 6.7727e-04\n",
      "Epoch 256/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 5.6129e-04 - val_loss: 6.7649e-04\n",
      "Epoch 257/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 5.5960e-04 - val_loss: 6.7494e-04\n",
      "Epoch 258/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.5794e-04 - val_loss: 6.7345e-04\n",
      "Epoch 259/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 5.5628e-04 - val_loss: 6.7151e-04\n",
      "Epoch 260/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.5463e-04 - val_loss: 6.7048e-04\n",
      "Epoch 261/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.5299e-04 - val_loss: 6.6931e-04\n",
      "Epoch 262/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.5137e-04 - val_loss: 6.6840e-04\n",
      "Epoch 263/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.4979e-04 - val_loss: 6.6773e-04\n",
      "Epoch 264/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.4815e-04 - val_loss: 6.6650e-04\n",
      "Epoch 265/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.4658e-04 - val_loss: 6.6533e-04\n",
      "Epoch 266/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.4497e-04 - val_loss: 6.6372e-04\n",
      "Epoch 267/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.4339e-04 - val_loss: 6.6271e-04\n",
      "Epoch 268/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 5.4181e-04 - val_loss: 6.6150e-04\n",
      "Epoch 269/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.4024e-04 - val_loss: 6.6120e-04\n",
      "Epoch 270/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.3871e-04 - val_loss: 6.6143e-04\n",
      "Epoch 271/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 5.3714e-04 - val_loss: 6.6027e-04\n",
      "Epoch 272/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 5.3558e-04 - val_loss: 6.5957e-04\n",
      "Epoch 273/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.3405e-04 - val_loss: 6.5875e-04\n",
      "Epoch 274/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.3251e-04 - val_loss: 6.5816e-04\n",
      "Epoch 275/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.3100e-04 - val_loss: 6.5854e-04\n",
      "Epoch 276/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.2948e-04 - val_loss: 6.5941e-04\n",
      "Epoch 277/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.2798e-04 - val_loss: 6.5955e-04\n",
      "Epoch 278/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.2646e-04 - val_loss: 6.5974e-04\n",
      "Epoch 279/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.2495e-04 - val_loss: 6.5953e-04\n",
      "Epoch 280/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.2345e-04 - val_loss: 6.5867e-04\n",
      "Epoch 281/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.2201e-04 - val_loss: 6.5825e-04\n",
      "Epoch 282/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 5.2048e-04 - val_loss: 6.5705e-04\n",
      "Epoch 283/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 5.1901e-04 - val_loss: 6.5660e-04\n",
      "Epoch 284/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 5.1756e-04 - val_loss: 6.5626e-04\n",
      "Epoch 285/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.1606e-04 - val_loss: 6.5530e-04\n",
      "Epoch 286/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.1461e-04 - val_loss: 6.5430e-04\n",
      "Epoch 287/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 5.1315e-04 - val_loss: 6.5261e-04\n",
      "Epoch 288/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 5.1170e-04 - val_loss: 6.5061e-04\n",
      "Epoch 289/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.1025e-04 - val_loss: 6.4955e-04\n",
      "Epoch 290/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.0880e-04 - val_loss: 6.4891e-04\n",
      "Epoch 291/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.0738e-04 - val_loss: 6.4830e-04\n",
      "Epoch 292/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 5.0594e-04 - val_loss: 6.4748e-04\n",
      "Epoch 293/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.0455e-04 - val_loss: 6.4686e-04\n",
      "Epoch 294/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.0313e-04 - val_loss: 6.4612e-04\n",
      "Epoch 295/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 5.0170e-04 - val_loss: 6.4575e-04\n",
      "Epoch 296/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 5.0029e-04 - val_loss: 6.4531e-04\n",
      "Epoch 297/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.9891e-04 - val_loss: 6.4478e-04\n",
      "Epoch 298/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.9750e-04 - val_loss: 6.4529e-04\n",
      "Epoch 299/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.9610e-04 - val_loss: 6.4485e-04\n",
      "Epoch 300/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.9471e-04 - val_loss: 6.4477e-04\n",
      "Epoch 301/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.9335e-04 - val_loss: 6.4348e-04\n",
      "Epoch 302/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.9197e-04 - val_loss: 6.4091e-04\n",
      "Epoch 303/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.9062e-04 - val_loss: 6.3934e-04\n",
      "Epoch 304/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.8928e-04 - val_loss: 6.3854e-04\n",
      "Epoch 305/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.8789e-04 - val_loss: 6.3804e-04\n",
      "Epoch 306/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 4.8655e-04 - val_loss: 6.3776e-04\n",
      "Epoch 307/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 4.8519e-04 - val_loss: 6.3624e-04\n",
      "Epoch 308/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.8385e-04 - val_loss: 6.3559e-04\n",
      "Epoch 309/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.8252e-04 - val_loss: 6.3503e-04\n",
      "Epoch 310/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.8118e-04 - val_loss: 6.3430e-04\n",
      "Epoch 311/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.7984e-04 - val_loss: 6.3376e-04\n",
      "Epoch 312/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 4.7856e-04 - val_loss: 6.3332e-04\n",
      "Epoch 313/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.7722e-04 - val_loss: 6.3290e-04\n",
      "Epoch 314/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.7590e-04 - val_loss: 6.3290e-04\n",
      "Epoch 315/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.7458e-04 - val_loss: 6.3228e-04\n",
      "Epoch 316/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.7330e-04 - val_loss: 6.3192e-04\n",
      "Epoch 317/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.7201e-04 - val_loss: 6.3161e-04\n",
      "Epoch 318/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 4.7071e-04 - val_loss: 6.3103e-04\n",
      "Epoch 319/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.6942e-04 - val_loss: 6.2962e-04\n",
      "Epoch 320/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.6812e-04 - val_loss: 6.2822e-04\n",
      "Epoch 321/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.6685e-04 - val_loss: 6.2698e-04\n",
      "Epoch 322/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.6557e-04 - val_loss: 6.2572e-04\n",
      "Epoch 323/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.6429e-04 - val_loss: 6.2436e-04\n",
      "Epoch 324/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.6303e-04 - val_loss: 6.2370e-04\n",
      "Epoch 325/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.6177e-04 - val_loss: 6.2367e-04\n",
      "Epoch 326/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.6051e-04 - val_loss: 6.2307e-04\n",
      "Epoch 327/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.5927e-04 - val_loss: 6.2209e-04\n",
      "Epoch 328/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 4.5799e-04 - val_loss: 6.2182e-04\n",
      "Epoch 329/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.5674e-04 - val_loss: 6.2148e-04\n",
      "Epoch 330/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.5549e-04 - val_loss: 6.2138e-04\n",
      "Epoch 331/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 4.5424e-04 - val_loss: 6.2111e-04\n",
      "Epoch 332/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.5300e-04 - val_loss: 6.2101e-04\n",
      "Epoch 333/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.5177e-04 - val_loss: 6.2072e-04\n",
      "Epoch 334/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.5052e-04 - val_loss: 6.2049e-04\n",
      "Epoch 335/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.4930e-04 - val_loss: 6.2060e-04\n",
      "Epoch 336/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 4.4806e-04 - val_loss: 6.2038e-04\n",
      "Epoch 337/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.4684e-04 - val_loss: 6.2014e-04\n",
      "Epoch 338/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 4.4561e-04 - val_loss: 6.1929e-04\n",
      "Epoch 339/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 4.4439e-04 - val_loss: 6.1865e-04\n",
      "Epoch 340/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 4.4320e-04 - val_loss: 6.1769e-04\n",
      "Epoch 341/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 4.4194e-04 - val_loss: 6.1695e-04\n",
      "Epoch 342/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.4074e-04 - val_loss: 6.1688e-04\n",
      "Epoch 343/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.3954e-04 - val_loss: 6.1607e-04\n",
      "Epoch 344/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.3834e-04 - val_loss: 6.1558e-04\n",
      "Epoch 345/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.3711e-04 - val_loss: 6.1540e-04\n",
      "Epoch 346/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 4.3593e-04 - val_loss: 6.1485e-04\n",
      "Epoch 347/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.3472e-04 - val_loss: 6.1480e-04\n",
      "Epoch 348/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.3353e-04 - val_loss: 6.1385e-04\n",
      "Epoch 349/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.3233e-04 - val_loss: 6.1287e-04\n",
      "Epoch 350/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 4.3118e-04 - val_loss: 6.1193e-04\n",
      "Epoch 351/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.2998e-04 - val_loss: 6.1041e-04\n",
      "Epoch 352/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.2882e-04 - val_loss: 6.0951e-04\n",
      "Epoch 353/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 4.2764e-04 - val_loss: 6.0750e-04\n",
      "Epoch 354/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 4.2648e-04 - val_loss: 6.0603e-04\n",
      "Epoch 355/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.2531e-04 - val_loss: 6.0380e-04\n",
      "Epoch 356/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 4.2417e-04 - val_loss: 6.0349e-04\n",
      "Epoch 357/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 4.2301e-04 - val_loss: 6.0326e-04\n",
      "Epoch 358/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 4.2184e-04 - val_loss: 6.0276e-04\n",
      "Epoch 359/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.2070e-04 - val_loss: 6.0288e-04\n",
      "Epoch 360/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.1956e-04 - val_loss: 6.0308e-04\n",
      "Epoch 361/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.1839e-04 - val_loss: 6.0227e-04\n",
      "Epoch 362/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.1727e-04 - val_loss: 6.0140e-04\n",
      "Epoch 363/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.1612e-04 - val_loss: 6.0110e-04\n",
      "Epoch 364/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.1499e-04 - val_loss: 6.0071e-04\n",
      "Epoch 365/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.1386e-04 - val_loss: 5.9958e-04\n",
      "Epoch 366/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 4.1272e-04 - val_loss: 5.9945e-04\n",
      "Epoch 367/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.1163e-04 - val_loss: 5.9930e-04\n",
      "Epoch 368/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.1047e-04 - val_loss: 5.9870e-04\n",
      "Epoch 369/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 4.0933e-04 - val_loss: 5.9848e-04\n",
      "Epoch 370/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 4.0819e-04 - val_loss: 5.9737e-04\n",
      "Epoch 371/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.0708e-04 - val_loss: 5.9634e-04\n",
      "Epoch 372/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.0595e-04 - val_loss: 5.9542e-04\n",
      "Epoch 373/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 4.0482e-04 - val_loss: 5.9506e-04\n",
      "Epoch 374/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 4.0375e-04 - val_loss: 5.9416e-04\n",
      "Epoch 375/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 4.0262e-04 - val_loss: 5.9327e-04\n",
      "Epoch 376/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.0153e-04 - val_loss: 5.9213e-04\n",
      "Epoch 377/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 4.0049e-04 - val_loss: 5.9144e-04\n",
      "Epoch 378/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.9932e-04 - val_loss: 5.8989e-04\n",
      "Epoch 379/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.9827e-04 - val_loss: 5.8893e-04\n",
      "Epoch 380/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.9719e-04 - val_loss: 5.8787e-04\n",
      "Epoch 381/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.9604e-04 - val_loss: 5.8773e-04\n",
      "Epoch 382/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.9496e-04 - val_loss: 5.8770e-04\n",
      "Epoch 383/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 3.9387e-04 - val_loss: 5.8761e-04\n",
      "Epoch 384/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.9276e-04 - val_loss: 5.8800e-04\n",
      "Epoch 385/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.9165e-04 - val_loss: 5.8838e-04\n",
      "Epoch 386/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.9055e-04 - val_loss: 5.8881e-04\n",
      "Epoch 387/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.8947e-04 - val_loss: 5.8849e-04\n",
      "Epoch 388/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.8838e-04 - val_loss: 5.8737e-04\n",
      "Epoch 389/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.8729e-04 - val_loss: 5.8655e-04\n",
      "Epoch 390/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 3.8623e-04 - val_loss: 5.8520e-04\n",
      "Epoch 391/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.8517e-04 - val_loss: 5.8422e-04\n",
      "Epoch 392/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.8409e-04 - val_loss: 5.8329e-04\n",
      "Epoch 393/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.8303e-04 - val_loss: 5.8281e-04\n",
      "Epoch 394/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.8194e-04 - val_loss: 5.8350e-04\n",
      "Epoch 395/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.8088e-04 - val_loss: 5.8369e-04\n",
      "Epoch 396/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.7984e-04 - val_loss: 5.8447e-04\n",
      "Epoch 397/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 3.7876e-04 - val_loss: 5.8498e-04\n",
      "Epoch 398/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.7771e-04 - val_loss: 5.8500e-04\n",
      "Epoch 399/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.7664e-04 - val_loss: 5.8422e-04\n",
      "Epoch 400/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.7561e-04 - val_loss: 5.8366e-04\n",
      "Epoch 401/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 3.7458e-04 - val_loss: 5.8285e-04\n",
      "Epoch 402/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.7354e-04 - val_loss: 5.8251e-04\n",
      "Epoch 403/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.7251e-04 - val_loss: 5.8203e-04\n",
      "Epoch 404/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.7145e-04 - val_loss: 5.8174e-04\n",
      "Epoch 405/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.7045e-04 - val_loss: 5.8140e-04\n",
      "Epoch 406/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.6941e-04 - val_loss: 5.8116e-04\n",
      "Epoch 407/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.6839e-04 - val_loss: 5.8132e-04\n",
      "Epoch 408/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 3.6733e-04 - val_loss: 5.8148e-04\n",
      "Epoch 409/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.6633e-04 - val_loss: 5.8141e-04\n",
      "Epoch 410/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.6529e-04 - val_loss: 5.8047e-04\n",
      "Epoch 411/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.6429e-04 - val_loss: 5.7928e-04\n",
      "Epoch 412/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.6327e-04 - val_loss: 5.7876e-04\n",
      "Epoch 413/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.6225e-04 - val_loss: 5.7782e-04\n",
      "Epoch 414/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.6128e-04 - val_loss: 5.7677e-04\n",
      "Epoch 415/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 3.6028e-04 - val_loss: 5.7603e-04\n",
      "Epoch 416/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.5927e-04 - val_loss: 5.7548e-04\n",
      "Epoch 417/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.5828e-04 - val_loss: 5.7534e-04\n",
      "Epoch 418/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.5730e-04 - val_loss: 5.7536e-04\n",
      "Epoch 419/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.5628e-04 - val_loss: 5.7519e-04\n",
      "Epoch 420/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.5528e-04 - val_loss: 5.7467e-04\n",
      "Epoch 421/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.5431e-04 - val_loss: 5.7400e-04\n",
      "Epoch 422/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.5333e-04 - val_loss: 5.7469e-04\n",
      "Epoch 423/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.5235e-04 - val_loss: 5.7489e-04\n",
      "Epoch 424/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.5137e-04 - val_loss: 5.7566e-04\n",
      "Epoch 425/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.5041e-04 - val_loss: 5.7620e-04\n",
      "Epoch 426/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.4942e-04 - val_loss: 5.7603e-04\n",
      "Epoch 427/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.4844e-04 - val_loss: 5.7550e-04\n",
      "Epoch 428/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 3.4748e-04 - val_loss: 5.7490e-04\n",
      "Epoch 429/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.4654e-04 - val_loss: 5.7479e-04\n",
      "Epoch 430/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 3.4556e-04 - val_loss: 5.7428e-04\n",
      "Epoch 431/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.4461e-04 - val_loss: 5.7340e-04\n",
      "Epoch 432/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.4368e-04 - val_loss: 5.7257e-04\n",
      "Epoch 433/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.4276e-04 - val_loss: 5.7224e-04\n",
      "Epoch 434/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.4180e-04 - val_loss: 5.7200e-04\n",
      "Epoch 435/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.4088e-04 - val_loss: 5.7126e-04\n",
      "Epoch 436/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.3994e-04 - val_loss: 5.7059e-04\n",
      "Epoch 437/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.3900e-04 - val_loss: 5.7001e-04\n",
      "Epoch 438/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.3808e-04 - val_loss: 5.6948e-04\n",
      "Epoch 439/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.3716e-04 - val_loss: 5.6883e-04\n",
      "Epoch 440/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.3624e-04 - val_loss: 5.6831e-04\n",
      "Epoch 441/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.3533e-04 - val_loss: 5.6785e-04\n",
      "Epoch 442/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 3.3442e-04 - val_loss: 5.6746e-04\n",
      "Epoch 443/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.3352e-04 - val_loss: 5.6695e-04\n",
      "Epoch 444/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 3.3263e-04 - val_loss: 5.6661e-04\n",
      "Epoch 445/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.3172e-04 - val_loss: 5.6586e-04\n",
      "Epoch 446/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.3083e-04 - val_loss: 5.6488e-04\n",
      "Epoch 447/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.2996e-04 - val_loss: 5.6452e-04\n",
      "Epoch 448/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.2904e-04 - val_loss: 5.6470e-04\n",
      "Epoch 449/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.2814e-04 - val_loss: 5.6432e-04\n",
      "Epoch 450/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.2726e-04 - val_loss: 5.6418e-04\n",
      "Epoch 451/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 3.2636e-04 - val_loss: 5.6373e-04\n",
      "Epoch 452/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.2547e-04 - val_loss: 5.6346e-04\n",
      "Epoch 453/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.2457e-04 - val_loss: 5.6295e-04\n",
      "Epoch 454/10000\n",
      "11310/11310 [==============================] - 0s 44us/sample - loss: 3.2371e-04 - val_loss: 5.6242e-04\n",
      "Epoch 455/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.2283e-04 - val_loss: 5.6205e-04\n",
      "Epoch 456/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.2195e-04 - val_loss: 5.6141e-04\n",
      "Epoch 457/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 3.2108e-04 - val_loss: 5.6107e-04\n",
      "Epoch 458/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.2022e-04 - val_loss: 5.6044e-04\n",
      "Epoch 459/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.1937e-04 - val_loss: 5.6005e-04\n",
      "Epoch 460/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.1849e-04 - val_loss: 5.6024e-04\n",
      "Epoch 461/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.1761e-04 - val_loss: 5.6063e-04\n",
      "Epoch 462/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.1676e-04 - val_loss: 5.6055e-04\n",
      "Epoch 463/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.1590e-04 - val_loss: 5.6004e-04\n",
      "Epoch 464/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.1503e-04 - val_loss: 5.5934e-04\n",
      "Epoch 465/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.1421e-04 - val_loss: 5.5893e-04\n",
      "Epoch 466/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.1337e-04 - val_loss: 5.5818e-04\n",
      "Epoch 467/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 3.1251e-04 - val_loss: 5.5724e-04\n",
      "Epoch 468/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.1166e-04 - val_loss: 5.5722e-04\n",
      "Epoch 469/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.1080e-04 - val_loss: 5.5757e-04\n",
      "Epoch 470/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.0996e-04 - val_loss: 5.5755e-04\n",
      "Epoch 471/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.0912e-04 - val_loss: 5.5749e-04\n",
      "Epoch 472/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 3.0826e-04 - val_loss: 5.5716e-04\n",
      "Epoch 473/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 3.0743e-04 - val_loss: 5.5689e-04\n",
      "Epoch 474/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.0662e-04 - val_loss: 5.5651e-04\n",
      "Epoch 475/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 3.0578e-04 - val_loss: 5.5546e-04\n",
      "Epoch 476/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 3.0498e-04 - val_loss: 5.5388e-04\n",
      "Epoch 477/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 3.0415e-04 - val_loss: 5.5304e-04\n",
      "Epoch 478/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 3.0341e-04 - val_loss: 5.5237e-04\n",
      "Epoch 479/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.0256e-04 - val_loss: 5.5222e-04\n",
      "Epoch 480/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 3.0171e-04 - val_loss: 5.5141e-04\n",
      "Epoch 481/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 20us/sample - loss: 3.0091e-04 - val_loss: 5.5135e-04\n",
      "Epoch 482/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 3.0012e-04 - val_loss: 5.5089e-04\n",
      "Epoch 483/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.9929e-04 - val_loss: 5.5063e-04\n",
      "Epoch 484/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 2.9849e-04 - val_loss: 5.5044e-04\n",
      "Epoch 485/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.9765e-04 - val_loss: 5.5097e-04\n",
      "Epoch 486/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.9686e-04 - val_loss: 5.5073e-04\n",
      "Epoch 487/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.9606e-04 - val_loss: 5.5034e-04\n",
      "Epoch 488/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 2.9530e-04 - val_loss: 5.4984e-04\n",
      "Epoch 489/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.9447e-04 - val_loss: 5.4975e-04\n",
      "Epoch 490/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.9367e-04 - val_loss: 5.4930e-04\n",
      "Epoch 491/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.9288e-04 - val_loss: 5.4918e-04\n",
      "Epoch 492/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.9208e-04 - val_loss: 5.4884e-04\n",
      "Epoch 493/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.9128e-04 - val_loss: 5.4873e-04\n",
      "Epoch 494/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.9050e-04 - val_loss: 5.4845e-04\n",
      "Epoch 495/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.8970e-04 - val_loss: 5.4784e-04\n",
      "Epoch 496/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.8892e-04 - val_loss: 5.4746e-04\n",
      "Epoch 497/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.8813e-04 - val_loss: 5.4684e-04\n",
      "Epoch 498/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.8737e-04 - val_loss: 5.4653e-04\n",
      "Epoch 499/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.8660e-04 - val_loss: 5.4642e-04\n",
      "Epoch 500/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.8582e-04 - val_loss: 5.4565e-04\n",
      "Epoch 501/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.8508e-04 - val_loss: 5.4477e-04\n",
      "Epoch 502/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.8433e-04 - val_loss: 5.4284e-04\n",
      "Epoch 503/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 2.8357e-04 - val_loss: 5.4108e-04\n",
      "Epoch 504/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.8282e-04 - val_loss: 5.3995e-04\n",
      "Epoch 505/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.8205e-04 - val_loss: 5.3943e-04\n",
      "Epoch 506/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.8127e-04 - val_loss: 5.3934e-04\n",
      "Epoch 507/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.8050e-04 - val_loss: 5.3924e-04\n",
      "Epoch 508/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 2.7975e-04 - val_loss: 5.3903e-04\n",
      "Epoch 509/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.7899e-04 - val_loss: 5.3876e-04\n",
      "Epoch 510/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.7825e-04 - val_loss: 5.3881e-04\n",
      "Epoch 511/10000\n",
      "11310/11310 [==============================] - 0s 33us/sample - loss: 2.7753e-04 - val_loss: 5.3910e-04\n",
      "Epoch 512/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.7679e-04 - val_loss: 5.3875e-04\n",
      "Epoch 513/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.7601e-04 - val_loss: 5.3773e-04\n",
      "Epoch 514/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.7529e-04 - val_loss: 5.3706e-04\n",
      "Epoch 515/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.7454e-04 - val_loss: 5.3680e-04\n",
      "Epoch 516/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 2.7381e-04 - val_loss: 5.3606e-04\n",
      "Epoch 517/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.7308e-04 - val_loss: 5.3527e-04\n",
      "Epoch 518/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 2.7236e-04 - val_loss: 5.3409e-04\n",
      "Epoch 519/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 2.7164e-04 - val_loss: 5.3334e-04\n",
      "Epoch 520/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 2.7090e-04 - val_loss: 5.3258e-04\n",
      "Epoch 521/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 2.7018e-04 - val_loss: 5.3204e-04\n",
      "Epoch 522/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.6945e-04 - val_loss: 5.3203e-04\n",
      "Epoch 523/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.6873e-04 - val_loss: 5.3164e-04\n",
      "Epoch 524/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.6800e-04 - val_loss: 5.3113e-04\n",
      "Epoch 525/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 2.6730e-04 - val_loss: 5.3038e-04\n",
      "Epoch 526/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 2.6658e-04 - val_loss: 5.3007e-04\n",
      "Epoch 527/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.6588e-04 - val_loss: 5.2962e-04\n",
      "Epoch 528/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.6519e-04 - val_loss: 5.3003e-04\n",
      "Epoch 529/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.6443e-04 - val_loss: 5.3003e-04\n",
      "Epoch 530/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.6372e-04 - val_loss: 5.3031e-04\n",
      "Epoch 531/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.6302e-04 - val_loss: 5.3040e-04\n",
      "Epoch 532/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.6229e-04 - val_loss: 5.2980e-04\n",
      "Epoch 533/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.6159e-04 - val_loss: 5.2923e-04\n",
      "Epoch 534/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 2.6087e-04 - val_loss: 5.2794e-04\n",
      "Epoch 535/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.6018e-04 - val_loss: 5.2687e-04\n",
      "Epoch 536/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.5948e-04 - val_loss: 5.2589e-04\n",
      "Epoch 537/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.5881e-04 - val_loss: 5.2493e-04\n",
      "Epoch 538/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.5815e-04 - val_loss: 5.2403e-04\n",
      "Epoch 539/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.5744e-04 - val_loss: 5.2326e-04\n",
      "Epoch 540/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.5675e-04 - val_loss: 5.2304e-04\n",
      "Epoch 541/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.5606e-04 - val_loss: 5.2360e-04\n",
      "Epoch 542/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 2.5539e-04 - val_loss: 5.2412e-04\n",
      "Epoch 543/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.5471e-04 - val_loss: 5.2420e-04\n",
      "Epoch 544/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.5402e-04 - val_loss: 5.2350e-04\n",
      "Epoch 545/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.5333e-04 - val_loss: 5.2302e-04\n",
      "Epoch 546/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 2.5267e-04 - val_loss: 5.2201e-04\n",
      "Epoch 547/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.5199e-04 - val_loss: 5.2197e-04\n",
      "Epoch 548/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.5130e-04 - val_loss: 5.2175e-04\n",
      "Epoch 549/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 22us/sample - loss: 2.5061e-04 - val_loss: 5.2173e-04\n",
      "Epoch 550/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 2.4994e-04 - val_loss: 5.2105e-04\n",
      "Epoch 551/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.4927e-04 - val_loss: 5.2048e-04\n",
      "Epoch 552/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 2.4860e-04 - val_loss: 5.2044e-04\n",
      "Epoch 553/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.4793e-04 - val_loss: 5.2052e-04\n",
      "Epoch 554/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.4727e-04 - val_loss: 5.2006e-04\n",
      "Epoch 555/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.4658e-04 - val_loss: 5.1918e-04\n",
      "Epoch 556/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.4594e-04 - val_loss: 5.1860e-04\n",
      "Epoch 557/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4527e-04 - val_loss: 5.1755e-04\n",
      "Epoch 558/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4462e-04 - val_loss: 5.1647e-04\n",
      "Epoch 559/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4397e-04 - val_loss: 5.1539e-04\n",
      "Epoch 560/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4332e-04 - val_loss: 5.1502e-04\n",
      "Epoch 561/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4267e-04 - val_loss: 5.1412e-04\n",
      "Epoch 562/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.4204e-04 - val_loss: 5.1320e-04\n",
      "Epoch 563/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.4142e-04 - val_loss: 5.1225e-04\n",
      "Epoch 564/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4074e-04 - val_loss: 5.1135e-04\n",
      "Epoch 565/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.4010e-04 - val_loss: 5.1020e-04\n",
      "Epoch 566/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.3946e-04 - val_loss: 5.0953e-04\n",
      "Epoch 567/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 2.3882e-04 - val_loss: 5.0832e-04\n",
      "Epoch 568/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.3820e-04 - val_loss: 5.0748e-04\n",
      "Epoch 569/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.3756e-04 - val_loss: 5.0717e-04\n",
      "Epoch 570/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.3693e-04 - val_loss: 5.0710e-04\n",
      "Epoch 571/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.3630e-04 - val_loss: 5.0651e-04\n",
      "Epoch 572/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.3566e-04 - val_loss: 5.0571e-04\n",
      "Epoch 573/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.3504e-04 - val_loss: 5.0525e-04\n",
      "Epoch 574/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.3442e-04 - val_loss: 5.0524e-04\n",
      "Epoch 575/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.3380e-04 - val_loss: 5.0563e-04\n",
      "Epoch 576/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.3317e-04 - val_loss: 5.0598e-04\n",
      "Epoch 577/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.3255e-04 - val_loss: 5.0623e-04\n",
      "Epoch 578/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 2.3192e-04 - val_loss: 5.0608e-04\n",
      "Epoch 579/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.3129e-04 - val_loss: 5.0471e-04\n",
      "Epoch 580/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 2.3067e-04 - val_loss: 5.0306e-04\n",
      "Epoch 581/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.3008e-04 - val_loss: 5.0126e-04\n",
      "Epoch 582/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.2946e-04 - val_loss: 5.0058e-04\n",
      "Epoch 583/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 2.2886e-04 - val_loss: 4.9993e-04\n",
      "Epoch 584/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.2826e-04 - val_loss: 4.9914e-04\n",
      "Epoch 585/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.2767e-04 - val_loss: 4.9872e-04\n",
      "Epoch 586/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 2.2705e-04 - val_loss: 4.9766e-04\n",
      "Epoch 587/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.2643e-04 - val_loss: 4.9687e-04\n",
      "Epoch 588/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.2581e-04 - val_loss: 4.9606e-04\n",
      "Epoch 589/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.2521e-04 - val_loss: 4.9541e-04\n",
      "Epoch 590/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.2461e-04 - val_loss: 4.9495e-04\n",
      "Epoch 591/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 2.2400e-04 - val_loss: 4.9510e-04\n",
      "Epoch 592/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.2339e-04 - val_loss: 4.9504e-04\n",
      "Epoch 593/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.2281e-04 - val_loss: 4.9479e-04\n",
      "Epoch 594/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 2.2220e-04 - val_loss: 4.9442e-04\n",
      "Epoch 595/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 2.2161e-04 - val_loss: 4.9394e-04\n",
      "Epoch 596/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.2099e-04 - val_loss: 4.9315e-04\n",
      "Epoch 597/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 2.2040e-04 - val_loss: 4.9265e-04\n",
      "Epoch 598/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.1979e-04 - val_loss: 4.9224e-04\n",
      "Epoch 599/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 2.1919e-04 - val_loss: 4.9145e-04\n",
      "Epoch 600/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.1859e-04 - val_loss: 4.9056e-04\n",
      "Epoch 601/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1801e-04 - val_loss: 4.9008e-04\n",
      "Epoch 602/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1742e-04 - val_loss: 4.8986e-04\n",
      "Epoch 603/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1683e-04 - val_loss: 4.8974e-04\n",
      "Epoch 604/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1625e-04 - val_loss: 4.8957e-04\n",
      "Epoch 605/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.1566e-04 - val_loss: 4.8922e-04\n",
      "Epoch 606/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1507e-04 - val_loss: 4.8864e-04\n",
      "Epoch 607/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.1450e-04 - val_loss: 4.8751e-04\n",
      "Epoch 608/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.1392e-04 - val_loss: 4.8604e-04\n",
      "Epoch 609/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1335e-04 - val_loss: 4.8499e-04\n",
      "Epoch 610/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1278e-04 - val_loss: 4.8393e-04\n",
      "Epoch 611/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.1222e-04 - val_loss: 4.8305e-04\n",
      "Epoch 612/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 2.1163e-04 - val_loss: 4.8291e-04\n",
      "Epoch 613/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.1105e-04 - val_loss: 4.8249e-04\n",
      "Epoch 614/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.1048e-04 - val_loss: 4.8186e-04\n",
      "Epoch 615/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 2.0992e-04 - val_loss: 4.8099e-04\n",
      "Epoch 616/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.0935e-04 - val_loss: 4.7969e-04\n",
      "Epoch 617/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0879e-04 - val_loss: 4.7870e-04\n",
      "Epoch 618/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.0824e-04 - val_loss: 4.7824e-04\n",
      "Epoch 619/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0767e-04 - val_loss: 4.7790e-04\n",
      "Epoch 620/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0712e-04 - val_loss: 4.7731e-04\n",
      "Epoch 621/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.0656e-04 - val_loss: 4.7652e-04\n",
      "Epoch 622/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 2.0599e-04 - val_loss: 4.7532e-04\n",
      "Epoch 623/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.0544e-04 - val_loss: 4.7466e-04\n",
      "Epoch 624/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0490e-04 - val_loss: 4.7343e-04\n",
      "Epoch 625/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.0435e-04 - val_loss: 4.7244e-04\n",
      "Epoch 626/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.0380e-04 - val_loss: 4.7183e-04\n",
      "Epoch 627/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0324e-04 - val_loss: 4.7118e-04\n",
      "Epoch 628/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 2.0271e-04 - val_loss: 4.7078e-04\n",
      "Epoch 629/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 2.0215e-04 - val_loss: 4.7065e-04\n",
      "Epoch 630/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0161e-04 - val_loss: 4.6960e-04\n",
      "Epoch 631/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 2.0107e-04 - val_loss: 4.6873e-04\n",
      "Epoch 632/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 2.0051e-04 - val_loss: 4.6755e-04\n",
      "Epoch 633/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.9998e-04 - val_loss: 4.6631e-04\n",
      "Epoch 634/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.9942e-04 - val_loss: 4.6530e-04\n",
      "Epoch 635/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 1.9889e-04 - val_loss: 4.6502e-04\n",
      "Epoch 636/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 1.9833e-04 - val_loss: 4.6540e-04\n",
      "Epoch 637/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.9779e-04 - val_loss: 4.6565e-04\n",
      "Epoch 638/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 1.9727e-04 - val_loss: 4.6519e-04\n",
      "Epoch 639/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 1.9674e-04 - val_loss: 4.6509e-04\n",
      "Epoch 640/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.9619e-04 - val_loss: 4.6472e-04\n",
      "Epoch 641/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 1.9566e-04 - val_loss: 4.6357e-04\n",
      "Epoch 642/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.9513e-04 - val_loss: 4.6280e-04\n",
      "Epoch 643/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.9457e-04 - val_loss: 4.6169e-04\n",
      "Epoch 644/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.9405e-04 - val_loss: 4.6063e-04\n",
      "Epoch 645/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.9351e-04 - val_loss: 4.5923e-04\n",
      "Epoch 646/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 1.9299e-04 - val_loss: 4.5798e-04\n",
      "Epoch 647/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.9246e-04 - val_loss: 4.5685e-04\n",
      "Epoch 648/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.9194e-04 - val_loss: 4.5547e-04\n",
      "Epoch 649/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.9144e-04 - val_loss: 4.5426e-04\n",
      "Epoch 650/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.9092e-04 - val_loss: 4.5357e-04\n",
      "Epoch 651/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.9038e-04 - val_loss: 4.5308e-04\n",
      "Epoch 652/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.8988e-04 - val_loss: 4.5215e-04\n",
      "Epoch 653/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.8933e-04 - val_loss: 4.5167e-04\n",
      "Epoch 654/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.8882e-04 - val_loss: 4.5096e-04\n",
      "Epoch 655/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8829e-04 - val_loss: 4.5033e-04\n",
      "Epoch 656/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.8777e-04 - val_loss: 4.4998e-04\n",
      "Epoch 657/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8725e-04 - val_loss: 4.4916e-04\n",
      "Epoch 658/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8674e-04 - val_loss: 4.4813e-04\n",
      "Epoch 659/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.8623e-04 - val_loss: 4.4695e-04\n",
      "Epoch 660/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.8571e-04 - val_loss: 4.4583e-04\n",
      "Epoch 661/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.8519e-04 - val_loss: 4.4448e-04\n",
      "Epoch 662/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.8469e-04 - val_loss: 4.4356e-04\n",
      "Epoch 663/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.8417e-04 - val_loss: 4.4249e-04\n",
      "Epoch 664/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.8367e-04 - val_loss: 4.4131e-04\n",
      "Epoch 665/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8317e-04 - val_loss: 4.3983e-04\n",
      "Epoch 666/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8266e-04 - val_loss: 4.3832e-04\n",
      "Epoch 667/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.8216e-04 - val_loss: 4.3703e-04\n",
      "Epoch 668/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.8166e-04 - val_loss: 4.3638e-04\n",
      "Epoch 669/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.8116e-04 - val_loss: 4.3537e-04\n",
      "Epoch 670/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.8066e-04 - val_loss: 4.3396e-04\n",
      "Epoch 671/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 1.8016e-04 - val_loss: 4.3294e-04\n",
      "Epoch 672/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.7966e-04 - val_loss: 4.3188e-04\n",
      "Epoch 673/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.7917e-04 - val_loss: 4.3094e-04\n",
      "Epoch 674/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.7866e-04 - val_loss: 4.3023e-04\n",
      "Epoch 675/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.7816e-04 - val_loss: 4.2910e-04\n",
      "Epoch 676/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.7767e-04 - val_loss: 4.2779e-04\n",
      "Epoch 677/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.7717e-04 - val_loss: 4.2695e-04\n",
      "Epoch 678/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.7669e-04 - val_loss: 4.2608e-04\n",
      "Epoch 679/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.7619e-04 - val_loss: 4.2505e-04\n",
      "Epoch 680/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.7570e-04 - val_loss: 4.2423e-04\n",
      "Epoch 681/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.7520e-04 - val_loss: 4.2350e-04\n",
      "Epoch 682/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.7472e-04 - val_loss: 4.2315e-04\n",
      "Epoch 683/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.7423e-04 - val_loss: 4.2296e-04\n",
      "Epoch 684/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.7374e-04 - val_loss: 4.2208e-04\n",
      "Epoch 685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.7326e-04 - val_loss: 4.2103e-04\n",
      "Epoch 686/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.7277e-04 - val_loss: 4.2054e-04\n",
      "Epoch 687/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.7228e-04 - val_loss: 4.1943e-04\n",
      "Epoch 688/10000\n",
      "11310/11310 [==============================] - 0s 31us/sample - loss: 1.7179e-04 - val_loss: 4.1884e-04\n",
      "Epoch 689/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.7132e-04 - val_loss: 4.1802e-04\n",
      "Epoch 690/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.7084e-04 - val_loss: 4.1717e-04\n",
      "Epoch 691/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.7035e-04 - val_loss: 4.1588e-04\n",
      "Epoch 692/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.6987e-04 - val_loss: 4.1491e-04\n",
      "Epoch 693/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.6938e-04 - val_loss: 4.1408e-04\n",
      "Epoch 694/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.6891e-04 - val_loss: 4.1288e-04\n",
      "Epoch 695/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 1.6843e-04 - val_loss: 4.1173e-04\n",
      "Epoch 696/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.6795e-04 - val_loss: 4.1016e-04\n",
      "Epoch 697/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 1.6747e-04 - val_loss: 4.0864e-04\n",
      "Epoch 698/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6700e-04 - val_loss: 4.0760e-04\n",
      "Epoch 699/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6652e-04 - val_loss: 4.0670e-04\n",
      "Epoch 700/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.6604e-04 - val_loss: 4.0613e-04\n",
      "Epoch 701/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6557e-04 - val_loss: 4.0494e-04\n",
      "Epoch 702/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6510e-04 - val_loss: 4.0314e-04\n",
      "Epoch 703/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.6463e-04 - val_loss: 4.0155e-04\n",
      "Epoch 704/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.6416e-04 - val_loss: 4.0032e-04\n",
      "Epoch 705/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6370e-04 - val_loss: 3.9946e-04\n",
      "Epoch 706/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6323e-04 - val_loss: 3.9819e-04\n",
      "Epoch 707/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.6277e-04 - val_loss: 3.9682e-04\n",
      "Epoch 708/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.6230e-04 - val_loss: 3.9547e-04\n",
      "Epoch 709/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6183e-04 - val_loss: 3.9468e-04\n",
      "Epoch 710/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.6136e-04 - val_loss: 3.9373e-04\n",
      "Epoch 711/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.6090e-04 - val_loss: 3.9283e-04\n",
      "Epoch 712/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.6043e-04 - val_loss: 3.9229e-04\n",
      "Epoch 713/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.5997e-04 - val_loss: 3.9194e-04\n",
      "Epoch 714/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.5950e-04 - val_loss: 3.9117e-04\n",
      "Epoch 715/10000\n",
      "11310/11310 [==============================] - 0s 25us/sample - loss: 1.5903e-04 - val_loss: 3.9016e-04\n",
      "Epoch 716/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.5857e-04 - val_loss: 3.8933e-04\n",
      "Epoch 717/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5812e-04 - val_loss: 3.8837e-04\n",
      "Epoch 718/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.5765e-04 - val_loss: 3.8697e-04\n",
      "Epoch 719/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.5719e-04 - val_loss: 3.8559e-04\n",
      "Epoch 720/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5672e-04 - val_loss: 3.8433e-04\n",
      "Epoch 721/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.5626e-04 - val_loss: 3.8350e-04\n",
      "Epoch 722/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.5580e-04 - val_loss: 3.8305e-04\n",
      "Epoch 723/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.5534e-04 - val_loss: 3.8226e-04\n",
      "Epoch 724/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 1.5487e-04 - val_loss: 3.8088e-04\n",
      "Epoch 725/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5441e-04 - val_loss: 3.7940e-04\n",
      "Epoch 726/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5396e-04 - val_loss: 3.7798e-04\n",
      "Epoch 727/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.5350e-04 - val_loss: 3.7643e-04\n",
      "Epoch 728/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 1.5304e-04 - val_loss: 3.7521e-04\n",
      "Epoch 729/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 1.5260e-04 - val_loss: 3.7423e-04\n",
      "Epoch 730/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5214e-04 - val_loss: 3.7260e-04\n",
      "Epoch 731/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.5169e-04 - val_loss: 3.7107e-04\n",
      "Epoch 732/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.5124e-04 - val_loss: 3.6989e-04\n",
      "Epoch 733/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.5079e-04 - val_loss: 3.6891e-04\n",
      "Epoch 734/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.5034e-04 - val_loss: 3.6776e-04\n",
      "Epoch 735/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4990e-04 - val_loss: 3.6671e-04\n",
      "Epoch 736/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4945e-04 - val_loss: 3.6587e-04\n",
      "Epoch 737/10000\n",
      "11310/11310 [==============================] - 0s 34us/sample - loss: 1.4900e-04 - val_loss: 3.6478e-04\n",
      "Epoch 738/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.4855e-04 - val_loss: 3.6328e-04\n",
      "Epoch 739/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.4812e-04 - val_loss: 3.6172e-04\n",
      "Epoch 740/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4767e-04 - val_loss: 3.6001e-04\n",
      "Epoch 741/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4723e-04 - val_loss: 3.5826e-04\n",
      "Epoch 742/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.4679e-04 - val_loss: 3.5698e-04\n",
      "Epoch 743/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4635e-04 - val_loss: 3.5584e-04\n",
      "Epoch 744/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 1.4591e-04 - val_loss: 3.5463e-04\n",
      "Epoch 745/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4548e-04 - val_loss: 3.5363e-04\n",
      "Epoch 746/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.4504e-04 - val_loss: 3.5271e-04\n",
      "Epoch 747/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 1.4460e-04 - val_loss: 3.5160e-04\n",
      "Epoch 748/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.4417e-04 - val_loss: 3.5048e-04\n",
      "Epoch 749/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4374e-04 - val_loss: 3.4891e-04\n",
      "Epoch 750/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.4330e-04 - val_loss: 3.4757e-04\n",
      "Epoch 751/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4287e-04 - val_loss: 3.4599e-04\n",
      "Epoch 752/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4244e-04 - val_loss: 3.4418e-04\n",
      "Epoch 753/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.4202e-04 - val_loss: 3.4209e-04\n",
      "Epoch 754/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.4159e-04 - val_loss: 3.4047e-04\n",
      "Epoch 755/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.4117e-04 - val_loss: 3.3903e-04\n",
      "Epoch 756/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.4075e-04 - val_loss: 3.3783e-04\n",
      "Epoch 757/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.4032e-04 - val_loss: 3.3663e-04\n",
      "Epoch 758/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.3990e-04 - val_loss: 3.3570e-04\n",
      "Epoch 759/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3947e-04 - val_loss: 3.3481e-04\n",
      "Epoch 760/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.3905e-04 - val_loss: 3.3373e-04\n",
      "Epoch 761/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3863e-04 - val_loss: 3.3281e-04\n",
      "Epoch 762/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.3821e-04 - val_loss: 3.3169e-04\n",
      "Epoch 763/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.3779e-04 - val_loss: 3.3050e-04\n",
      "Epoch 764/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.3737e-04 - val_loss: 3.2940e-04\n",
      "Epoch 765/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.3695e-04 - val_loss: 3.2824e-04\n",
      "Epoch 766/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3654e-04 - val_loss: 3.2725e-04\n",
      "Epoch 767/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 1.3612e-04 - val_loss: 3.2625e-04\n",
      "Epoch 768/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3570e-04 - val_loss: 3.2531e-04\n",
      "Epoch 769/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 1.3529e-04 - val_loss: 3.2435e-04\n",
      "Epoch 770/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3487e-04 - val_loss: 3.2335e-04\n",
      "Epoch 771/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.3445e-04 - val_loss: 3.2210e-04\n",
      "Epoch 772/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3404e-04 - val_loss: 3.2089e-04\n",
      "Epoch 773/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3363e-04 - val_loss: 3.1967e-04\n",
      "Epoch 774/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.3322e-04 - val_loss: 3.1811e-04\n",
      "Epoch 775/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3281e-04 - val_loss: 3.1692e-04\n",
      "Epoch 776/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.3240e-04 - val_loss: 3.1574e-04\n",
      "Epoch 777/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3199e-04 - val_loss: 3.1448e-04\n",
      "Epoch 778/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3158e-04 - val_loss: 3.1323e-04\n",
      "Epoch 779/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.3118e-04 - val_loss: 3.1203e-04\n",
      "Epoch 780/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.3077e-04 - val_loss: 3.1106e-04\n",
      "Epoch 781/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.3037e-04 - val_loss: 3.0985e-04\n",
      "Epoch 782/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2996e-04 - val_loss: 3.0878e-04\n",
      "Epoch 783/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 1.2956e-04 - val_loss: 3.0757e-04\n",
      "Epoch 784/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2917e-04 - val_loss: 3.0626e-04\n",
      "Epoch 785/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.2877e-04 - val_loss: 3.0490e-04\n",
      "Epoch 786/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.2838e-04 - val_loss: 3.0402e-04\n",
      "Epoch 787/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 1.2798e-04 - val_loss: 3.0297e-04\n",
      "Epoch 788/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2759e-04 - val_loss: 3.0193e-04\n",
      "Epoch 789/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2719e-04 - val_loss: 3.0091e-04\n",
      "Epoch 790/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2680e-04 - val_loss: 3.0009e-04\n",
      "Epoch 791/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.2640e-04 - val_loss: 2.9900e-04\n",
      "Epoch 792/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.2601e-04 - val_loss: 2.9782e-04\n",
      "Epoch 793/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2562e-04 - val_loss: 2.9643e-04\n",
      "Epoch 794/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.2523e-04 - val_loss: 2.9518e-04\n",
      "Epoch 795/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2484e-04 - val_loss: 2.9425e-04\n",
      "Epoch 796/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.2446e-04 - val_loss: 2.9335e-04\n",
      "Epoch 797/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2406e-04 - val_loss: 2.9236e-04\n",
      "Epoch 798/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 1.2369e-04 - val_loss: 2.9182e-04\n",
      "Epoch 799/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2330e-04 - val_loss: 2.9081e-04\n",
      "Epoch 800/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2291e-04 - val_loss: 2.8951e-04\n",
      "Epoch 801/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.2253e-04 - val_loss: 2.8816e-04\n",
      "Epoch 802/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2214e-04 - val_loss: 2.8713e-04\n",
      "Epoch 803/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2177e-04 - val_loss: 2.8580e-04\n",
      "Epoch 804/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.2139e-04 - val_loss: 2.8450e-04\n",
      "Epoch 805/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.2101e-04 - val_loss: 2.8347e-04\n",
      "Epoch 806/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2064e-04 - val_loss: 2.8255e-04\n",
      "Epoch 807/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.2026e-04 - val_loss: 2.8158e-04\n",
      "Epoch 808/10000\n",
      "11310/11310 [==============================] - 0s 35us/sample - loss: 1.1989e-04 - val_loss: 2.8080e-04\n",
      "Epoch 809/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1952e-04 - val_loss: 2.7969e-04\n",
      "Epoch 810/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1915e-04 - val_loss: 2.7855e-04\n",
      "Epoch 811/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.1878e-04 - val_loss: 2.7754e-04\n",
      "Epoch 812/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.1841e-04 - val_loss: 2.7669e-04\n",
      "Epoch 813/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.1805e-04 - val_loss: 2.7565e-04\n",
      "Epoch 814/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1769e-04 - val_loss: 2.7426e-04\n",
      "Epoch 815/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.1732e-04 - val_loss: 2.7320e-04\n",
      "Epoch 816/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1696e-04 - val_loss: 2.7238e-04\n",
      "Epoch 817/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.1660e-04 - val_loss: 2.7158e-04\n",
      "Epoch 818/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.1623e-04 - val_loss: 2.7064e-04\n",
      "Epoch 819/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1588e-04 - val_loss: 2.6977e-04\n",
      "Epoch 820/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1552e-04 - val_loss: 2.6873e-04\n",
      "Epoch 821/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.1516e-04 - val_loss: 2.6763e-04\n",
      "Epoch 822/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.1481e-04 - val_loss: 2.6656e-04\n",
      "Epoch 823/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.1445e-04 - val_loss: 2.6529e-04\n",
      "Epoch 824/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1410e-04 - val_loss: 2.6422e-04\n",
      "Epoch 825/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1375e-04 - val_loss: 2.6333e-04\n",
      "Epoch 826/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1340e-04 - val_loss: 2.6252e-04\n",
      "Epoch 827/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1305e-04 - val_loss: 2.6180e-04\n",
      "Epoch 828/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 1.1271e-04 - val_loss: 2.6075e-04\n",
      "Epoch 829/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 1.1237e-04 - val_loss: 2.5958e-04\n",
      "Epoch 830/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 1.1202e-04 - val_loss: 2.5842e-04\n",
      "Epoch 831/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.1168e-04 - val_loss: 2.5736e-04\n",
      "Epoch 832/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.1134e-04 - val_loss: 2.5663e-04\n",
      "Epoch 833/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.1101e-04 - val_loss: 2.5609e-04\n",
      "Epoch 834/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.1067e-04 - val_loss: 2.5563e-04\n",
      "Epoch 835/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.1033e-04 - val_loss: 2.5476e-04\n",
      "Epoch 836/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.0999e-04 - val_loss: 2.5408e-04\n",
      "Epoch 837/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 1.0966e-04 - val_loss: 2.5321e-04\n",
      "Epoch 838/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 1.0933e-04 - val_loss: 2.5213e-04\n",
      "Epoch 839/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.0900e-04 - val_loss: 2.5101e-04\n",
      "Epoch 840/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.0867e-04 - val_loss: 2.5009e-04\n",
      "Epoch 841/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0833e-04 - val_loss: 2.4932e-04\n",
      "Epoch 842/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0800e-04 - val_loss: 2.4875e-04\n",
      "Epoch 843/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.0767e-04 - val_loss: 2.4823e-04\n",
      "Epoch 844/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0734e-04 - val_loss: 2.4745e-04\n",
      "Epoch 845/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.0702e-04 - val_loss: 2.4681e-04\n",
      "Epoch 846/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.0669e-04 - val_loss: 2.4587e-04\n",
      "Epoch 847/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0637e-04 - val_loss: 2.4484e-04\n",
      "Epoch 848/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.0605e-04 - val_loss: 2.4389e-04\n",
      "Epoch 849/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.0572e-04 - val_loss: 2.4299e-04\n",
      "Epoch 850/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.0541e-04 - val_loss: 2.4238e-04\n",
      "Epoch 851/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0510e-04 - val_loss: 2.4190e-04\n",
      "Epoch 852/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0478e-04 - val_loss: 2.4131e-04\n",
      "Epoch 853/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 1.0446e-04 - val_loss: 2.4067e-04\n",
      "Epoch 854/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0415e-04 - val_loss: 2.3984e-04\n",
      "Epoch 855/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 1.0383e-04 - val_loss: 2.3927e-04\n",
      "Epoch 856/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0353e-04 - val_loss: 2.3873e-04\n",
      "Epoch 857/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0322e-04 - val_loss: 2.3773e-04\n",
      "Epoch 858/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0291e-04 - val_loss: 2.3697e-04\n",
      "Epoch 859/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 1.0260e-04 - val_loss: 2.3612e-04\n",
      "Epoch 860/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 1.0229e-04 - val_loss: 2.3528e-04\n",
      "Epoch 861/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0198e-04 - val_loss: 2.3468e-04\n",
      "Epoch 862/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0167e-04 - val_loss: 2.3437e-04\n",
      "Epoch 863/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 1.0137e-04 - val_loss: 2.3416e-04\n",
      "Epoch 864/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 1.0107e-04 - val_loss: 2.3359e-04\n",
      "Epoch 865/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 1.0076e-04 - val_loss: 2.3263e-04\n",
      "Epoch 866/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0046e-04 - val_loss: 2.3186e-04\n",
      "Epoch 867/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 1.0016e-04 - val_loss: 2.3107e-04\n",
      "Epoch 868/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.9855e-05 - val_loss: 2.3026e-04\n",
      "Epoch 869/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.9557e-05 - val_loss: 2.2949e-04\n",
      "Epoch 870/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.9263e-05 - val_loss: 2.2881e-04\n",
      "Epoch 871/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.8968e-05 - val_loss: 2.2807e-04\n",
      "Epoch 872/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 9.8678e-05 - val_loss: 2.2737e-04\n",
      "Epoch 873/10000\n",
      "11310/11310 [==============================] - 0s 36us/sample - loss: 9.8395e-05 - val_loss: 2.2685e-04\n",
      "Epoch 874/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.8102e-05 - val_loss: 2.2619e-04\n",
      "Epoch 875/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 9.7814e-05 - val_loss: 2.2547e-04\n",
      "Epoch 876/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 9.7527e-05 - val_loss: 2.2496e-04\n",
      "Epoch 877/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.7247e-05 - val_loss: 2.2448e-04\n",
      "Epoch 878/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.6960e-05 - val_loss: 2.2382e-04\n",
      "Epoch 879/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 9.6683e-05 - val_loss: 2.2338e-04\n",
      "Epoch 880/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.6400e-05 - val_loss: 2.2293e-04\n",
      "Epoch 881/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.6125e-05 - val_loss: 2.2225e-04\n",
      "Epoch 882/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.5845e-05 - val_loss: 2.2156e-04\n",
      "Epoch 883/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 9.5576e-05 - val_loss: 2.2082e-04\n",
      "Epoch 884/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 9.5293e-05 - val_loss: 2.2008e-04\n",
      "Epoch 885/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.5015e-05 - val_loss: 2.1993e-04\n",
      "Epoch 886/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.4746e-05 - val_loss: 2.1945e-04\n",
      "Epoch 887/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.4470e-05 - val_loss: 2.1865e-04\n",
      "Epoch 888/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.4202e-05 - val_loss: 2.1784e-04\n",
      "Epoch 889/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.3935e-05 - val_loss: 2.1716e-04\n",
      "Epoch 890/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.3668e-05 - val_loss: 2.1684e-04\n",
      "Epoch 891/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 9.3406e-05 - val_loss: 2.1639e-04\n",
      "Epoch 892/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.3143e-05 - val_loss: 2.1571e-04\n",
      "Epoch 893/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.2881e-05 - val_loss: 2.1505e-04\n",
      "Epoch 894/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 9.2620e-05 - val_loss: 2.1457e-04\n",
      "Epoch 895/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.2365e-05 - val_loss: 2.1420e-04\n",
      "Epoch 896/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 9.2113e-05 - val_loss: 2.1320e-04\n",
      "Epoch 897/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.1887e-05 - val_loss: 2.1187e-04\n",
      "Epoch 898/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.1665e-05 - val_loss: 2.1140e-04\n",
      "Epoch 899/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 9.1402e-05 - val_loss: 2.1125e-04\n",
      "Epoch 900/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 9.1128e-05 - val_loss: 2.1185e-04\n",
      "Epoch 901/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 9.0869e-05 - val_loss: 2.1221e-04\n",
      "Epoch 902/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 9.0767e-05 - val_loss: 2.0891e-04\n",
      "Epoch 903/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 9.0528e-05 - val_loss: 2.0805e-04\n",
      "Epoch 904/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 9.0353e-05 - val_loss: 2.0759e-04\n",
      "Epoch 905/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 9.0047e-05 - val_loss: 2.0776e-04\n",
      "Epoch 906/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.9741e-05 - val_loss: 2.0853e-04\n",
      "Epoch 907/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 8.9471e-05 - val_loss: 2.0899e-04\n",
      "Epoch 908/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.9224e-05 - val_loss: 2.0837e-04\n",
      "Epoch 909/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.8956e-05 - val_loss: 2.0703e-04\n",
      "Epoch 910/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.8703e-05 - val_loss: 2.0624e-04\n",
      "Epoch 911/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.8468e-05 - val_loss: 2.0587e-04\n",
      "Epoch 912/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.8356e-05 - val_loss: 2.0641e-04\n",
      "Epoch 913/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.9169e-05 - val_loss: 2.0817e-04\n",
      "Epoch 914/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.9614e-05 - val_loss: 2.0557e-04\n",
      "Epoch 915/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.9425e-05 - val_loss: 2.0290e-04\n",
      "Epoch 916/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.8836e-05 - val_loss: 2.0181e-04\n",
      "Epoch 917/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 8.8308e-05 - val_loss: 2.0239e-04\n",
      "Epoch 918/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.7850e-05 - val_loss: 2.0343e-04\n",
      "Epoch 919/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.7450e-05 - val_loss: 2.0352e-04\n",
      "Epoch 920/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.7057e-05 - val_loss: 2.0269e-04\n",
      "Epoch 921/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.6697e-05 - val_loss: 2.0132e-04\n",
      "Epoch 922/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.6376e-05 - val_loss: 2.0036e-04\n",
      "Epoch 923/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.6064e-05 - val_loss: 1.9995e-04\n",
      "Epoch 924/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.5764e-05 - val_loss: 1.9998e-04\n",
      "Epoch 925/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.5492e-05 - val_loss: 2.0011e-04\n",
      "Epoch 926/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.5229e-05 - val_loss: 2.0013e-04\n",
      "Epoch 927/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.4984e-05 - val_loss: 2.0004e-04\n",
      "Epoch 928/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.4758e-05 - val_loss: 1.9925e-04\n",
      "Epoch 929/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.4532e-05 - val_loss: 1.9880e-04\n",
      "Epoch 930/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.4308e-05 - val_loss: 1.9872e-04\n",
      "Epoch 931/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.4276e-05 - val_loss: 1.9745e-04\n",
      "Epoch 932/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.4178e-05 - val_loss: 1.9754e-04\n",
      "Epoch 933/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.4372e-05 - val_loss: 1.9650e-04\n",
      "Epoch 934/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.4243e-05 - val_loss: 1.9535e-04\n",
      "Epoch 935/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.3884e-05 - val_loss: 1.9531e-04\n",
      "Epoch 936/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.3559e-05 - val_loss: 1.9601e-04\n",
      "Epoch 937/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.3265e-05 - val_loss: 1.9649e-04\n",
      "Epoch 938/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.2987e-05 - val_loss: 1.9624e-04\n",
      "Epoch 939/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.2707e-05 - val_loss: 1.9589e-04\n",
      "Epoch 940/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.2436e-05 - val_loss: 1.9523e-04\n",
      "Epoch 941/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 8.2186e-05 - val_loss: 1.9473e-04\n",
      "Epoch 942/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 8.1940e-05 - val_loss: 1.9476e-04\n",
      "Epoch 943/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 8.1708e-05 - val_loss: 1.9671e-04\n",
      "Epoch 944/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.2119e-05 - val_loss: 1.9550e-04\n",
      "Epoch 945/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.2532e-05 - val_loss: 1.9624e-04\n",
      "Epoch 946/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 8.2833e-05 - val_loss: 1.9330e-04\n",
      "Epoch 947/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 8.2500e-05 - val_loss: 1.9176e-04\n",
      "Epoch 948/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 8.2020e-05 - val_loss: 1.9138e-04\n",
      "Epoch 949/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.1610e-05 - val_loss: 1.9228e-04\n",
      "Epoch 950/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 8.1247e-05 - val_loss: 1.9256e-04\n",
      "Epoch 951/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.0878e-05 - val_loss: 1.9199e-04\n",
      "Epoch 952/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 8.0522e-05 - val_loss: 1.9111e-04\n",
      "Epoch 953/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 8.0212e-05 - val_loss: 1.9040e-04\n",
      "Epoch 954/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.9932e-05 - val_loss: 1.8993e-04\n",
      "Epoch 955/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.9654e-05 - val_loss: 1.8999e-04\n",
      "Epoch 956/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.9389e-05 - val_loss: 1.9024e-04\n",
      "Epoch 957/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.9146e-05 - val_loss: 1.9058e-04\n",
      "Epoch 958/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.8923e-05 - val_loss: 1.9075e-04\n",
      "Epoch 959/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.8938e-05 - val_loss: 1.8998e-04\n",
      "Epoch 960/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.8560e-05 - val_loss: 1.8841e-04\n",
      "Epoch 961/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.8484e-05 - val_loss: 1.8777e-04\n",
      "Epoch 962/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.8319e-05 - val_loss: 1.8733e-04\n",
      "Epoch 963/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.8083e-05 - val_loss: 1.8769e-04\n",
      "Epoch 964/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.7860e-05 - val_loss: 1.8833e-04\n",
      "Epoch 965/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.7647e-05 - val_loss: 1.8857e-04\n",
      "Epoch 966/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.7446e-05 - val_loss: 1.8825e-04\n",
      "Epoch 967/10000\n",
      "11310/11310 [==============================] - 0s 29us/sample - loss: 7.7466e-05 - val_loss: 1.8656e-04\n",
      "Epoch 968/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.7130e-05 - val_loss: 1.8595e-04\n",
      "Epoch 969/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.6969e-05 - val_loss: 1.8566e-04\n",
      "Epoch 970/10000\n",
      "11310/11310 [==============================] - 0s 32us/sample - loss: 7.6749e-05 - val_loss: 1.8598e-04\n",
      "Epoch 971/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.6545e-05 - val_loss: 1.8687e-04\n",
      "Epoch 972/10000\n",
      "11310/11310 [==============================] - 0s 16us/sample - loss: 7.7070e-05 - val_loss: 1.8645e-04\n",
      "Epoch 973/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.6417e-05 - val_loss: 1.8537e-04\n",
      "Epoch 974/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 7.6052e-05 - val_loss: 1.8501e-04\n",
      "Epoch 975/10000\n",
      "11310/11310 [==============================] - 0s 26us/sample - loss: 7.5883e-05 - val_loss: 1.8493e-04\n",
      "Epoch 976/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.5691e-05 - val_loss: 1.8512e-04\n",
      "Epoch 977/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.5724e-05 - val_loss: 1.8392e-04\n",
      "Epoch 978/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.5513e-05 - val_loss: 1.8339e-04\n",
      "Epoch 979/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.5488e-05 - val_loss: 1.8268e-04\n",
      "Epoch 980/10000\n",
      "11310/11310 [==============================] - 0s 23us/sample - loss: 7.5322e-05 - val_loss: 1.8240e-04\n",
      "Epoch 981/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.5089e-05 - val_loss: 1.8275e-04\n",
      "Epoch 982/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.4878e-05 - val_loss: 1.8331e-04\n",
      "Epoch 983/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.4663e-05 - val_loss: 1.8349e-04\n",
      "Epoch 984/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.4448e-05 - val_loss: 1.8332e-04\n",
      "Epoch 985/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.4242e-05 - val_loss: 1.8300e-04\n",
      "Epoch 986/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 7.4054e-05 - val_loss: 1.8250e-04\n",
      "Epoch 987/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.4343e-05 - val_loss: 1.8131e-04\n",
      "Epoch 988/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.3843e-05 - val_loss: 1.8073e-04\n",
      "Epoch 989/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 7.3721e-05 - val_loss: 1.8050e-04\n",
      "Epoch 990/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 7.3523e-05 - val_loss: 1.8071e-04\n",
      "Epoch 991/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 7.3324e-05 - val_loss: 1.8119e-04\n",
      "Epoch 992/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.3135e-05 - val_loss: 1.8138e-04\n",
      "Epoch 993/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2952e-05 - val_loss: 1.8099e-04\n",
      "Epoch 994/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.3009e-05 - val_loss: 1.7987e-04\n",
      "Epoch 995/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2640e-05 - val_loss: 1.7960e-04\n",
      "Epoch 996/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2478e-05 - val_loss: 1.7965e-04\n",
      "Epoch 997/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.2301e-05 - val_loss: 1.7960e-04\n",
      "Epoch 998/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.2140e-05 - val_loss: 1.7941e-04\n",
      "Epoch 999/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.1984e-05 - val_loss: 1.7936e-04\n",
      "Epoch 1000/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.2102e-05 - val_loss: 1.7802e-04\n",
      "Epoch 1001/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.2003e-05 - val_loss: 1.7767e-04\n",
      "Epoch 1002/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 7.1943e-05 - val_loss: 1.7703e-04\n",
      "Epoch 1003/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.1727e-05 - val_loss: 1.7706e-04\n",
      "Epoch 1004/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.1506e-05 - val_loss: 1.7749e-04\n",
      "Epoch 1005/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 7.1303e-05 - val_loss: 1.7784e-04\n",
      "Epoch 1006/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 7.1080e-05 - val_loss: 1.7770e-04\n",
      "Epoch 1007/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 7.0867e-05 - val_loss: 1.7752e-04\n",
      "Epoch 1008/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.0673e-05 - val_loss: 1.7748e-04\n",
      "Epoch 1009/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.0497e-05 - val_loss: 1.8774e-04\n",
      "Epoch 1010/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 7.1319e-05 - val_loss: 1.7634e-04\n",
      "Epoch 1011/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.0280e-05 - val_loss: 1.7586e-04\n",
      "Epoch 1012/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 7.0204e-05 - val_loss: 1.7534e-04\n",
      "Epoch 1013/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 7.0039e-05 - val_loss: 1.7533e-04\n",
      "Epoch 1014/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.9843e-05 - val_loss: 1.7578e-04\n",
      "Epoch 1015/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.9666e-05 - val_loss: 1.7601e-04\n",
      "Epoch 1016/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.9480e-05 - val_loss: 1.7586e-04\n",
      "Epoch 1017/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.9543e-05 - val_loss: 1.7744e-04\n",
      "Epoch 1018/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.9390e-05 - val_loss: 1.7436e-04\n",
      "Epoch 1019/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.9104e-05 - val_loss: 1.7377e-04\n",
      "Epoch 1020/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.9071e-05 - val_loss: 1.7325e-04\n",
      "Epoch 1021/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.8909e-05 - val_loss: 1.7318e-04\n",
      "Epoch 1022/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.8707e-05 - val_loss: 1.7359e-04\n",
      "Epoch 1023/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.8536e-05 - val_loss: 1.7394e-04\n",
      "Epoch 1024/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.8352e-05 - val_loss: 1.7400e-04\n",
      "Epoch 1025/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.8172e-05 - val_loss: 1.7382e-04\n",
      "Epoch 1026/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.8254e-05 - val_loss: 1.7322e-04\n",
      "Epoch 1027/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.7887e-05 - val_loss: 1.7258e-04\n",
      "Epoch 1028/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.7750e-05 - val_loss: 1.7242e-04\n",
      "Epoch 1029/10000\n",
      "11310/11310 [==============================] - 0s 24us/sample - loss: 6.7592e-05 - val_loss: 1.7246e-04\n",
      "Epoch 1030/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.7678e-05 - val_loss: 1.7419e-04\n",
      "Epoch 1031/10000\n",
      "11310/11310 [==============================] - 0s 28us/sample - loss: 6.7314e-05 - val_loss: 1.7155e-04\n",
      "Epoch 1032/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.7230e-05 - val_loss: 1.7108e-04\n",
      "Epoch 1033/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.7119e-05 - val_loss: 1.7089e-04\n",
      "Epoch 1034/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.6960e-05 - val_loss: 1.7105e-04\n",
      "Epoch 1035/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.6793e-05 - val_loss: 1.7158e-04\n",
      "Epoch 1036/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.6636e-05 - val_loss: 1.7591e-04\n",
      "Epoch 1037/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.6977e-05 - val_loss: 1.7101e-04\n",
      "Epoch 1038/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.6356e-05 - val_loss: 1.7032e-04\n",
      "Epoch 1039/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 6.6237e-05 - val_loss: 1.7005e-04\n",
      "Epoch 1040/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.6096e-05 - val_loss: 1.7010e-04\n",
      "Epoch 1041/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.6187e-05 - val_loss: 1.6983e-04\n",
      "Epoch 1042/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.5859e-05 - val_loss: 1.6903e-04\n",
      "Epoch 1043/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.5785e-05 - val_loss: 1.6855e-04\n",
      "Epoch 1044/10000\n",
      "11310/11310 [==============================] - 0s 30us/sample - loss: 6.5662e-05 - val_loss: 1.6837e-04\n",
      "Epoch 1045/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.5497e-05 - val_loss: 1.6858e-04\n",
      "Epoch 1046/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.5334e-05 - val_loss: 1.6891e-04\n",
      "Epoch 1047/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.5175e-05 - val_loss: 1.7096e-04\n",
      "Epoch 1048/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.5519e-05 - val_loss: 1.7305e-04\n",
      "Epoch 1049/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.5382e-05 - val_loss: 1.6832e-04\n",
      "Epoch 1050/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4764e-05 - val_loss: 1.6770e-04\n",
      "Epoch 1051/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4654e-05 - val_loss: 1.6715e-04\n",
      "Epoch 1052/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.4541e-05 - val_loss: 1.6699e-04\n",
      "Epoch 1053/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4401e-05 - val_loss: 1.6717e-04\n",
      "Epoch 1054/10000\n",
      "11310/11310 [==============================] - 0s 22us/sample - loss: 6.4252e-05 - val_loss: 1.6959e-04\n",
      "Epoch 1055/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4605e-05 - val_loss: 1.7597e-04\n",
      "Epoch 1056/10000\n",
      "11310/11310 [==============================] - 0s 18us/sample - loss: 6.4723e-05 - val_loss: 1.7952e-04\n",
      "Epoch 1057/10000\n",
      "11310/11310 [==============================] - 0s 27us/sample - loss: 6.4594e-05 - val_loss: 1.7723e-04\n",
      "Epoch 1058/10000\n",
      "11310/11310 [==============================] - 0s 20us/sample - loss: 6.4467e-05 - val_loss: 1.7423e-04\n",
      "Epoch 1059/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.4338e-05 - val_loss: 1.7072e-04\n",
      "Epoch 1060/10000\n",
      "11310/11310 [==============================] - 0s 21us/sample - loss: 6.4206e-05 - val_loss: 1.7453e-04\n",
      "Epoch 1061/10000\n",
      "11310/11310 [==============================] - 0s 19us/sample - loss: 6.4080e-05 - val_loss: 1.7443e-04\n",
      "Epoch 1062/10000\n",
      "11310/11310 [==============================] - 0s 17us/sample - loss: 6.3954e-05 - val_loss: 1.7182e-04\n",
      "Epoch 01062: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelType = \"LSTM\"\n",
    "trainingSetAdv, trainingSetLabels, testSet, validationSet = getReshapedAdversarialDataSet(dataSet, advDataSet, modelType)\n",
    "numOfLayers = 1\n",
    "numOfNeurons = 20 \n",
    "[model, validatoinLoss, numOfEpochs, history] = trainLSTMAdv(numOfLayers, numOfNeurons, trainingSetAdv, trainingSetLabels, validationSet)\n",
    "model.save('Trained_Model/lstm_adv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
