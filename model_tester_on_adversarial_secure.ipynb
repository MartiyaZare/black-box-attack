{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Flatten, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load config\n",
    "config = loadData(\"config\")\n",
    "dataSetSize = config[\"dataSetSize\"]\n",
    "testSetBenignSize = config[\"testSetBenignSize\"]\n",
    "validationSetSize = config[\"validationSetSize\"]\n",
    "trainingSetSize = config[\"trainingSetSize\"]\n",
    "sequenceLen = config[\"sequenceLen\"]\n",
    "dimensionsCount = config[\"dimensionsCount\"]\n",
    "adversarialTestSetSize = config[\"adversarialTestSetSize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = loadData(\"thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision without threshold is:  1.0\n",
      "Recall without threshold is:  1.0\n",
      "minPositiveMSE 0.0032279734131176706\n",
      "maxNegativeMSE 0.0015371517642618381\n",
      "Threshold is  0.0017062339291474215\n",
      "Precision by threshold is:  1.0\n",
      "Recall by threshold is:  1.0\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_pca\")\n",
    "advSetSize = len(adversarialSet)\n",
    "advTestSet = adversarialSet[advSetSize - adversarialTestSetSize:]\n",
    "_,benignTestSet,_ = getReshapedDataSet(loadData(\"normalized_data_set\"), \"PCA\")\n",
    "test_labels = np.concatenate((np.ones(len(advTestSet)),np.zeros(len(benignTestSet))))\n",
    "testSet = np.concatenate((getReshapedTestSet(advTestSet, \"PCA\"),benignTestSet))\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/pca_adv.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = calculateThreshold(minPositiveMSE,maxNegativeMSE)\n",
    "thresholds[\"PCA_adv\"] = thre\n",
    "saveData(thresholds,\"thresholds\")\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision without threshold is:  1.0\n",
      "Recall without threshold is:  1.0\n",
      "minPositiveMSE 0.003073575349258088\n",
      "maxNegativeMSE 0.0010811324296685183\n",
      "Threshold is  0.0013730668853040838\n",
      "Precision by threshold is:  1.0\n",
      "Recall by threshold is:  1.0\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_fullyConnected\")\n",
    "advSetSize = len(adversarialSet)\n",
    "advTestSet = adversarialSet[advSetSize - adversarialTestSetSize:]\n",
    "_,benignTestSet,_ = getReshapedDataSet(loadData(\"normalized_data_set\"), \"fullyConnected\")\n",
    "test_labels = np.concatenate((np.ones(len(advTestSet)),np.zeros(len(benignTestSet))))\n",
    "testSet = np.concatenate((getReshapedTestSet(advTestSet, \"fullyConnected\"),benignTestSet))\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/autoencoder_adv.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"fullyConnected\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision without threshold is:  0.9157509157509157\n",
      "Recall without threshold is:  0.9157509157509157\n",
      "minPositiveMSE 0.0022853074886004694\n",
      "maxNegativeMSE 8.91216968976937e-05\n",
      "Threshold is  3.693430875407472e-05\n",
      "Precision by threshold is:  0.9157509157509157\n",
      "Recall by threshold is:  1.0\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_conv\")\n",
    "advSetSize = len(adversarialSet)\n",
    "advTestSet = adversarialSet[advSetSize - adversarialTestSetSize:]\n",
    "_,benignTestSet,_ = getReshapedDataSet(loadData(\"normalized_data_set\"), \"1DConv\")\n",
    "test_labels = np.concatenate((np.ones(len(advTestSet)),np.zeros(len(benignTestSet))))\n",
    "testSet = np.concatenate((getReshapedTestSet(advTestSet, \"1DConv\"),benignTestSet))\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/conv_adv.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=1)\n",
    "mse = mse.reshape(len(testSet)) # for conv only\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"1DConv\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision without threshold is:  0.15318627450980393\n",
      "Recall without threshold is:  0.15318627450980393\n",
      "minPositiveMSE 0.014541888110610808\n",
      "maxNegativeMSE 0.003002605852733423\n",
      "Threshold is  1.0687692541864324e-05\n",
      "Precision by threshold is:  0.15318627450980393\n",
      "Recall by threshold is:  1.0\n"
     ]
    }
   ],
   "source": [
    "adversarialSet = loadData(\"adversarial_data_set_lstm\")\n",
    "advSetSize = len(adversarialSet)\n",
    "advTestSet = adversarialSet[advSetSize - adversarialTestSetSize:]\n",
    "_,benignTestSet,_ = getReshapedDataSet(loadData(\"normalized_data_set\"), \"LSTM\")\n",
    "test_labels = np.concatenate((np.ones(len(advTestSet)),np.zeros(len(benignTestSet))))\n",
    "testSet = np.concatenate((getReshapedTestSet(advTestSet, \"LSTM\"),benignTestSet))\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "model = load_model('Trained_Model/lstm_adv.h5')\n",
    "predicted = model.predict(testSet)\n",
    "mse = (np.square(testSet - predicted)).mean(axis=2).mean(axis=1)\n",
    "mse_label = np.vstack((mse, test_labels)).T\n",
    "precision, recall, minPositiveMSE, maxNegativeMSE = rankedPrecisionAndRecall(mse_label)\n",
    "precisions.append(precision)\n",
    "recalls.append(recall)\n",
    "PCAPrecisions_domain = precisions\n",
    "thre = thresholds[\"LSTM\"]\n",
    "precisionThre, recallThre = rankedPrecisionAndRecallWithThreshold(mse_label,thre)\n",
    "\n",
    "print(\"Precision without threshold is: \", precision)\n",
    "print(\"Recall without threshold is: \", recall)\n",
    "print(\"minPositiveMSE\",minPositiveMSE)\n",
    "print(\"maxNegativeMSE\",maxNegativeMSE)\n",
    "print(\"Threshold is \", thre)\n",
    "print(\"Precision by threshold is: \", precisionThre)\n",
    "print(\"Recall by threshold is: \", recallThre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1, 200, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advTestSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382, 200, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benignTestSet.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
